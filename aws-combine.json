[
    {
        "name": "AWS Route 53 Domain Name Renewal (30 days before expiration)",
        "description": "Ensure that all the domain names registered with AWS Route 53 or transferred to AWS Route 53 are renewed 30 days before their expiry",
        "severity": "Informational",
        "logic": "Route53Domain should not have expirationTime before(30, 'days')",
        "remediation": "\n**From Portal**\nUse following steps to validate expiry date for a domain:\n1. Navigate to Route 53 dashboard at https://console.aws.amazon.com/route53/.\n2. In the left navigation panel, under Domains, click Registered Domains.\n3. Select the relevant domain.\n4. On Your Domains 'domain name' page, in the domain name configuration section, check the domain expiration date -  next to 'Expires on'. If the selected domain is about to expire within 30 days, continue with the renewal process.\n\nUse following steps to enable auto renew for the domains expiring within 30 days:\n1. Sign in to the AWS Management Console and open the Route 53 console.\n2. In the navigation pane, choose Registered Domains.\n3. Choose the name of the domain that you want to update.\n4. Choose Enable to turn on automatic renewal. Once the renewal process for the domain is successfully completed, AWS will send you an email with the renewal details.\n\n**From TF**\n```\nresource \"aws_route53domains_registered_domain\" \"example\" {\ndomain_name = \"example.com\"\nauto_renew =  true\nname_server {\nname = \"example.com\"\n}\n}\n```\nNote: 'auto_renew = true/false' parameter is used to ensure whether the domain registration is set to renew automatically or not.\n\n**From Command Line**\nRun following command to enable the Auto Renew feature for the selected domain:\n```\naws route53domains enable-domain-auto-renew --domain-name DOMAIN_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-enable-disable-auto-renewal.html\n2. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-extend.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53domains_registered_domain#auto_renew\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53domains/enable-domain-auto-renew.html\n5. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-renew.html ",
        "complianceTag": "DNS Management|Baseline",
        "logicHash": "564FPZUMq5MhOnKuGOztrQ",
        "ruleId": "D9.AWS.DNS.05",
        "category": "Baseline"
    },
    {
        "name": "AWS Route 53 Domain Name Renewal (7 days before expiration)",
        "description": "Ensure that all the domain names registered with AWS Route 53 or transferred to AWS Route 53 are renewed 7 days before their expiry",
        "severity": "Informational",
        "logic": "Route53Domain should not have expirationTime before(7, 'days')",
        "remediation": "\n**From Portal**\nUse following steps to validate expiry date for a domain:\n1. Navigate to Route 53 dashboard at https://console.aws.amazon.com/route53/.\n2. In the left navigation panel, under Domains, click Registered Domains.\n3. Select the relevant domain.\n4. On Your Domains 'domain name' page, in the domain name configuration section, check the domain expiration date -  next to 'Expires on'. If the selected domain is about to expire within 7 days, continue with the renewal process.\n\nUse following steps to enable auto renew for the domains expiring within 7 days:\n1. Sign in to the AWS Management Console and open the Route 53 console.\n2. In the navigation pane, choose Registered Domains.\n3. Choose the name of the domain that you want to update.\n4. Choose Enable to turn on automatic renewal. Once the renewal process for the domain is successfully completed, AWS will send you an email with the renewal details.\n\n**From TF**\n```\nresource \"aws_route53domains_registered_domain\" \"example\" {\ndomain_name = \"example.com\"\nauto_renew =  true\nname_server {\nname = \"example.com\"\n}\n}\n```\nNote: 'auto_renew = true/false' parameter is used to ensure whether the domain registration is set to renew automatically or not.\n\n**From Command Line**\nRun following command to enable the Auto Renew feature for the selected domain:\n```\naws route53domains enable-domain-auto-renew --domain-name DOMAIN_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-enable-disable-auto-renewal.html\n2. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-extend.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53domains_registered_domain#auto_renew\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53domains/enable-domain-auto-renew.html\n5. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-renew.html ",
        "complianceTag": "DNS Management|Baseline",
        "logicHash": "nw3dvVdC/LUEPB61aCR6fQ",
        "ruleId": "D9.AWS.DNS.04",
        "category": "Baseline"
    },
    {
        "name": "Amazon EFS must have an associated tag",
        "description": "Tags are key-value pairs that you attach to AWS resources to better organize them. They are particularly useful when you have many resources of the same type. By using tags, customers with multiple Amazon EFS can easily access and analyze a specific set by filtering on those that contain the same tag. Two of the key advantages of tagging your Amazon EFS are: Grouping and Filtering and Cost allocation.",
        "severity": "Informational",
        "logic": "EFS should have tags",
        "remediation": "\n**From Portal**\n1. Navigate to https://console.aws.amazon.com/efs/\n2. Choose the File System in the left navigation panel.\n3. Select the desired file system and click on Tags.\n4. Under Tags, choose Manage tags.\n5. Choose Add tag, and then enter a Tag Key and an optional Value. To add more tags, repeat this step.\n6. Choose Save.\n\n**From TF**\n```\nresource \"aws_efs_file_system\" \"example\" {\ncreation_token = \"FILE_SYSTEM_NAME\"\n\ntags = {\nName = \"TAG_NAME\"\n}\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/efs/latest/ug/manage-fs-tags.html\n2. https://docs.aws.amazon.com/efs/latest/ug/API_TagResource.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_file_system ",
        "complianceTag": "Cloud Assets Management|Baseline",
        "logicHash": "1JIEUsfnGSg4XhxFMPQ8Fg",
        "ruleId": "D9.AWS.AS.04",
        "category": "Baseline"
    },
    {
        "name": "Enable AWS Route 53 Domain Auto Renew",
        "description": "Ensure that AWS Route 53 Auto Renew feature is enabled to automatically renew your domain names as the expiration date approaches",
        "severity": "Informational",
        "logic": "Route53Domain should not have autoRenew=false",
        "remediation": "\n**From Portal**\nUse following steps to enable automatic renewal for a domain:\n1. Sign in to the AWS Management Console and open the Route 53 console.\n2. In the navigation pane, choose Registered Domains.\n3. Choose the name of the domain that you want to update.\n4. Choose Enable to turn on automatic renewal.\n\n**From TF**\n```\nresource \"aws_route53domains_registered_domain\" \"example\" {\ndomain_name = \"example.com\"\nauto_renew =  true\nname_server {\nname = \"example.com\"\n}\n}\n```\nNote: 'auto_renew = true/false' parameter is used to ensure whether the domain registration is set to renew automatically or not.\n\n**From Command Line**\nRun following command to enable the Auto Renew feature for the selected domain:\n```\naws route53domains enable-domain-auto-renew --domain-name DOMAIN_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-enable-disable-auto-renewal.html\n2. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-extend.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53domains_registered_domain#auto_renew\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53domains/enable-domain-auto-renew.html ",
        "complianceTag": "DNS Management|Baseline",
        "logicHash": "3Ofsoa9WtC1Ef4D2ggU1aA",
        "ruleId": "D9.AWS.DNS.02",
        "category": "Baseline"
    },
    {
        "name": "Enable AWS Route 53 Domain Transfer Lock",
        "description": "Ensure that your AWS Route 53 registered domains are locked to prevent any unauthorized transfers to another domain name registrar",
        "severity": "Informational",
        "logic": "Route53Domain should not have transferLock=false",
        "remediation": "\n**From Portal**\nUse following steps to enable Transfer Lock for domains:\n1. Sign in to the AWS Management Console and open the Route 53 console at https://console.aws.amazon.com/route53/.\n2. In the navigation pane, choose Registered Domains.\n3. Choose the name of the domain that you want to update.\n4. Click on the 'Domain Name' as a link to access the configuration settings and click on the 'Enable' option next to 'Transfer Lock'.\n\n**From TF**\n```\nresource \"aws_route53domains_registered_domain\" \"example\" {\ndomain_name = \"example.com\"\nauto_renew =  true\ntransfer_lock = true\nname_server {\nname = \"example.com\"\n}\n}\n```\n\n**From Command Line**\nRun following command to enable the transfer lock on a Domains.\n```\naws route53domains enable-domain-transfer-lock --region REGION_NAME --domain-name DOMAIN_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-lock.html\n2. https://awscli.amazonaws.com/v2/documentation/api/2.4.19/reference/route53domains/enable-domain-transfer-lock.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53domains_registered_domain ",
        "complianceTag": "DNS Management|Baseline",
        "logicHash": "U+nfNp3v9mWzW8/T67Yu1A",
        "ruleId": "D9.AWS.DNS.03",
        "category": "Baseline"
    },
    {
        "name": "Enable container's health checks",
        "description": "Amazon Elastic Container Service (ECS) health checks give you more control over monitoring the health of your tasks and improve the ability of the ECS service scheduler to ensure your services are healthy. If health checks are not configured for this container in its task definition, then it reports the health status as UNKNOWN.",
        "severity": "Informational",
        "logic": "EcsTask should not have healthStatus = 'UNKNOWN'",
        "remediation": "\n**From Portal**\nUse following steps to verify current status of task definition.\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. Navigate to ECS.\n3. Select the Region that contains your task definition.\n4. In the left pane, select Task Definitions.\n5. Verify the Status of last revision. it should be ACTIVE not UNKNOWN.\n\nCreate a new task definition revision to enable container's health check.\n1. Navigate to ECS.\n2. Select the Region that contains your task definition.\n3. In the left pane, select Task Definitions.\n4. Check the task definition and click Create new revision.\n5. On the Create new revision of task definition page, make changes. For example, to change the existing container definitions (such as the container image, memory limits, or port mappings), select the container, make the changes, and then choose Update.\n6. Select Create.\n7. If your task definition is used in a service, update your service with the updated task definition and deactivate the previous task definition.\n\nNote: Follow reference section for more details on updating a service.\n\n**From Command Line**\nUse following command to create new task definition revision with a JSON string parameter.\n\nNote: Container definitions is provided as a JSON string parameter with escaped double quotes.\n```\naws ecs register-task-definition --family task_definition_family --container-definitions \"[{\"name\":\"sleep\",\"image\":\"busybox\",\"cpu\":10,\"command\":[\"sleep\",\"360\"],\"memory\":10,\"essential\":true}]\"\n```\nUse following command to change the task definition used in a service.\n```\naws ecs update-service --service service_name --task-definition task_definition_ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-task-definition.html\n2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definition_healthcheck\n3. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-task-definition-classic.html\n4. https://aws.amazon.com/premiumsupport/knowledge-center/ecs-task-container-health-check-failures/\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/register-task-definition.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-service.html ",
        "complianceTag": "Operational|Baseline",
        "logicHash": "4fO5vMDNtVWUgDzGHABEZg",
        "ruleId": "D9.AWS.OPE.03",
        "category": "Baseline"
    },
    {
        "name": "Ensure AWS Lambda functions have tracing enabled",
        "description": "AWS Lambda functions should have TracingConfig enabled since it activates the AWS X-Ray service.  AWS X-Ray service collects information on requests that a specific function performed. It reduces the investigation, debugging and diagnostics time and effort. The value can be either PassThrough or Active. If PassThrough, Lambda will only trace the request from an upstream service if it contains a tracing header with 'sampled=1'. If Active, Lambda will respect any tracing header it receives from an upstream service. If no tracing header is received, Lambda will call X-Ray for a tracing decision. It is recommended to use 'Active'.",
        "severity": "Informational",
        "logic": "Lambda should not have tracingConfig.mode='PassThrough'",
        "remediation": "\n**From Portal**\n1. Log in to the AWS Management Console and open the Amazon Lambda console.\n2. Open the function you want to modify.\n3. Click the Configuration tab.\n4. Open the Monitoring and operations tools on the left side.\n5. Click Edit and enable Active tracing for AWS X-ray.\n6. Click Save.\n\n**From TF**\n```\nresource \"aws_lambda_function\" \"active\" {\ntracing_config {\n-  mode = \"PassThrough\"\n+  mode = \"Active\"\n}\n}\n```\n\n**From Command Line**\n```\naws lambda update-function-configuration --function-name lambda_function_name --tracing-config Mode=Active\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/services-xray.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/update-function-configuration.html ",
        "complianceTag": "Operational|Baseline",
        "logicHash": "+LQWVKps1YRogPibMGt8Vg",
        "ruleId": "D9.AWS.OPE.07",
        "category": "Baseline"
    },
    {
        "name": "Ensure AWS RDS instances have Automatic Backup set up",
        "description": "Automatic Backup creates a storage volume snapshot of your DB instance, backing up the entire DB instance and not just individual databases which provide for point-in-time recovery. The automatic backup will happen during a specified backup window time and keeps the backups for a period of time defined in the retention period. It is recommended to set Automatic Backups for your critical RDS servers that will help in the data restoration process.",
        "severity": "Informational",
        "logic": "RDS should have backupRetentionPeriod>0",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the navigation pane, choose Databases, and then choose the DB instance that you want to modify.\n3. Choose Modify.\n4. In 'Backup' section,\na. From the 'Backup Retention Period' drop-down list, select the number of days to retain automatic backups of this DB instance\nb. Select 'Start Time' and 'Duration' in 'Backup window', which is the daily time range (in UTC) during which automated backups will be performed\n5. Click 'Continue'\n6. On the confirmation page, select 'Modify DB Instance' to save your changes\n\n**From TF**\n```\nresource \"aws_db_instance\" \"default\" {\nallocated_storage    = 10\nengine               = \"mysql\"\nengine_version       = \"5.7\"\ninstance_class       = \"db.t3.micro\"\nname                 = \"mydb\"\nusername             = \"foo\"\npassword             = \"foobarbaz\"\nparameter_group_name = \"default.mysql5.7\"\nskip_final_snapshot  = true\n+ backup_retention_period = 5 # any positive number\n}\n```\n\n**From Command Line**\naws rds modify-db-instance --region REGION --db-instance-identifier DBINSTANCE --backup-retention-period NUMBER_OF_DAYS --apply-immediately\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html\n2. https://aws.amazon.com/rds/faqs/\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance",
        "complianceTag": "Backup and Disaster Recovery|Baseline",
        "logicHash": "gL5dKBHr+iM2AkfWm//7Cw",
        "ruleId": "D9.AWS.DR.01",
        "category": "Baseline"
    },
    {
        "name": "Ensure AWS RDS retention policy is at least 7 days",
        "description": "RDS clusters should have Retention Policies for Backups configured to retain at least 7 days of backups.",
        "severity": "Informational",
        "logic": "RDS should have backupRetentionPeriod>6",
        "remediation": "\n**From Portal**\nConfigure your RDS backup retention policy to be at least 7 days.\n1. Sign in to the AWS Management Console and open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the navigation pane, choose Databases, and then choose the DB instance that you want to modify.\n3. Choose Modify.\n4. In 'Backup' section,\na. From the 'Backup Retention Period' options set the retention period to at least 7 days.\nb. Select 'Start Time' and 'Duration' in 'Backup window', which is the daily time range (in UTC) during which automated backups will be performed\n5. Click 'Continue'\n6. On the confirmation page, select 'Modify DB Instance' to save your changes\n\n\n**From TF**\n```\nresource \"aws_db_instance\" \"default\" {\nallocated_storage    = 10\nengine               = \"mysql\"\nengine_version       = \"5.7\"\ninstance_class       = \"db.t3.micro\"\nname                 = \"mydb\"\nusername             = \"foo\"\npassword             = \"foobarbaz\"\nparameter_group_name = \"default.mysql5.7\"\nskip_final_snapshot  = true\n+ backup_retention_period = 7 # number should be 7 or more\n}\n```\n\n**From Command Line**\naws rds modify-db-instance --region REGION --db-instance-identifier DBINSTANCE --backup-retention-period 7 --apply-immediately\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html\n2. https://aws.amazon.com/rds/faqs/\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance",
        "complianceTag": "Backup and Disaster Recovery|Baseline",
        "logicHash": "SE16bmra/4/6Dmq5QMuiCQ",
        "ruleId": "D9.AWS.DR.03",
        "category": "Baseline"
    },
    {
        "name": "Ensure Amazon DynamoDB tables have continuous backups enabled",
        "description": "Continuous Backups in DynamoDB will prevent from loss of data and the features will include Global secondary indexes (GSIs), Local secondary indexes (LSIs), Streams, Provisioned read and write capacity. Restored table items are consistent with LSI projections and eventually consistent with GSI projections.",
        "severity": "Informational",
        "logic": "DynamoDbTable should have continuousBackups.pointInTimeRecoveryDescription.pointInTimeRecoveryStatus='ENABLED'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the DynamoDB console.\n2. In the navigation pane on the left side of the console, choose Tables.\n3. In the list of tables, choose the table you want to update backups\n4. Click on the Backups tab of the table,\n5. Click on edit tab under 'Point-in-time recovery (PITR)' section.\n6. Checkmark on 'Enable point-in-time-recovery' and click save changes.\n\n**From TF**\n```\nresource \"aws_dynamodb_table\" \"example\" {\npoint_in_time_recovery {\nenabled = true\n}\nother required fields here\n}\n```\n\n**From Command Line**\nThe following command update-continuous-backups enables point-in-time recovery for specific table.\n```\naws dynamodb update-continuous-backups --table-name EXAMPLE_NAME --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true\n```\n\n**References**\n1. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/dynamodb_table\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dynamodb/update-continuous-backups.html ",
        "complianceTag": "Backup and Disaster Recovery|Baseline",
        "logicHash": "aP+8rCoYfSTyjD3NkrYEaA",
        "ruleId": "D9.AWS.DR.04",
        "category": "Baseline"
    },
    {
        "name": "Ensure VIRTUAL or HARDWARE MFA is enabled for the 'root' account",
        "description": "The root account is the most privileged user in an AWS account. MFA adds an extra layer of protection on top of a username and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their username and password as well as for an authentication code from their AWS MFA device.\nWhen virtual MFA is used for root accounts, it is recommended that the device used is NOT a personal device, but rather a dedicated mobile device (tablet or phone) that is managed to be kept charged and secured independent of any individual personal devices. ('non-personal virtual MFA') This lessens the risks of losing access to the MFA due to  device loss, device trade-in or if the individual owning the device is no longer employed at the company.\nEnabling MFA provides increased security for console access as it requires the authenticating principal to possess a device that emits a time-sensitive key and have knowledge of a credential.\nNote: Government cloud accounts do not have a root user, and so, should exclude this rule in the CloudGuard UI -> Posture Management -> Exclusions -> Create New Exclusion (for each relevant ruleset)",
        "severity": "Critical",
        "logic": "IamUser where name like '%root_account%' should have mfaType in('Virtual','Hardware')",
        "remediation": "\n**From Portal**\nHardware MFA:\nNote: to manage MFA devices for the root AWS account, you must use your root account credentials to sign in to AWS. You cannot manage MFA devices for the root account using other credentials.\n1. Login to AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/\n2. Choose Dashboard, and under Security Status, expand Activate MFA on your root account\n3. Choose Activate MFA\n4. In the wizard, choose A hardware MFA device and then choose Next Step\n5. In the Serial Number box, enter the serial number that is found on the back of the MFA device\n6. In the Authentication Code 1 box, enter the six-digit number displayed by the MFA device. You might need to press the button on the front of the device to display the number\n7. Wait 30 seconds while the device refreshes the code, and then enter the next six-digit number into the Authentication Code 2 box. You might need to press the button on the front of the device again to display the second number\n8. Choose Next Step. The MFA device is now associated with the AWS account. The next time you use your AWS account credentials to sign in, you must type a code from the hardware MFA device.\n\nVirtual MFA:\nNote: to manage MFA devices for the root AWS account, you must use your root account credentials to sign in to AWS. You cannot manage MFA devices for the root account using other credentials.\n1. Login to AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/\n2. Choose Dashboard, and under Security Status, expand Activate MFA on your root account\n3. Choose Activate MFA\n4. In the wizard, choose A virtual MFA device and then choose Next Step\n5. IAM generates and displays configuration information for the virtual MFA device, including a QR code graphic. The graphic is a representation of the 'secret configuration key' that is available for manual entry on devices that do not support QR codes\n6. Open your virtual MFA application. (For a list of apps that you can use for hosting virtual MFA devices, see Virtual MFA Applications.) If the virtual MFA application supports multiple accounts (multiple virtual MFA devices), choose the option to create a new account (a new virtual MFA device)\n7. Determine whether the MFA app supports QR codes, and then do one of the following:\n- Use the app to scan the QR code. For example, you might choose the camera icon or choose an option similar to Scan code, and then use the device's camera to scan the code\n- In the Manage MFA Device wizard, choose Show secret key for manual configuration, and then type the secret configuration key into your MFA application\nWhen you are finished, the virtual MFA device starts generating one-time passwords\n8. In the Manage MFA Device wizard, in the Authentication Code 1 box, type the one time password that currently appears in the virtual MFA device. Wait up to 30 seconds for the device to generate a new one-time password. Then type the second one-time password into the Authentication Code 2 box. Choose Active Virtual MFA\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_physical.html#enable-hw-mfa-for-root\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html#enable-virt-mfa-for-root",
        "complianceTag": "Identity and Access Management",
        "logicHash": "iRVfGpftQivOb3eqDdh2Lw",
        "ruleId": "D9.AWS.IAM.18",
        "category": ""
    },
    {
        "name": "Ensure no security groups allow ingress from 0.0.0.0/0 to remote server administration ports",
        "description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389.Public access to remote server administration ports, such as 22 and 3389, increases resource attack surface and unnecessarily raises the risk of resource compromise.",
        "severity": "Critical",
        "logic": "SecurityGroup should not have inboundRules with [ scope='0.0.0.0/0' and ( ( port<=22 and portTo>=22) or ( port<=3389 and portTo>=3389 ) ) ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. In the left pane, click Security Groups\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Inbound Rules tab\n6. Click the Edit inbound rules button\n7. Identify the rules to be edited or removed\n8. Either A) update the Source field to a range other than 0.0.0.0/0, or, B) Click Delete to remove the offending inbound rule\n9. Click Save rules\n\n**From Command Line**\n1.  List all security groups with an ingress rule of 0.0.0.0/0.\n```\naws ec2 describe-security-groups --filters Name=ip-permission.cidr,Values='0.0.0.0/0' --query \"SecurityGroups[*].{Name:GroupName,ID:GroupId}\"\n```\n2. Remove the rule which has port 22 or 3389 when ingress is 0.0.0.0/0.\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --protocol tcp --port 22 --cidr 0.0.0.0/0\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --protocol tcp --port 3389 --cidr 0.0.0.0/0\n```\n3. Now add the inbound rules with different parameters, When port is 22 or 3389 set cidr value other than 0.0.0.0/0 e.g. 10.0.0.0/24 or any suitable range.\n```\naws ec2 authorize-security-group-ingress --region REGION --group-name GROUP_NAME --protocol PROTOCOL --port PORT --cidr CIDR_BLOCK\n```\n**From CFT**\n1. Use the resource AWS::EC2::SecurityGroup. When port is 22 or 3389, make sure property AWS::EC2::SecurityGroup::SecurityGroupIngress::CidrIp has specific cidr range other than \"0.0.0.0/0\" e.g. \"10.0.0.1/32\" or any suitable range. See below example template;\n```\nResources:\nGoodSecurityGroup:\nType: AWS::EC2::SecurityGroup\nProperties:\n...\nSecurityGroupIngress:\n- IpProtocol: tcp\nFromPort: 3389\nToPort: 3389\nCidrIp: 10.0.0.0/24\n...\n\n```\n**From TF**\n1. Use the resource aws_security_group. When port is 22 or 3389, make sure property ingress.cidr_blocks has specific cidr range other than \"0.0.0.0/0\" e.g. \"10.0.0.1/32\" or any suitable range. See below example template;\n```\nresource \"aws_security_group\" \"\" {\n...\ningress {\nfrom_port        = 22\nto_port          = 22\nprotocol         = \"tcp\"\ncidr_blocks      = [\"10.0.0.1/32\"]\n}\n...\n}\n\n```\n**References**\n1. https://workbench.cisecurity.org/sections/615826/recommendations/1009568\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html#\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group",
        "complianceTag": "Network Security|Baseline",
        "logicHash": "PnrfhC1TKURVUm8jV02cxg",
        "ruleId": "D9.AWS.NET.77",
        "category": "Baseline"
    },
    {
        "name": "Ensure that S3 Buckets are configured with 'Block public access (bucket settings)'",
        "description": "Amazon S3 provides `Block public access (bucket settings)` and `Block public access (account settings)` to help you manage public access to Amazon S3 resources. By default, S3 buckets and objects are created with public access disabled. However, an IAM principal with sufficient S3 permissions can enable public access at the bucket and/or object level. While enabled, `Block public access (bucket settings)` prevents an individual bucket, and its contained objects, from becoming publicly accessible. Similarly, `Block public access (account settings)` prevents all buckets, and contained objects, from becoming publicly accessible across the entire account.",
        "severity": "Critical",
        "logic": "S3Bucket should have (accessPublicBlock.blockPublicAcls=true or accountAccessPublicBlock.blockPublicAcls=true) and (accessPublicBlock.ignorePublicAcls=true or accountAccessPublicBlock.ignorePublicAcls=true) and (accessPublicBlock.blockPublicPolicy=true or accountAccessPublicBlock.blockPublicPolicy=true) and (accessPublicBlock.restrictPublicBuckets=true or accountAccessPublicBlock.restrictPublicBuckets=true)",
        "remediation": "\n**From Console**\n1. Login to AWS Management Console and open the Amazon S3 console using https://console.aws.amazon.com/s3/\n2. Select the Check box next to the Bucket\n3. Click on 'Edit public access settings'\n4. Click 'Block all public access'\n5. Repeat for all the buckets in your AWS account that contain sensitive data\n\n**From TF**\nTo enable block public access bucket setting, add following in a terraform file:\n```\nresource \"aws_s3_bucket_public_access_block\" \"public_access_block_example\" {\nbucket = BUCKET-NAME\nblock_public_acls = true\nblock_public_policy = true\nrestrict_public_buckets = true\nignore_public_acls = true\n}\n```\n\n**From Command Line**\nTo set Block Public Access configurations, run:\n```\naws s3api put-public-access-block --bucket BUCKET_NAME --public-access-block-configuration \"BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\"\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html#console-block-public-access-options\n2. https://docs.aws.amazon.com/AmazonS3/latest/user-guide/block-public-access-bucket.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_account_public_access_block\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-public-access-block.html\n",
        "complianceTag": "Network Security",
        "logicHash": "YuRxOMrOjPghCAPTgKi4Tw",
        "ruleId": "D9.AWS.NET.72",
        "category": ""
    },
    {
        "name": "Ensure the default security group of every VPC restricts all traffic",
        "description": "A VPC comes with a default security group whose initial settings deny all inbound traffic, allow all outbound traffic, and allow all traffic between instances assigned to the security group. If you don't specify a security group when you launch an instance, the instance is automatically assigned to this default security group. Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that the default security group restrict all traffic. Configuring all VPC default security groups to restrict all traffic will encourage least privilege security group development and mindful placement of AWS resources into security groups which will in-turn reduce the exposure of those resources.",
        "severity": "Critical",
        "logic": "SecurityGroup where name like 'default' and (region='ap_southeast_1' or region='us_east_1') should have inboundRules isEmpty() and outboundRules isEmpty()",
        "remediation": "\n**From Portal**\nSecurity Group Members Perform the following to implement the prescribed state:\n1. Identify AWS resources that exist within the default security group\n2. Create a set of least privilege security groups for those resources\n3. Place the resources in those security groups\n4. Remove the resources noted in #1 from the default security group\n\nSecurity Group State\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. Repeat the next steps for all VPCs - including the default VPC in each AWS region:\n3. In the left pane, click 'Security Groups'.\n4. For each default security group, perform the following:\n5. Select the default security group\n6. For each default security group, choose the Inbound rules tab and delete all inbound rules.\n7. For each default security group, choose the Outbound rules tab and delete all outbound rules.\n8. Create a set of least-privilege security groups for the resources. See here for more details.\nRecommended: IAM groups allow you to edit the 'name' field. After remediating default groups rules for all VPCs in all regions, edit this field to add text similar to 'DO NOT USE. DO NOT ADD RULES'\n\n**From TF**\n```\nresource \"aws_vpc\" \"mainvpc\" {\ncidr_block = \"10.1.0.0/16\"\n}\nresource \"aws_default_security_group\" \"test\" {\nvpc_id = aws_vpc.mainvpc.id\n\ningress {\nprotocol  = -1\nself      = true\nfrom_port = 0\nto_port   = 0\n}\n\n# OR\n\negress {\nfrom_port   = 0\nto_port     = 0\nprotocol    = \"-1\"\n}\n}\n```\n\n**From Command Line**\nTo make sure the default security group of every VPC restricts all traffic, run:\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP-NAME --protocol PROTOCOL --port PORT --cidr 0.0.0.0/0\n```\n```\naws ec2 revoke-security-group-egress --region REGION --group-name GROUP-NAME --protocol PROTOCOL --port PORT --cidr 0.0.0.0/0\n```\n\n**References**\n1. https://docs.aws.amazon.com/config/latest/developerguide/vpc-default-security-group-closed.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/default_security_group\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/default_security_group\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html ",
        "complianceTag": "Network Security|Baseline",
        "logicHash": "qhhhlqwUgKGHYRciOwXeHA",
        "ruleId": "D9.AWS.NET.04",
        "category": "Baseline"
    },
    {
        "name": "Ensure there is a Dead Letter Queue configured for each Amazon SQS queue",
        "description": "Amazon SQS supports dead-letter queues, which other queues (source queues) can target for messages that can't be processed (consumed) successfully. Dead-letter queues are useful for debugging your application or messaging system because they let you isolate problematic messages to determine why their processing doesn't succeed.",
        "severity": "Informational",
        "logic": "Sqs should have redrivePolicy.deadLetterTargetArn",
        "remediation": "\n**From Portal**\nPerform the following to set a dead-letter queue for existing queue:\n1. Sign in to the Amazon SQS console at https://console.aws.amazon.com/sqs/\n2. In the navigation pane, choose Queues.\n3. Choose a queue and choose Edit.\n3. Scroll to the redrive policy section and choose Enabled.\n4. Enable the Dead-letter queue, and set the number of maximum receives to 50.\n5. Choose the Amazon Resource Name (ARN) of an existing Dead Letter Queue that you want to associate with this source queue.\n6. choose Save.\n\n**From TF**\n```\nresource \"aws_sqs_queue\" \"terraform_queue\" {\n+ redrive_policy = jsonencode({                     # to configure DLQ\ndeadLetterTargetArn = aws_sqs_queue.terraform_queue_deadletter.arn\nmaxReceiveCount     = 4\n})\n}\n```\n\n**From CLI**\nNOTE : Where the file should contain RedrivePolicy with deadLetterTargetArn different then the source queue.\naws sqs set-queue-attributes --queue-url QUEUE-URL --attributes <file:update_attributes.json>\n\n**References**\n1. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-dead-letter-queue.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/set-queue-attributes.html\n3. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html",
        "complianceTag": "Operational|Baseline",
        "logicHash": "a0LhfuZpLSySLMyjINX0Ug",
        "ruleId": "D9.AWS.OPE.12",
        "category": "Baseline"
    },
    {
        "name": "Expired Route 53 Domain Names",
        "description": "Identify any expired domain names registered with AWS Route 53",
        "severity": "Informational",
        "logic": "Route53Domain should not have expirationTime before(-1, 'minutes')",
        "remediation": "\n**From Portal**\nUse following steps to verify expired domains.\n1. Navigate to Route 53 dashboard at https://console.aws.amazon.com/route53/.\n2. In the left navigation panel, under Domains, click Registered Domains.\n3. Select the relevant domain.\n4. On Your Domains 'domain name' page, in domain name configuration section, check the domain expiration date.\n5. If the selected domain name is already expired, continue with the restoration process setup.\n\n**From Command Line**\n1. Run below command to list all the domain names registered with AWS or transferred to AWS:\n```\naws route53domains list-domains --query 'Domains[*].DomainName'\n```\n\n2. Run below command to check the expiration date for the selected domain:\n```\naws route53domains get-domain-detail --domain-name EXAMPLE.DOMAIN.COM --query 'ExpirationDate'\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-restore-expired.html\n2. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-renew.html\n3. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-extend.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53domains/list-domains.html ",
        "complianceTag": "DNS Management|Baseline",
        "logicHash": "SNomCgKepzi+esTby4yiFQ",
        "ruleId": "D9.AWS.DNS.01",
        "category": "Baseline"
    },
    {
        "name": "Lambda Functions must have an associated tag",
        "description": "Tags are key-value pairs that you attach to AWS resources to better organize them. They are particularly useful when you have many resources of the same type, which in the case of AWS Lambda, is a function. By using tags, customers with hundreds of Lambda functions can easily access and analyze a specific set by filtering on those that contain the same tag. Two of the key advantages of tagging your Lambda functions are: Grouping and Filtering and Cost allocation.",
        "severity": "Informational",
        "logic": "Lambda should have tags",
        "remediation": "\n**From Portal**\n1. Navigate to: https://console.aws.amazon.com/lambda/home#/functions.\n2. Choose the name of a function.\n3. Choose Configuration, and then choose Tags.\n4. Under Tags, choose Manage tags.\n5. Choose Add new tag, and then enter a Key and an optional Value. To add more tags, repeat this step.\n6. Choose Save.\n\n**From TF**\n```\nresource \"aws_lambda_function\" \"test\" {\nruntime = \"nodejs12.x\"\n\n+ tags = {\n+   Name = \"TAG_NAME\"\n+ }\n}\n```\n\n**From CLI**\nTo add tags to an existing function, use the tag-resource command.\n```\naws lambda tag-resource --resource arn:aws:lambda:us-east-2:123456789012:function:my-function --tags Department=Marketing,CostCenter=1234ABCD\n```\nTo remove tags, use the untag-resource command.\n```\naws lambda untag-resource --resource arn:aws:lambda:us-east-1:123456789012:function:my-function --tag-keys Department\n```\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/configuration-tags.html ",
        "complianceTag": "Cloud Assets Management|Baseline",
        "logicHash": "EB4wPcgC2OLJglxS1wsAHg",
        "ruleId": "D9.AWS.AS.03",
        "category": "Baseline"
    },
    {
        "name": "Use Route53 for scalable, secure DNS service in AWS.",
        "description": "Use AWS Route 53 Domain Name System (DNS) service within your AWS account to manage DNS zones for your domains",
        "severity": "Informational",
        "logic": "Route53HostedZone should have recordSets",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Route 53 console at https://console.aws.amazon.com/route53/.\n2. Choose Create hosted zone.\n3. Login to the AWS Management Console.\n4. In the Create Hosted Zone pane, enter the name of the domain that you want to route traffic for. You can also optionally enter a comment.\n5. Under Type, select the value 'Public hosted zone' or 'Private hosted zone'.\n6. Choose Create.\n\n**From TF**\n```\nresource \"aws_route53_zone\" \"primary\" {\nname = \"example.com\"\n}\n```\n\n**From Command Line**\nRun following command to create a new AWS Route 53 Hosted zone.\n```\naws route53 create-hosted-zone --name example.com --caller-reference VALUE --hosted-zone-config Comment=command-line version\n```\nNote: --caller-reference: Use a unique string that identifies the request and that allows failed CreateHostedZone requests to be retried without the risk of executing the operation twice. You must use a unique CallerReference string every time you submit a CreateHostedZone request. CallerReference can be any unique string, for example, a date/time stamp.\n\nNote: --hosted-zone-config: Use a complex type that contains the optional values as:\nFor public and private hosted zones, an optional comment.\nFor private hosted zones, an optional PrivateZone element\n\nRun following command to add the new private DNS record to the selected Private Hosted zone. You need to create an Amazon Route 53 change file before adding the DNS record to a Hosted zone.\n```\naws route53 change-resource-record-sets --hosted-zone-id ZONE_ID --change-batch file://record.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zone-private-creating.html\n2. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingHostedZone.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_zone\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53/create-hosted-zone.html ",
        "complianceTag": "Network Security|Baseline",
        "logicHash": "lTOu+biDavs9Oz8Ppe2Clw",
        "ruleId": "D9.AWS.NET.24",
        "category": "Baseline"
    },
    {
        "name": "Eliminate use of the 'root' user for administrative and daily tasks",
        "description": "It is strongly recommended not to use the 'root' account. The root account is the most privileged AWS account; it has unrestricted access to all resources in the AWS account. Minimizing the use of this account and adopt the principle of least privilege to reduce the risk of accidental changes and unintended disclosure of highly privileged credentials.\nNote: Government cloud accounts do not have a root user, and so, should exclude this rule in the CloudGuard UI -> Posture Management -> Exclusions -> Create New Exclusion (for each relevant ruleset)",
        "severity": "High",
        "logic": "IamUser where name regexMatch /^<root_account>$/i should not have passwordLastUsed after(-90, 'days')",
        "remediation": "\nWe recommend that Root accounts should not be used and that the credentials not be shared with anyone else. As a best practice, customers should leverage IAM Groups, Roles and Users to grant access to specific AWS resources.\n\n**References**\n1. Follow IAM Best Practices at the following link: http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "jnZ2Ag5/fhI/qfHv3n9Fsg",
        "ruleId": "D9.AWS.IAM.01",
        "category": ""
    },
    {
        "name": "Enforce Password Policy",
        "description": "Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure password are comprised of different character sets, have minimal length, rotation and history restrictions.",
        "severity": "High",
        "logic": "Iam should have passwordPolicy.enabledInAccount=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console\n2. In the console, select the specific region\n3. Navigate to the 'Identity and Access Management (IAM)' service.\n4. In the left pane click on 'Account settings'.\n5. Click on change password policy and select your account password policy requirements.\n6. Select the options that you want to apply to your password policy and choose Save changes.\n\n**From TF**\n```\nresource \"aws_iam_account_password_policy\" \"Example\" {\nminimum_password_length        = \"value\"\nmax_password_age               = \"value\"\npassword_reuse_prevention\t = \"value\"\nhard_expiry\t\t\t = \"true/false\"\nrequire_lowercase_characters   = \"true/false\"\nrequire_numbers                = \"true/false\"\nrequire_uppercase_characters   = \"true/false\"\nrequire_symbols                = \"true/false\"\nallow_users_to_change_password = \"true/false\"\n}\n```\n**From Command Line**\nIn order to enforce password policy, use to following CLI command:\n```\naws iam update-account-password-policy [--minimum-password-length PUT_VALUE ] [--require-symbols | --no-require-symbols] [--require-numbers | --no-require-numbers] [--require-uppercase-characters | --no-require-uppercase-characters] [--require-lowercase-characters | --no-require-lowercase-characters] [--allow-users-to-change-password | --no-allow-users-to-change-password] [--max-password-age PUT_VALUE] [--password-reuse-prevention PUT_VALUE] [--hard-expiry | --no-hard-expiry]\n```\n\n**References**\n1. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n2. https://registry.terraform.io/modules/rhythmictech/password-policy/iam/latest\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_account_password_policy\n4. https://docs.aws.amazon.com/cli/latest/reference/iam/update-account-password-policy.html",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "3XFmc9AywfC7tUiBYvNJkQ",
        "ruleId": "D9.AWS.IAM.112",
        "category": "Baseline"
    },
    {
        "name": "Ensure IAM password policy prevents password reuse",
        "description": "IAM password policies can prevent the reuse of a given password by the same user. It is recommended that the password policy prevent the reuse of passwords.\nPreventing password reuse increases account resiliency against brute force login attempts.",
        "severity": "High",
        "logic": "Iam should have passwordPolicy.passwordReusePrevention>=4",
        "remediation": "\n**From Portal:**\n1. Go to AWS Management Console: https://console.aws.amazon.com/iam/\n2. Navigate to IAM Services.\n3. Under Access management go to Account settings.\n4. Select 'Change password policy'.\n5. Select 'Prevent password reuse'.\n6. Set '4' in the Remember passwords.\n7. Click save changes.\n\n**From TF:**\nSet the 'password_reuse_prevention' to be equal to 4:\n```\nresource \"aws_iam_account_password_policy\" \"strict\" {\n...\npassword_reuse_prevention       = 4\n...\n}\n```\n\n**From Command Line:**\nrun:\n```\naws iam update-account-password-policy --password-reuse-prevention 4\n```\n\nReferences:\n1. https://workbench.cisecurity.org/benchmarks/679\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/update-account-password-policy.html\n",
        "complianceTag": "1.9|Identity and Access Management|Baseline",
        "logicHash": "EOeAowlX4HaNybFByqyUig",
        "ruleId": "D9.AWS.IAM.14",
        "category": "Baseline"
    },
    {
        "name": "Ensure access keys are rotated every 90 days or less (First access key)",
        "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated. Rotating access keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used. Access keys should be rotated to ensure that data cannot be accessed with an old key which might have been lost, cracked, or stolen.",
        "severity": "High",
        "logic": "IamUser where firstAccessKey.isActive='true' should not have firstAccessKey.lastRotated before(-90, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Click 'Make inactive'\n8. Click 'Create access key' and save the new credentials.\n9. Update all applications and tools to use the new access key.\n10. After you verified the new Access key is updated, go to the inactive Access key and click on Delete.\n\n**From Command Line**\n1. To create new access key, run:\n```\naws iam create-access-key --user-name USER_NAME\n```\n2. To inactive the old access key, run following command:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n3. To delete the old access key, run:\n```\naws iam delete-access-key --access-key ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_CLIAPI\n3. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html ",
        "complianceTag": "1.14 | Identity and Access Management|Baseline",
        "logicHash": "2mtdy7TLhfgoYHKhfovZow",
        "ruleId": "D9.AWS.IAM.06",
        "category": "Baseline"
    },
    {
        "name": "Ensure access keys are rotated every 90 days or less (Second access key)",
        "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.\nRotating access keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used. Access keys should be rotated to ensure that data cannot be accessed with an old key which might have been lost, cracked, or stolen.",
        "severity": "High",
        "logic": "IamUser where secondAccessKey.isActive='true' should not have secondAccessKey.lastRotated before(-90, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Click 'Make inactive'\n8. Click 'Create access key' and save the new credentials.\n9. Update all applications and tools to use the new access key.\n10. After you verified the new Access key is updated, go to the inactive Access key and click on Delete.\n\n**From Command Line**\n1. To inactive the old access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n2. To delete the old access key, run:\n```\naws iam delete-access-key --access-key ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_CLIAPI\n3. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html ",
        "complianceTag": "1.14 | Identity and Access Management|Baseline",
        "logicHash": "F5tTPbvdkrZiOxyqiD17hw",
        "ruleId": "D9.AWS.IAM.07",
        "category": "Baseline"
    },
    {
        "name": "Ensure all S3 buckets employ encryption-at-rest",
        "description": "Amazon S3 provides a variety of no, or low, cost encryption options to protect data at rest.",
        "severity": "High",
        "logic": "S3Bucket should have encryption.serverSideEncryptionRules contain [ serverSideEncryptionByDefault.serverSideEncryptionAlgorithm='aws:kms' or 'AES256']",
        "remediation": "1. Login to AWS Management Console and open the Amazon S3 console using \nhttps://console.aws.amazon.com/s3/\n2. Select the Check box next to the Bucket.\n3. Click on 'Properties'.\n4. Click on Default Encryption.\n5. Select either AES-256 or AWS-KMS\n6. Click Save\n7. Repeat for all the buckets in your AWS account lacking encryption",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "RaBuO/FJzP71rAfCNvw8TQ",
        "ruleId": "D9.AWS.CRY.03",
        "category": ""
    },
    {
        "name": "Ensure no 'root' user account access key exists",
        "description": "The root account is the most privileged user in an AWS account. AWS Access Keys provide programmatic access to a given AWS account. It is recommended that all access keys associated with the root account be removed. Removing access keys associated with the root account limits vectors by which the account can be compromised. Additionally, removing the root access keys encourages the creation and use of role based accounts that are least privileged.\nNote: Government cloud accounts do not have a root user, and so, should exclude this rule in the CloudGuard UI -> Posture Management -> Exclusions -> Create New Exclusion (for each relevant ruleset)",
        "severity": "High",
        "logic": "IamUser where name regexMatch /^<root_account>$/ should have firstAccessKey.isActive=false and secondAccessKey.isActive=false",
        "remediation": "\n**From Portal**\nPerform the following to delete or disable active root access keys being Via the AWS Console:\n1. Sign in to the AWS Management Console as Root and open the IAM console at https://console.aws.amazon.com/iam/.\n2. Click on <Root_Account_Name> at the top right and select Security Credentials from the drop down list\n3. On the pop out screen Click on Continue to Security Credentials\n4. Click on Access Keys (Access Key ID and Secret Access Key)\n5. Under the Status column if there are any Keys which are Active\n5.1. Click on Make Inactive - (Temporarily disable Key - may be needed again)\n5.2. Click Delete - (Deleted keys cannot be recovered)\n\n**From TF**\n```\nresource \"aws_iam_access_key\" \"positive1\" {\n+ user    = \"root\"\n- id = \"some_id_that_exists\"\n+ status = \"Inactive\"\n}\n```\n\n**From Command Line**\nTo delete active root access keys, run:\n```\naws iam delete-access-key --access-key-id ACCESS_KEY_ID --user-name USERNAME\n```\n**References**\n1. https://docs.aws.amazon.com/config/latest/developerguide/operational-best-practices-for-cis_aws_benchmark_level_1.html\n2. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n3. https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\n4. https://docs.aws.amazon.com/cli/latest/reference/iam/delete-access-key.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "SUjlyn6ZyZb76aKyowybBw",
        "ruleId": "D9.AWS.IAM.16",
        "category": ""
    },
    {
        "name": "Ensure no EC2 instance allows incoming traffic from 0.0.0.0/0 to known TCP DB port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure EC2 instances are not exposed incoming traffic from 0.0.0.0/0 to known TCP DB ports",
        "severity": "High",
        "logic": "Instance where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_DB_TCP_Ports) and protocol in('TCP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console,  and Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/ .\n2. In the navigation pane, choose Instances.\n3. Select your instance and, in bottom half of the screen, choose the Security tab.\n4. Security groups lists the security groups that are associated with the instance. Inbound rules displays a list of the inbound rules that are in effect for the instance.\n5. Identify the security group with the scope 0.0.0.0/0 and a Known TCP port from the list in GSL.\n6. On the Edit inbound rules page, modify the traffic source that allow traffic from 0.0.0.0/0 to one of the port from the list.\n7. Select My IP from the Source dropdown list to allow inbound traffic only from your machine or  Select Custom from the Source dropdown list and enter appropriate range of IPs.\n8. Click Save to apply the changes.\n\n**From Command Line**\n1. Identify the security group associated with the instance.Remove the rule which has ingress is 0.0.0.0/0 to one of the from the GSL list.\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --protocol tcp --port PORT_NUMBER --cidr 0.0.0.0/0\n```\n2. Now add the inbound rules with different parameters, Modify the CIDR_BLOCK to appropriate range in order to restrict access from 0.0.0/0 to one of the port from the list.\n```\naws ec2 authorize-security-group-ingress --region REGION --group-name GROUP_NAME --protocol PROTOCOL --port PORT --cidr CIDR_BLOCK\n```\n**From CFT**\nUse the link to the Cloudformation resource from the references.\n\n**From TF**\nUse the link to the terraform resource from the references.\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html#\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance\n5. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html",
        "complianceTag": "Network Ports Security",
        "logicHash": "zPhm7LCvt+FHRWQJutcH/A",
        "ruleId": "D9.AWS.NET.80",
        "category": ""
    },
    {
        "name": "Ensure the S3 bucket used to store CloudTrail logs is not publicly accessible",
        "description": "CloudTrail logs a record of every API call made in your AWS account. These log files are stored in an S3 bucket. It is recommended that the bucket policy or access control list (ACL) applied to the S3 bucket that CloudTrail logs to prevents public access",
        "severity": "High",
        "logic": "S3Bucket where policy.Statement contain [Principal.Service='cloudtrail.amazonaws.com'] should not have ( acl.grants contain [uri like 'http://acs.amazonaws.com/groups/global/%'] or policy.Statement with [Effect='Allow' and (Principal='*' or Principal.AWS='*')])",
        "remediation": "\n**From Portal**\nPerform the following to remove any public access that has been granted to the bucket via an ACL or S3 bucket policy:\n\n1. Go to Amazon S3 console at https://console.aws.amazon.com/s3/home\n2. Right-click on the bucket and click Properties\n3. In the Properties pane, click the Permissions tab.\n4. The tab shows a list of grants, one row per grant, in the bucket ACL. Each row identifies the grantee and the permissions granted.\n5. Select the row that grants permission to Everyone or Any Authenticated User\n6. Uncheck all the permissions granted to Everyone or Any Authenticated User (click x to delete the row).\n7. Click Save to save the ACL.\n8. If the Edit bucket policy button is present, click it.\n9. Verify condition in any Statement having an Effect set to Allow and a Principal set to '*' or {'AWS' : '*'}.\n\n**From TF**\nAdd a policy document with required permissions and appropriate condition as needed as follows:\n```\ndata \"aws_iam_policy_document\" \"example\" {\n...\nstatement {\neffect = \"Allow\"\n\nactions = [\nREQUIRED_ACTIONS\n]\nprincipals {\nREQUIRED_PRINCIPALS\n}\n\nresources = [\n\"S3_BUCKET_ARN\",\n]\n\ncondition {\ntest     = TEST\nvariable = CONTEXT_VARIABLE\n\nvalues = [\nVALUES\n]\n}\n}\n...\n}\n```\n\n**From Command Line**\nTo add a policy with required permissions and appropriate condition as needed, run:\n```\naws s3api put-bucket-policy --bucket BUCKET-NAME --policy file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-policy.html\n2. https://registry.terraform.io/providers/hashicorp/aws/3.3.0/docs/data-sources/iam_policy_document\n3. https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html\n4. https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html",
        "complianceTag": "Logging|Baseline",
        "logicHash": "8IpYC8DknNj/TIvs6Ta4cQ",
        "ruleId": "D9.AWS.LOG.23",
        "category": "Baseline"
    },
    {
        "name": "Ensure there is only one active access key available for any single IAM user",
        "description": "Each IAM user can have up to two access keys. Having two access keys (instead of one), increases the risk of unauthorized access and compromise of credentials.  It is also recommended to delete unused access keys.",
        "severity": "High",
        "logic": "IamUser should not have firstAccessKey.isActive=true and secondAccessKey.isActive=true",
        "remediation": "\n**From Portal**\nPerform the following to delete or disable active root access keys being Via the AWS Console :\n1. Sign in to the AWS Management Console as Root and open the IAM console at https://console.aws.amazon.com/iam/.\n2. Click Users in the navigation pane\n3. For the identified IAM user which has two active Access Keys, based on policies of your company, take appropriate action\n4. Delete one of the unused Access Keys\n\n**From TF**\n```\nresource \"aws_iam_access_key\" \"positive1\" {\n+ user    = \"root\"\n- id = \"some_id_that_exists\"\n+ status = \"Inactive\"\n}\n```\n\n**From Command Line**\nTo disable one of the active access keys, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USERNAME\n```\n**References**\n1. https://docs.aws.amazon.com/config/latest/developerguide/operational-best-practices-for-cis_aws_benchmark_level_1.html\n2. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n3. https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys\n4. https://docs.aws.amazon.com/cli/latest/reference/iam/delete-access-key.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "oHt+/V6Iwesjwgzr9WVUeg",
        "ruleId": "D9.AWS.IAM.51",
        "category": ""
    },
    {
        "name": "AWS Cloud Front - WAF Integration",
        "description": "Ensure that all your AWS CloudFront web distributions are integrated with the Web Application Firewall (AWS WAF) service to protect against application-layer attacks",
        "severity": "Medium",
        "logic": "CloudFront where region unlike 'cn_%' should have distributionConfig.webACLId",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and open Cloudfront dashboard at https://console.aws.amazon.com/cloudfront/.\n2. On the Distributions page, select the relevant CDN.\n3. On the General tab click the Edit button.\n4. On the Distribution Settings page, verify the AWS WAF Web ACL configuration status. If AWS WAF Web ACL is set to None:, AWS WAF is not associated with an Access Control List (ACL).\n5. Edit the Settings in under General tab.\n6. Add a AWS WAF web ACL to the distribution.\n7. Click on Save changes.\n\n**From TF**\nwhile creating cloudfront add the web acl ID.\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\n+ web_acl_id = \"ID\"\n}\n```\n\n**From Command Line**\nTo create WAF ACL and update the configuration to integrate with CloudFront, run:\n```\naws waf create-web-acl --name NAME --metric-name METRIC_NAME --default-action Type=BLOCK --change-token TOKEN\n\naws cloudfront update-distribution --id ID --distribution-config file://FILE.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-awswaf.html\n2. https://docs.aws.amazon.com/waf/latest/developerguide/classic-cloudfront-features.html\n3. https://docs.aws.amazon.com/cli/latest/reference/wafv2/create-web-acl.html\n4. https://docs.aws.amazon.com/waf/latest/developerguide/cloudfront-features.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/wafregional_web_acl_association",
        "complianceTag": "Network Security|Baseline",
        "logicHash": "/u5AL41piigqNrQjGyHQgg",
        "ruleId": "D9.AWS.NET.36",
        "category": "Baseline"
    },
    {
        "name": "Attached EBS volumes should be encrypted at-rest",
        "description": "For an added layer of security of your sensitive data in EBS volumes, you should enable EBS encryption at rest. Amazon EBS encryption offers a straightforward encryption solution for your EBS resources that doesn't require you to build, maintain, and secure your own key management infrastructure. It uses KMS keys when creating encrypted volumes and snapshots.",
        "severity": "Medium",
        "logic": "Volume where state='attached' should have encrypted=true",
        "remediation": "\n**From Portal**\nUse following steps to create a new, encrypted EBS volume:\n1. Navigate to EC2.\n2. Select the Region in which you would like to create your volume.\n3. In the navigation pane, select ELASTIC BLOCK STORE, Volumes.\n4. Select Create Volume.\n5. Select the desired values for Volume Type, Size, IOPS, Throughput, and Availability Zone.\n6. To encrypt the volume, select Encrypt this volume, and choose a CMK.\n7. Click Create Volume.\n\n**From TF**\nEnsure that an aws_ebs_volume resource has the encrypted field set to true\n```\nresource \"aws_ebs_volume\" \"example\" {\nencrypted = true\n# other required fields here\n}\n```\n\n**From Command Line**\n1. Get a list of an instance volumes to see which are encrypted and unencrypted. Note the volume id and mount device for each unencrypted volume.\n```\naws ec2 describe-volumes --filters Name=attachment.instance-id, Values=instance_id\n```\n2. Create a snapshot of an unencrypted EBS volume and track the snapshot id that is returned.\n```\naws ec2 create-snapshot --volume-id unencrypted_volume_id\n```\n3. Make an encrypted copy of the snapshot you just created and get the new snapshot id.\n```\naws ec2 copy-snapshot --region destination_region --source-region region_name --encrypted --source-snapshot-id snapshot_id\n```\n4. Create a new EBS volume from the encrypted snapshot and get the new volume id.\n```\naws ec2 create-volume --region region_name --availability-zone availability_zone --snapshot-id snapshot_id --volume-type gp2 --encrypted\n```\n5. Stop the instance with the unencrypted EBS volume\n```\naws ec2 stop-instance --instance-id instance_id\n```\n6. Detatch the non-encrypted EBS volume\n```\naws ec2 detach-volume --volume-id unencrypted_volume_id\n```\n7. Attach the new encrypted EBS volume to the EC2 instance:\n```\naws ec2 attach-volume --volume-id encrypted_volume_id --instance-id instance_id --device device_name\n```\n8. Restart the instance:\n```\naws ec2 start-instance --instance-id instance_id\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\n2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-volume.html\n3. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ebs_volume\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-volume.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "3yMMo7dggCcUMgSnMXmFxQ",
        "ruleId": "D9.AWS.CRY.83",
        "category": ""
    },
    {
        "name": "Amazon GuardDuty service is enabled",
        "description": "Amazon GuardDuty is a threat detection service that continuously monitors for malicious or unauthorized behavior to help you protect your AWS accounts and workloads. It monitors for activity such as unusual API calls or potentially unauthorized deployments that indicate a possible account compromise. GuardDuty also detects potentially compromised instances or reconnaissance by attackers.",
        "severity": "Low",
        "logic": "Region where (region='ap_southeast_1' or region='us_east_1') should have guardDutyStatus='Enabled'",
        "remediation": "\n**From Portal**\nUse following steps to enable Amazon GuardDuty\n1. Open the GuardDuty console at https://console.aws.amazon.com/guardduty/\n2. Choose Get Started.\n3. Choose Enable GuardDuty.\n\nNote: If you previously signed in to the AWS Management Console using AWS account root user credentials, choose Sign in to a different account. If you previously signed in to the console using IAM credentials, choose Sign-in using root account credentials. Then choose Create a new AWS account.\n\n**From TF**\n```\nresource \"aws_guardduty_detector\" \"test\" {\n+ enable = true\n}\n```\n\n**From Command Line**\nRun following command to create an Amazon GuardDuty detector.\n```\naws guardduty create-detector --region AWS_region_name --enable\n```\nNote: Detector is an object to represent the AWS GuardDuty service. A detector must be created to make GuardDuty operational. --enable command syntax specifies that the detector is automatically enabled after creation.\n\n**References**\n1. https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_settingup.html\n2. https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_findings.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/guardduty_detector\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/guardduty/create-detector.html ",
        "complianceTag": "SC-5|AC-2|AU-3|AU-6|CA-7|CM-8|RA-3|RA-5|RA-10|IR-4|IR-5|CA-2|SC-43|SI-3|SI-4|SI-5|SA-15|SA-11",
        "logicHash": "2WCGLKBUCrKFidX2FvreNA",
        "ruleId": "D9.AWS.VLN.03",
        "category": ""
    },
    {
        "name": "Ensure AWS EBS Volumes are attached to instances",
        "description": "Checks for EBS volumes that are unattached to instances, for example, if they persist after an EC2 instance has been terminated. It is recommended to review of these volumes  regularly, since they may contain sensitive company data, application, infrastructure or users. In addition, removing unattached instances will lower your AWS bill.",
        "severity": "Low",
        "logic": "Volume should have attachments contain [ state='attached' ]",
        "remediation": "\n**From Portal**\nUse following steps to change the policy using the AWS Console:\n1. Log in to the AWS Management Console at https://console.aws.amazon.com/.\n2. Open the Amazon EC2 console.\n3. In the navigation pane, select Elastic Block Store and then Volumes.\n4. Select an available Volume and open Actions and then click on Attach Volume.\n5. Enter the name or ID of the Instance; the matching list of instances displays. Only instances in the same Availability Zone as the volume display. Select an Instance from the list.\nFor Device, either keep the suggested Device Name, or enter a different supported Device Name.\n6. Select Attach.\n\n**From TF**\n```\nresource \"aws_volume_attachment\" \"example1\" {\n...\n+ volume_id   = ebs_volume_id\n+ instance_id = aws_instance_id\n}\n```\n\n**From Command Line**\nUse following command to attach a volume to an instance:\n```\naws ec2 attach-volume --volume-id ebs_volume_id --instance-id aws_instance_id --device device_name\n```\nUse following command to delete the unused EBS volume:\n```\naws ec2 delete-volume --volume-id ebs_volume_id\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-attaching-volume.html\n2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/volume_attachment\n5. https://docs.aws.amazon.com/cli/latest/reference/ec2/attach-volume.html\n5. https://docs.aws.amazon.com/cli/latest/reference/ec2/delete-volume.html ",
        "complianceTag": "Operational|Baseline",
        "logicHash": "3qK2bSouG2I8taKC3V1NHA",
        "ruleId": "D9.AWS.OPE.05",
        "category": "Baseline"
    },
    {
        "name": "Ensure AWS RDS instances have Multi-Availability Zone enabled",
        "description": "When an RDS DB instance is enabled with Multi-AZ, the RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different availability zone. These Multi-AZ deployments will improve primary node reachability by providing read replica in case of network connectivity loss or loss of availability in the primary availability zone for read/write operations.",
        "severity": "Low",
        "logic": "RDSDBCluster should have multiAZ=true",
        "remediation": "\n**From Portal**\n1. Sign into the AWS console.\n2. In the console, select the specific region.\n3. Navigate to the Amazon RDS console.\n4. Select Instances, and then select the reported DB instance.\n5. On 'Instance Actions' drop-down list, select 'Modify'\n6. In 'Instance Specifications' section for the 'Multi-AZ Deployment', select 'Yes'\n7. Click 'Continue'\n8. On the confirmation page, review the changes and click 'Modify DB Instance' to save your changes.\n\n**From TF**\n```\nresource \"aws_db_instance\" \"example\" {\n...\nname                 = \"example_db\"\n+ multi_az             = true\n}\n```\nNote: multi_az attribute true specifies that the RDS instance is multi-AZ.\n\n**From Command Line**\n```\naws rds modify-db-instance --db-instance-identifier RDS_instance_name --option-group-name db_instance_option_group --db-parameter-group-name DB_parameter_group --multi-az --apply-immediately\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html\n2. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html\n3. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-cluster.html ",
        "complianceTag": "Backup and Disaster Recovery|Baseline",
        "logicHash": "s8zt1A411uJXLAFexpi5lQ",
        "ruleId": "D9.AWS.DR.02",
        "category": "Baseline"
    },
    {
        "name": "Ensure Auto Minor Version Upgrade feature is Enabled for RDS Instances",
        "description": "RDSs can be upgraded with major and minor upgrades. Minor upgrades help maintain a secure and stable RDS with minimal impact on the application. It is recommended that automatic minor upgrades are enabled. ",
        "severity": "Low",
        "logic": "RDS should have autoMinorVersionUpgrade=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the upper-right corner of the Amazon RDS console, choose the AWS Region in which you want to create the DB instance.\n3. In the navigation pane, choose Databases.\n4. Choose Create database.\n5. In Choose a database creation method, select Standard Create.\n6. Set the other options as per your requirement\n7. Under the Maintenance section, select Yes for Auto minor version upgrade.\n8. Choose Create database\n\n**From TF**\n```\nresource \"aws_db_instance\" \"test\" {\nallocated_storage    = 20\nstorage_type         = \"gp2\"\nengine               = \"mysql\"\nengine_version       = \"5.7\"\ninstance_class       = \"db.t2.micro\"\nname                 = \"mydb\"\nusername             = \"foo\"\npassword             = \"foobarbaz\"\niam_database_authentication_enabled = true\nstorage_encrypted = true\nca_cert_identifier = \"rds-ca-2019\"\n+ auto_minor_version_upgrade = true  #to enable auto Minor Version Upgrade feature\n}\n```\n\n**From Command Line**\nTo enable automatic minor upgrades, run:\n```\naws rds create-db-instance --engine ENGINE --db-instance-identifier DB_IDENTIFIER --allocated-storage SIZE  --db-instance-class DB_INSTANCE_CLASS --vpc-security-group-ids SECURITY_GROUP_ID --db-subnet-group SUBNET_GROUP --master-username USER --master-user-password PWD -backup-retention-period DAYS --auto-minor-version-upgrade\n\n```\n\n**References**\n1. https://docs.aws.amazon.com/config/latest/developerguide/rds-automatic-minor-version-upgrade-enabled.html\n2. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Upgrading.html\n3. https://docs.aws.amazon.com/cli/latest/reference/rds/modify-db-instance.html",
        "complianceTag": "Operational",
        "logicHash": "Iuk+6pQtWENThYdBRTGVOw",
        "ruleId": "D9.AWS.OPE.08",
        "category": ""
    },
    {
        "name": "Ensure CloudTrail log file validation is enabled",
        "description": "CloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails.",
        "severity": "Low",
        "logic": "CloudTrail should have logFileValidationEnabled=true",
        "remediation": "\n**From Portal**\nPerform the following to enable log file validation on a given trail: Via the management Console\n1. Sign in to the AWS Management Console and open the CloudTrail console at https://console.aws.amazon.com/cloudtrail\n2. On the CloudTrail service home page, the Trails page, or the Trails section of the Dashboard page, choose Create trail.\n3. On the Create Trail page, for Trail name, type a name for your trail.\n4. For Storage location, choose Create new S3 bucket to create a bucket. When you create a bucket, CloudTrail creates and applies the required bucket policies.\n5. In Additional settings, click on the yes radio button in section 'Enable log file validation'.\n6. Click Save\n\n**From TF**\n```\nresource \"aws_cloudtrail\" \"negative1\" {\nname                          = \"negative1\"\ns3_bucket_name                = \"bucketlog1\"\n+ enable_log_file_validation    = true\n}\n```\n\n**From Command Line**\naws cloudtrail update-trail --name TRAIL-NAME --enable-log-file-validation\n\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.amazonaws.cn/en_us/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-enabling.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail\n4. https://docs.amazonaws.cn/en_us/awscloudtrail/latest/userguide/cloudtrail-create-a-trail-using-the-console-first-time.html",
        "complianceTag": "Logging",
        "logicHash": "Fei/D4WfIb8eD28c7ibnMw",
        "ruleId": "D9.AWS.LOG.02",
        "category": ""
    },
    {
        "name": "Ensure CloudTrail trails are integrated with CloudWatch Logs",
        "description": "AWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, real time analysis can be performed by configuring CloudTrail to send logs to CloudWatch Logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch Logs log group. It is recommended that CloudTrail logs be sent to CloudWatch Logs.",
        "severity": "Low",
        "logic": "CloudTrail should have cloudWatchLogsRoleArn and status.latestCloudWatchLogsDeliveryTime after (-1, 'days')",
        "remediation": "\n**From Portal**\n1. Open the CloudTrail console at https://console.aws.amazon.com/cloudtrail/.\n2. Choose the trail name. If you choose a trail that applies to all regions, you will be redirected to the region in which the trail was created.\nYou can create a log group or choose an existing log group in the same region as the trail.\nNote: A trail that applies to all regions sends log files from all regions to the CloudWatch Logs log group that you specify.\n3. For CloudWatch Logs, choose Edit.\n4. For New or existing log group, type the log group name , and then choose Continue.\n5. For the IAM role, choose an existing role or create one. If you create an IAM role, type a role name.\n6. Choose Save changes.\n\n**From TF**\n```\nresource \"aws_cloudwatch_log_group\" \"example_log_group\" {\n...\n}\n\nresource \"aws_cloudtrail\" \"example_cloudtrail\" {\n...\ncloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example_log_group.arn}:*\" # CloudTrail requires the Log Stream wildcard\n...\n}\n```\n\n**From Command Line**\nTo update the CloudTrail to add CloudWatch logs, run:\n```\naws cloudtrail update-trail --name TRAIL-NAME --cloud-watch-logs-log-group-arn LOG-GROUP-ARN --cloud-watch-logs-role-arn ROLE-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/cloudtrail/update-trail.html\n2. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/send-cloudtrail-events-to-cloudwatch-logs.html#send-cloudtrail-events-to-cloudwatch-logs-console\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail",
        "complianceTag": "Logging",
        "logicHash": "giiUrgycXiS1LCFyShyGRQ",
        "ruleId": "D9.AWS.LOG.03",
        "category": ""
    },
    {
        "name": "Ensure IAM Users Receive Permissions Only Through Groups",
        "description": "It is recommended that IAM policies be applied directly to groups and roles but not to users. IAM policies are the means by which privileges are granted to users, groups, or roles. By default, IAM users, groups, and roles have no access to AWS resources.\nAssigning privileges at the group or role level reduces the complexity of access management as the number of users grow. Reducing access management complexity may in-turn reduce opportunity for a principal to inadvertently receive or retain excessive privileges.",
        "severity": "Low",
        "logic": "IamUser where not (name regexMatch /^<root_account>$/i ) should have managedPolicies isEmpty() and inlinePolicies isEmpty()",
        "remediation": "\n**From Portal**\nTo remove a direct association between a user and policy:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the left navigation pane, click on Users\n3. For each user:\na. Select the user\nb. Click on the Permissions tab\nc. Expand Managed Policies\nd. Click Detach Policy for each policy\ne. Expand Inline Policies\nf. Click Remove Policy for each policy\n\nTo create an IAM group and assign a policy to it:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/\n2. In the navigation pane, click Groups and then click Create New Group .\n3. In the Group Name box, type the name of the group and then click Next Step .\n4. In the list of policies, select the check box for each policy that you want to apply to all members of the group. Then click Next Step.\n5. Click Create Group\n\nTo add a user to a given group:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, click Groups\n3. Select the group to add a user to\n4. Click Add Users To Group\n5. Select the users to be added to the group\n6. Click Add Users\n\n**From TF**\nTo add user to a group, add following:\n```\nresource \"aws_iam_group_membership\" \"add_user_to_group_example\" {\n...\nusers = [\nUSER-1-NAME,\nUSER-2-NAME,\n]\ngroup = GROUP-NAME\n...\n}\n```\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\n\nTo attach a policy to IAM group, run:\n```\naws iam attach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\n\nTo add a user to a group, run:\n```\naws iam add-user-to-group --group-name GROUP-NAME --user-name USER-NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_create.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage_add-remove-users.html\n3. https://docs.aws.amazon.com/cli/latest/reference/iam/add-user-to-group.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user_group_membership",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "1Ufb5whTdTYU6VLIqa5Iqw",
        "ruleId": "D9.AWS.IAM.20",
        "category": "Baseline"
    },
    {
        "name": "Ensure IAM password policy expires passwords within 90 days or less",
        "description": "IAM password policies can require passwords to be rotated or expired after a given number of days. It is recommended that the password policy expire passwords after 90 days or less.\nReducing the password lifetime increases account resiliency against brute force login attempts. Additionally, requiring regular password changes help in the following scenarios:\n- Passwords can be stolen or compromised sometimes without your knowledge. This can happen via a system compromise, software vulnerability, or internal threat.\n- Certain corporate and government web filters or proxy servers have the ability to intercept and record traffic even if it's encrypted.\n- Many people use the same password for many systems such as work, email, and personal.\n- Compromised end user workstations might have a keystroke logger.",
        "severity": "Low",
        "logic": "Iam should have passwordPolicy.maxPasswordAge>0 and passwordPolicy.maxPasswordAge<91",
        "remediation": "\n**From Portal**\nPerform the following steps to set the password policy via AWS Console.\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Check 'Enable password expiration'\n5. Set 'Password expiration period (in days):' to 90 or less\n\n**From TF**\n```\nresource \"aws_iam_account_password_policy\" \"strict\" {\nmax_password_age               = TYPE_VALUE <= 90\n```\n\n**From Command Line**\n```\naws iam update-account-password-policy --max-password-age 90\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "289ILzPvl70+wpUKMNs+Kg",
        "ruleId": "D9.AWS.IAM.15",
        "category": "Baseline"
    },
    {
        "name": "Ensure IAM password policy require at least one lowercase letter",
        "description": "It is recommended that the password policy require at least one lowercase letter. Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure passwords consist of different character sets. Setting a password complexity policy increases account resiliency against brute force login attempts.",
        "severity": "Low",
        "logic": "Iam should have passwordPolicy.requireLowercaseCharacter=true",
        "remediation": "\n**From Portal**\nPerform the following to set the password policy as prescribed:\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Check 'Requires at least one lowercase letter'\n5. Click 'Apply password policy'\n\n**From TF**\n```\nresource \"aws_iam_account_password_policy\" \"test\" {\nminimum_password_length        = 8\n+ require_lowercase_characters   = true\nrequire_numbers                = true\nrequire_uppercase_characters   = true\nrequire_symbols                = true\nallow_users_to_change_password = true\n}\n```\n\n**From Command Line**\nTo add a password policy with required condition, run:\n```\naws iam update-account-password-policy --require-lowercase-characters\n```\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html\n2. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n3. https://docs.aws.amazon.com/config/latest/developerguide/iam-password-policy.html\n4. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-account-password-policy.html\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_account_password_policy",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "zQg4pD5gh2V74UjM5D2C/g",
        "ruleId": "D9.AWS.IAM.09",
        "category": "Baseline"
    },
    {
        "name": "Ensure IAM password policy require at least one symbol",
        "description": "It is recommended that the password policy require at least one symbol. Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure passwords consist of different character sets. Setting a password complexity policy increases account resiliency against brute force login attempts.",
        "severity": "Low",
        "logic": "Iam should have passwordPolicy.requireSymbols=true",
        "remediation": "\n**From Portal**\nPerform the following to set the password policy as prescribed:\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Check 'Require at least one non-alphanumeric character'\n5. Click 'Apply password policy'\n\n**From TF**\n```\nresource \"aws_iam_account_password_policy\" \"test\" {\nminimum_password_length        = 8\nrequire_lowercase_characters   = true\nrequire_numbers                = true\nrequire_uppercase_characters   = true\n+ require_symbols                = true\nallow_users_to_change_password = true\n}\n```\n\n**From Command Line**\nTo add a password policy with required condition, run:\n```\naws iam update-account-password-policy --require-symbols\n```\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html\n2. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n3. https://docs.aws.amazon.com/config/latest/developerguide/iam-password-policy.html\n4. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-account-password-policy.html\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_account_password_policy",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "AkhnR5uI4aUAwLf/Nj3TfQ",
        "ruleId": "D9.AWS.IAM.10",
        "category": "Baseline"
    },
    {
        "name": "Ensure IAM password policy requires at least one uppercase letter",
        "description": "It is recommended that the password policy require at least one uppercase letter. Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure passwords consist of different character sets. Setting a password complexity policy increases account resiliency against brute force login attempts.",
        "severity": "Low",
        "logic": "Iam should have passwordPolicy.requireUppercaseCharacter=true",
        "remediation": "\n**From Portal**\nPerform the following to set the password policy as prescribed:\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Check 'Requires at least one uppercase letter'\n5. Click 'Apply password policy'\n\n**From TF**\n```\nresource \"aws_iam_account_password_policy\" \"test\" {\nminimum_password_length        = 8\nrequire_lowercase_characters   = true\nrequire_numbers                = true\n+ require_uppercase_characters   = true\nrequire_symbols                = true\nallow_users_to_change_password = true\n}\n```\n**From Command Line**\nTo add a password policy with required condition, run:\n```\naws iam update-account-password-policy --require-uppercase-characters\n```\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html\n2. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n3. https://docs.aws.amazon.com/config/latest/developerguide/iam-password-policy.html\n4. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-account-password-policy.html\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_account_password_policy",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "deMWBl0D9k4hnT43t7rM9A",
        "ruleId": "D9.AWS.IAM.08",
        "category": "Baseline"
    },
    {
        "name": "Ensure IAM password policy requires minimum length of 8 or greater",
        "description": "Set the IAM password policy to ensure passwords consist of at least 8 characters. Password policies are, in part, used to enforce password complexity requirements. Setting a password complexity policy increases account resiliency against brute force login attempts.",
        "severity": "Low",
        "logic": "Iam should have passwordPolicy.minPasswordLength>=8",
        "remediation": "\n**From Portal:**\n1. Go to AWS Management Console: https://console.aws.amazon.com/iam/\n2. Navigate to IAM Services.\n3. Under Access management go to Account settings.\n4. Select 'Change password policy'.\n5. Set the Enforce minimum password length to be '8' characters.\n6. Click save changes.\n\n**From TF:**\nSet the 'minimum_password_length' to be equal to 8:\n```\nresource \"aws_iam_account_password_policy\" \"strict\" {\n...\nminimum_password_length        = 8\n...\n}\n```\n\n**From Command Line:**\nrun:\n```\naws iam update-account-password-policy --minimum-password-length 8\n```\n\nReferences:\n1. https://workbench.cisecurity.org/benchmarks/679\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/update-account-password-policy.html\n",
        "complianceTag": "1.8 | Identity and Access Management|Baseline",
        "logicHash": "ApbJG7LIbHs1ojCJUxXU4A",
        "ruleId": "D9.AWS.IAM.12",
        "category": "Baseline"
    },
    {
        "name": "Ensure S3 bucket access logging is enabled on the CloudTrail S3 bucket",
        "description": "S3 Bucket Access Logging generates a log that contains access records for each request made to your S3 bucket. An access log record contains details about the request, such as the request type, the resources specified in the request worked, and the time and date the request was processed. It is recommended that bucket access logging be enabled on the CloudTrail S3 bucket. By enabling S3 bucket logging on target S3 buckets, it is possible to capture all events which may affect objects within an target buckets. Configuring logs to be placed in a separate bucket allows access to log information which can be useful in security and incident response workflows.",
        "severity": "Low",
        "logic": "S3Bucket where policy.Statement contain [Principal.Service='cloudtrail.amazonaws.com'] should have logging.enabled='true'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and Navigate to Amazon S3 console.\n2. Click on the name of the associated S3 bucket that you want to update.\n3. Select the Properties tab from the console menu to access the bucket properties.\n4. In the Server access logging section, choose Edit to modify the feature configuration.\n5. On the Edit server access logging page, perform the following actions:\na. Choose Enable under Server access logging to enable the Server Access Logging feature for the selected Amazon S3 bucket.\nb. For Target bucket, choose Browse S3 and select the name of the destination bucket and folder for the access logs. You should not use the same bucket for log storage. When your source bucket and destination (target) bucket are the same, additional logs are created for the logs that are written to the bucket. These extra logs can increase your storage billing and make it harder to find the logs that you are looking for.\nc. Choose Save changes to apply the configuration changes. Once the feature is enabled, Amazon S3 console will automatically update your bucket access control list (ACL) to include access to the S3 log delivery group.\n\n**From TF**\n```\nresource \"aws_s3_bucket\" \"cloudtrail_bucket\" {\nbucket = \"BUCKET_NAME\"\nlogging {\ntarget_bucket = \"${TARGET_BUCKET_NAME}\"\ntarget_prefix = \"KEY_PREFIX\"\n}\nother required fields here\n}\n```\nNote: Terraform logging configuration block supports the following arguments:\ntarget_bucket - (Required) The name of the bucket that will receive the log objects.\ntarget_prefix - (Optional) To specify a key prefix for log objects.\n\n**From Command Line**\nUse following command to enable Bucket Logging:\n```\naws s3api put-bucket-logging --bucket BUCKET_NAME --bucket-logging-status file://logging.json\n```\nNote: Logging.json is a JSON document in the current folder that contains the logging configuration. For more information follow the reference section.\n\n**References**\n1. https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-server-access-logging.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/get-bucket-acl.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudtrail/index.html ",
        "complianceTag": "Logging|Baseline",
        "logicHash": "CIiGKr8zSDlruWpKA4jkwg",
        "ruleId": "D9.AWS.LOG.05",
        "category": "Baseline"
    },
    {
        "name": "Ensure VPC Flow Logging is Enabled in all Applicable Regions (Singapore and North Virginia)",
        "description": "VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. After you've created a flow log, you can view and retrieve its data in Amazon CloudWatch Logs. It is recommended that VPC Flow Logs be enabled. VPC Flow Logs provide visibility into network traffic that traverses the VPC and can be used to detect anomalous traffic or insight during security workflows.",
        "severity": "Low",
        "logic": "Region where(region='ap_southeast_1' or region='us_east_1') and (not vpcs isEmpty()) should have hasVpcFLowLogging='true'",
        "remediation": "\n**From Portal**\n1. Log in to the AWS Management Console at [https://console.aws.amazon.com/]\n2. Select Services and open VPC dashboard.\n3. In the left navigation pane, select Your VPCs.\n4. Select a VPC and open Flow Logs tab In the right pane.\n5. If no Flow Log exists, click Create Flow Log.\n6. Set Filter to Reject.\n7. Enter a Role and Destination Log Group.\n8. Click Create Log Flow.\n9. Click CloudWatch Logs Group.\n10. Perform the above steps for all applicable regions.\n\n**From TF**\n```\nresource \"aws_flow_log\" \"example\" {\niam_role_arn    = \"arn\"\nlog_destination = \"log\"\ntraffic_type    = \"ALL\"\n+ vpc_id          = vpc.id\n}\n\nresource \"aws_vpc\" \"example_vpc\" {\ncidr_block = \"IP_block\"\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\n2. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n3. https://registry.terraform.io/providers/hashicorp/aws/3.1.0/docs/resources/flow_log ",
        "complianceTag": "Logging|Baseline",
        "logicHash": "qCF4FWkfLj6SFfR2I3rXeA",
        "ruleId": "D9.AWS.LOG.14",
        "category": "Baseline"
    },
    {
        "name": "Ensure VPC flow logging is enabled in all VPCs (Singapore and North Virginia)",
        "description": "VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. After you've created a flow log, you can view and retrieve its data in Amazon CloudWatch Logs. VPC Flow Logs provide visibility into network traffic that traverses the VPC and can be used to detect anomalous traffic or insight during security workflows.",
        "severity": "Low",
        "logic": "VPC where (region='ap_southeast_1' or region='us_east_1') should have hasFlowLogs=true",
        "remediation": "\n**From Portal**\nPerform the following to determine if VPC Flow logs is enabled.\n1. Log in to the AWS Management Console at https://console.aws.amazon.com/.\n2. Select Services and open VPC dashboard.\n3. In the left navigation pane, select Your VPCs.\n4. Select a VPC and open Flow Logs tab In the right pane.\n5. If no Flow Log exists, click Create Flow Log.\n6. Set Filter to Reject.\n7. Enter a Role and Destination Log Group.\n8. Click Create Log Flow.\n9. Click CloudWatch Logs Group.\n\n**From TF**\n```\nresource \"aws_vpc\" \"main\" {\ncidr_block = \"10.0.0.0/16\"\n}\n\n+ resource \"aws_flow_log\" \"example\" {\n+    iam_role_arn    = aws_iam_role.example.arn\n+    log_destination = aws_cloudwatch_log_group.example.arn\n+    traffic_type    = \"ALL\"\n+    vpc_id          = aws_vpc.example.id # *** can't be same VPC ***\n+  }\n\n+ resource \"aws_flow_log\" \"example2\" {\n+   iam_role_arn    = aws_iam_role.example.arn\n+   log_destination = aws_cloudwatch_log_group.example.arn\n+   traffic_type    = \"ALL\"\n+   vpc_id          = aws_vpc.example.id\n+ }\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\n2. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n3. https://registry.terraform.io/providers/hashicorp/aws/3.1.0/docs/resources/flow_log\n4. https://workbench.cisecurity.org/benchmarks/679 ",
        "complianceTag": "Logging|Baseline",
        "logicHash": "NbXAGSaTlOAuFyFCYJtJwg",
        "ruleId": "D9.AWS.LOG.22",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for AWS Config configuration changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for detecting changes to CloudTrail's configurations.Monitoring changes to AWS Config configuration will help ensure sustained visibility of configuration items within the AWS account.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventSource = config.amazonaws.com) && (($.eventName=StopConfigurationRecorder)||($.eventName=DeleteDeliveryChannel)||($.eventName=PutDeliveryChannel)||($.eventName=PutConfigurationRecorder))}')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name aws_config_changes_metric --metric-transformations metricName= aws_config_changes_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventSource = config.amazonaws.com) && (($.eventName=StopConfigurationRecorder)||($.eventName=DeleteDeliveryChannel)||($.eventName=PutDeliveryChannel)||($.eventName=PutConfigurationRecorder)) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name aws_config_changes_alarm --metric-name aws_config_changes_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace METRIC_NAMESPACE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387897\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "/wXbj7Q2epO3UtkXgTWyuA",
        "ruleId": "D9.AWS.MON.09",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for AWS Management Console authentication failures",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for failed console authentication attempts. Monitoring failed console logins may decrease lead time to detect an attempt to brute force a credential, which may provide an indicator, such as source IP, that can be used in other event correlation.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = ConsoleLogin) && ($.errorMessage = Failed authentication) }')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name  `console_signin_failure_metric`  --metric-transformations metricName= `console_signin_failure_metric` ,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = ConsoleLogin) && ($.errorMessage = Failed authentication) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name  `console_signin_failure_alarm`  --metric-name  `console_signin_failure_metric`  --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387892\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "avrjhWut3T0ClguNn8uRlA",
        "ruleId": "D9.AWS.MON.06",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for CloudTrail configuration changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for detecting changes to CloudTrail's configurations. Monitoring changes to CloudTrail's configuration will help ensure sustained visibility to activities performed in the AWS account.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = CreateTrail) || ($.eventName = UpdateTrail) ||($.eventName = DeleteTrail) || ($.eventName = StartLogging) || ($.eventName =StopLogging) }')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name `cloudtrail_cfg_changes_metric`  --metric-transformations metricName= `cloudtrail_cfg_changes_metric` ,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventName = CreateTrail) || ($.eventName = UpdateTrail) || ($.eventName = DeleteTrail) || ($.eventName = StartLogging) || ($.eventName = StopLogging) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name `cloudtrail_cfg_changes_alarm` --metric-name  `cloudtrail_cfg_changes_metric` --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387890\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "qtrirEtxV9UZW6m2ppE6BQ",
        "ruleId": "D9.AWS.MON.05",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for IAM policy changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established changes made to Identity and Access Management (IAM) policies.\nMonitoring changes to IAM policies will help ensure authentication and authorization controls remain intact.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventName=DeleteGroupPolicy)||($.eventName=DeleteRolePolicy)||($.eventName=DeleteUserPolicy)||($.eventName=PutGroupPolicy)||($.eventName=PutRolePolicy)||($.eventName=PutUserPolicy)||($.eventName=CreatePolicy)||($.eventName=DeletePolicy)||($.eventName=CreatePolicyVersion)||($.eventName=DeletePolicyVersion)||($.eventName=AttachRolePolicy)||($.eventName=DetachRolePolicy)||($.eventName=AttachUserPolicy)||($.eventName=DetachUserPolicy)||($.eventName=AttachGroupPolicy)||($.eventName=DetachGroupPolicy)||($.eventName=SetDefaultPolicyVersion)||($.eventName=AddUserToGroup)||($.eventName=UpdateAssumeRolePolicy)}')] length() > 0]",
        "remediation": "\nNote: This remediation process assumes SNS topic and log group are already configured.\n\n**From Portal**\n1. Go to 'CloudWatch'\n2. In the menu, under 'Logs', choose 'Log groups' and choose the relevant log group\n3. Press 'Create new metric filter' and add the following 'Filter pattern': '{($.eventName=DeleteGroupPolicy)||($.eventName=DeleteRolePolicy)||($.eventName=DeleteUserPolicy)||($.eventName=PutGroupPolicy)||($.eventName=PutRolePolicy)||($.eventName=PutUserPolicy)||($.eventName=CreatePolicy)||($.eventName=DeletePolicy)||($.eventName=CreatePolicyVersion)||($.eventName=DeletePolicyVersion)||($.eventName=AttachRolePolicy)||($.eventName=DetachRolePolicy)||($.eventName=AttachUserPolicy)||($.eventName=DetachUserPolicy)||($.eventName=AttachGroupPolicy)||($.eventName=DetachGroupPolicy)||($.eventName=SetDefaultPolicyVersion)||($.eventName=AddUserToGroup)||($.eventName=UpdateAssumeRolePolicy)}'\n4. Review and create the new metric filter\n5. In the menu, under 'Alarms', choose 'All alarms' and choose the relevant log group\n6. Press 'Create alarm' and choose the relevant metric and press 'Next'\n7. Under 'Metric', make sure 'Statistic' is set to 'Sum'\n8. Under 'Conditions', make sure the threshold type is set to 'Static', an alarm condition is set to 'Greater/Equal' and the threshold value is set to '1'\n9. Configure your SNS topic under 'Notification'\n10. Create the alarm\n\n**From TF**\nCreate a new CloudWatch metric filter:\n```\nresource \"aws_cloudwatch_log_metric_filter\" \"metric_filter_example\" {\n..\nname             = \"FILTER-NAME\"\npattern          = \"{($.eventName=DeleteGroupPolicy)||($.eventName=DeleteRolePolicy)||($.eventName=DeleteUserPolicy)||($.eventName=PutGroupPolicy)||($.eventName=PutRolePolicy)||($.eventName=PutUserPolicy)||($.eventName=CreatePolicy)||($.eventName=DeletePolicy)||($.eventName=CreatePolicyVersion)||($.eventName=DeletePolicyVersion)||($.eventName=AttachRolePolicy)||($.eventName=DetachRolePolicy)||($.eventName=AttachUserPolicy)||($.eventName=DetachUserPolicy)||($.eventName=AttachGroupPolicy)||($.eventName=DetachGroupPolicy)||($.eventName=SetDefaultPolicyVersion)||($.eventName=AddUserToGroup)||($.eventName=UpdateAssumeRolePolicy)}\"\nlog_group_name   = \"LOG-GROUP-NAME\"\n\nmetric_transformation {\nname      = \"METRIC-NAME\"\nnamespace = \"NAMESPACE-NAME\"\nvalue     = \"1\"\n..\n}\n}\n```\nCreate a new CloudWatch metric alarm:\n```\nresource \"aws_cloudwatch_metric_alarm\" \"metric_alarm_example\" {\n..\nalarm_name            = \"ALARM-NAME\"\ncomparison_operator   = \"GreaterThanOrEqualToThreshold\"\nevaluation_periods    = \"1\"\nmetric_name           = \"METRIC-NAME\"\nnamespace             = \"NAMESPACE-NAME\"\nperiod                = \"PERIOD\"\nstatistic             = \"Sum\"\nthreshold             = \"1\"\nalarm_actions         = [\"SNS-TOPIC-ARN\"]\n..\n}\n```\n\n**From Command Line**\nCreate a new CloudWatch metric filter:\n```\naws logs put-metric-filter --region REGION --log-group-name LOG-GROUP-NAME --filter-name FILTER-NAME --filter-pattern '{($.eventName=DeleteGroupPolicy)||($.eventName=DeleteRolePolicy)||($.eventName=DeleteUserPolicy)||($.eventName=PutGroupPolicy)||($.eventName=PutRolePolicy)||($.eventName=PutUserPolicy)||($.eventName=CreatePolicy)||($.eventName=DeletePolicy)||($.eventName=CreatePolicyVersion)||($.eventName=DeletePolicyVersion)||($.eventName=AttachRolePolicy)||($.eventName=DetachRolePolicy)||($.eventName=AttachUserPolicy)||($.eventName=DetachUserPolicy)||($.eventName=AttachGroupPolicy)||($.eventName=DetachGroupPolicy)||($.eventName=SetDefaultPolicyVersion)||($.eventName=AddUserToGroup)||($.eventName=UpdateAssumeRolePolicy)}' --metric-transformations metricName=METRIC-NAME,metricNamespace=METRIC-NAMESPACE,metricValue=1\n```\nCreate a new CloudWatch metric alarm:\n```\naws cloudwatch put-metric-alarm --region REGION --alarm-name ALARM-NAME --metric-name METRIC-NAME --statistic Sum --period PERIOD --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE --alarm-actions SNS-TOPIC-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateMetricFilterProcedure.html\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ConsoleAlarms.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/put-metric-filter.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/put-metric-alarm.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_log_metric_filter\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm\n7. https://docs.aws.amazon.com/IAM/latest/APIReference/API_Operations.html\n8. CIS AWS Foundations Benchmark: https://workbench.cisecurity.org/benchmarks/679 ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "rNxA7MdGOzs/WsXoEr4TTg",
        "ruleId": "D9.AWS.MON.04",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for Management Console sign-in without MFA",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Monitoring for single-factor console logins will increase visibility into accounts that are not protected by MFA.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [ hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = ConsoleLogin) && ($.additionalEventData.MFAUsed != Yes) }') or filterPattern isFilterPatternEqual('{ $.userIdentity.sessionContext.attributes.mfaAuthenticated != true }')] ] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.3.0: https://workbench.cisecurity.org/benchmarks/679\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided which checks for AWS Management Console sign-in without MFA and the cloudtrail_log_group_name. Use following command:\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name no_mfa_console_signin_metric --metric-transformations metricName= no_mfa_console_signin_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventName = ConsoleLogin) && ($.additionalEventData.MFAUsed != Yes) }'\n```\nNote: You can use below command to reduce false positives incase Single Sign-On (SSO) is used in organization:\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name  no_mfa_console_signin_metric --metric-transformations metricName= no_mfa_console_signin_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventName = ConsoleLogin) && ($.additionalEventData.MFAUsed != Yes) && ($.userIdentity.type = IAMUser) && ($.responseElements.ConsoleLogin = Success) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n```\naws cloudwatch put-metric-alarm --alarm-name no_mfa_console_signin_alarm --metric-name no_mfa_console_signin_metric  --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace METRIC_NAMESPACE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387884\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "ivL611FueFugX4S9c8LJCA",
        "ruleId": "D9.AWS.MON.02",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for S3 bucket policy changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for changes to S3 bucket policies. Monitoring changes to S3 bucket policies may reduce time to detect and correct permissive policies on sensitive S3 buckets.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventSource = s3.amazonaws.com) && (($.eventName = PutBucketAcl) || ($.eventName = PutBucketPolicy) || ($.eventName = PutBucketCors) ||($.eventName = PutBucketLifecycle) || ($.eventName = PutBucketReplication) ||($.eventName = DeleteBucketPolicy) || ($.eventName = DeleteBucketCors) || ($.eventName= DeleteBucketLifecycle) || ($.eventName = DeleteBucketReplication)) }')]length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name  `s3_bucket_policy_changes_metric`  --metric-transformations metricName= `s3_bucket_policy_changes_metric` ,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{ ($.eventSource = s3.amazonaws.com) && (($.eventName = PutBucketAcl) || ($.eventName = PutBucketPolicy) || ($.eventName = PutBucketCors) || ($.eventName = PutBucketLifecycle) || ($.eventName = PutBucketReplication) || ($.eventName = DeleteBucketPolicy) || ($.eventName = DeleteBucketCors) || ($.eventName = DeleteBucketLifecycle) || ($.eventName = DeleteBucketReplication)) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name  `s3_bucket_policy_changes_alarm`  --metric-name  `s3_bucket_policy_changes_metric`  --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387895\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "UiW4MYzMcM6hyzZ2dwIfjg",
        "ruleId": "D9.AWS.MON.08",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for VPC changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is possible to have more than 1 VPC within an account, in addition it is also possible to create a peer connection between 2 VPCs enabling network traffic to route between VPCs. It is recommended that a metric filter and alarm be established for changes made to VPCs.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = CreateVpc) || ($.eventName =DeleteVpc) || ($.eventName =ModifyVpcAttribute) ||($.eventName = AcceptVpcPeeringConnection) || ($.eventName = CreateVpcPeeringConnection) || ($.eventName = DeleteVpcPeeringConnection) || ($.eventName = RejectVpcPeeringConnection) || ($.eventName = AttachClassicLinkVpc) || ($.eventName = DetachClassicLinkVpc) || ($.eventName = DisableVpcClassicLink) || ($.eventName = EnableVpcClassicLink) }')]] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name vpc_changes_metric --metric-transformations metricName= vpc_changes_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventName = CreateVpc) || ($.eventName = DeleteVpc) || ($.eventName = ModifyVpcAttribute) || ($.eventName = AcceptVpcPeeringConnection) || ($.eventName = CreateVpcPeeringConnection) || ($.eventName = DeleteVpcPeeringConnection) || ($.eventName = RejectVpcPeeringConnection) || ($.eventName = AttachClassicLinkVpc) || ($.eventName = DetachClassicLinkVpc) || ($.eventName = DisableVpcClassicLink) || ($.eventName = EnableVpcClassicLink) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name vpc_changes_alarm --metric-name vpc_changes_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE_VALUE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387907\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "nssQ7UvCMv7Som8MWJS1mA",
        "ruleId": "D9.AWS.MON.14",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for changes to Network Access Control Lists (NACL)",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. NACLs are used as a stateless packet filter to control ingress and egress traffic for subnets within a VPC. It is recommended that a metric filter and alarm be established for changes made to NACLs. Monitoring changes to NACLs will help ensure that AWS resources and services are not unintentionally exposed.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = CreateNetworkAcl) || ($.eventName = CreateNetworkAclEntry) || ($.eventName = DeleteNetworkAcl) || ($.eventName =DeleteNetworkAclEntry) || ($.eventName = ReplaceNetworkAclEntry) || ($.eventName = ReplaceNetworkAclAssociation) }')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name nacl_changes_metric --metric-transformations metricName= nacl_changes_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventName = CreateNetworkAcl) || ($.eventName = CreateNetworkAclEntry) || ($.eventName = DeleteNetworkAcl) || ($.eventName = DeleteNetworkAclEntry) || ($.eventName = ReplaceNetworkAclEntry) || ($.eventName = ReplaceNetworkAclAssociation) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name nacl_changes_alarm --metric-name nacl_changes_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE_VALUE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387901\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "YbrFxpfY3DRouLKlaiNdog",
        "ruleId": "D9.AWS.MON.11",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for changes to network gateways",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Network gateways are required to send/receive traffic to a destination outside of a VPC. It is recommended that a metric filter and alarm be established for changes to network gateways. Monitoring changes to network gateways will help ensure that all ingress/egress traffic traverses the VPC border via a controlled path.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [ hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = CreateCustomerGateway) || ($.eventName = DeleteCustomerGateway) || ($.eventName = AttachInternetGateway) || ($.eventName = CreateInternetGateway) || ($.eventName = DeleteInternetGateway) || ($.eventName = DetachInternetGateway) }')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name network_gw_changes_metric --metric-transformations metricName= network_gw_changes_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventName = CreateCustomerGateway) || ($.eventName = DeleteCustomerGateway) || ($.eventName = AttachInternetGateway) || ($.eventName = CreateInternetGateway) || ($.eventName = DeleteInternetGateway) || ($.eventName = DetachInternetGateway) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name network_gw_changes_alarm --metric-name network_gw_changes_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE_VALUE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387903\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "A+/vhHvzhyaS2buGrf/rHg",
        "ruleId": "D9.AWS.MON.12",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for disabling or scheduled deletion of customer created CMKs",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for customer created CMKs which have changed state to disabled or scheduled deletion. Data encrypted with disabled or deleted keys will no longer be accessible.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventSource = kms.amazonaws.com) && (($.eventName=DisableKey)||($.eventName=ScheduleKeyDeletion))}')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name  `disable_or_delete_cmk_changes_metric`  --metric-transformations metricName= `disable_or_delete_cmk_changes_metric` ,metricNamespace='CISBenchmark',metricValue=1 --filter-pattern '{($.eventSource = kms.amazonaws.com) && (($.eventName=DisableKey)||($.eventName=ScheduleKeyDeletion)) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name  `disable_or_delete_cmk_changes_alarm`  --metric-name  `disable_or_delete_cmk_changes_metric`  --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'CISBenchmark' --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387893\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "Da7h6lmr/hVVSdH9SGvCbA",
        "ruleId": "D9.AWS.MON.07",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for route table changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Routing tables are used to route network traffic between subnets and to network gateways. It is recommended that a metric filter and alarm be established for changes to route tables. Monitoring changes to route tables will help ensure that all VPC traffic flows through an expected path.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = CreateRoute) || ($.eventName = CreateRouteTable) || ($.eventName = ReplaceRoute) || ($.eventName = ReplaceRouteTableAssociation) || ($.eventName = DeleteRouteTable) || ($.eventName = DeleteRoute) || ($.eventName = DisassociateRouteTable) }')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name  route_table_changes_metric --metric-transformations metricName= route_table_changes_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventName = CreateRoute) || ($.eventName = CreateRouteTable) || ($.eventName = ReplaceRoute) || ($.eventName = ReplaceRouteTableAssociation) || ($.eventName = DeleteRouteTable) || ($.eventName = DeleteRoute) || ($.eventName = DisassociateRouteTable) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name route_table_changes_alarm --metric-name route_table_changes_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE_VALUE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387905\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "iyrOlVFUD9vRT8n/U0rMxQ",
        "ruleId": "D9.AWS.MON.13",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for security group changes",
        "description": "Monitoring changes to security group will help ensure that resources and services are not unintentionally exposed. ",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual ('{($.eventName = AuthorizeSecurityGroupIngress) || ($.eventName = AuthorizeSecurityGroupEgress) || ($.eventName = RevokeSecurityGroupIngress) || ($.eventName = RevokeSecurityGroupEgress) || ($.eventName = CreateSecurityGroup) || ($.eventName = DeleteSecurityGroup)}')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name security_group_changes_metric --metric-transformations metricName= security_group_changes_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filter-pattern { ($.eventName = AuthorizeSecurityGroupIngress) || ($.eventName = AuthorizeSecurityGroupEgress) || ($.eventName = RevokeSecurityGroupIngress) || ($.eventName = RevokeSecurityGroupEgress) || ($.eventName = CreateSecurityGroup) || ($.eventName = DeleteSecurityGroup) }\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name security_group_changes_alarm --metric-name  security_group_changes_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE_VALUE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387899\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "sO7cmN5wguWDxX2hW/6BRQ",
        "ruleId": "D9.AWS.MON.10",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for unauthorized API calls",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for unauthorized API calls. Monitoring unauthorized API calls will help reveal application errors and may reduce time to detect malicious activity.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{(($.errorCode=\"*UnauthorizedOperation\") || ($.errorCode=\"AccessDenied*\")) && (($.sourceIPAddress!=\"delivery.logs.amazonaws.com\") && ($.eventName!=\"HeadBucket\"))}')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.3.0: https://workbench.cisecurity.org/benchmarks/679\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\n\n1. Create a metric filter based on filter pattern relevant for this check. Run following commands.\n```\naws logs put-metric-filter --region REGION_NAME --log-group-name NAME_OF_LOG_GROUP --filter-name  AWSAuthorizationFailures --filter-pattern ADD_FILTER_PATTERN --metric-transformations metricName=AuthorizationFailureCount,metricNamespace=CloudTrailMetrics,metricValue=1\n```\n2. Create an SNS topic that the alarm will notify\n```\naws sns create-topic --name SNS_TOPIC_NAME\n```\n\n3. Create an SNS subscription to the topic created in step 2\n```\naws sns subscribe --topic-arn sns_topic_arn from step 2 --protocol PROTOCOL_FOR_SNS --notification-endpoint SNS_SUBSCRIPTION_ENDPOINT\n```\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n```\naws cloudwatch put-metric-alarm --alarm-name  UNAUTHORIZED_API_CALLS_ALARM  --metric-name  UNAUTHORIZED_API_CALLS_METRIC  --statistic SUM --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace CISBenchmark --alarm-actions sns_topic_arn\n```\n**References**\n1. CIS Amazon Web Services Foundations Benchmark v1.3.0 - https://workbench.cisecurity.org/benchmarks/679\n2. Count Log Events - https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CountingLogEventsExample.html",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "RlVY3Ca9SEKCuum63uloaQ",
        "ruleId": "D9.AWS.MON.01",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exist for usage of 'root' account",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for root login attempts. Monitoring for root account logins will provide visibility into the use of a fully privileged account and an opportunity to reduce the use of it.\nNote: Government cloud accounts do not have a root user, and so, should exclude this rule in the CloudGuard UI -> Posture Management -> Exclusions -> Create New Exclusion (for each relevant ruleset)",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ $.userIdentity.type = Root && $.userIdentity.invokedBy NOT EXISTS && $.eventType != AwsServiceEvent }')] length() > 0]",
        "remediation": "\n**From Portal**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check. For More details, refer to CIS Amazon Web Services Foundations Benchmark v1.5.0: https://workbench.cisecurity.org/benchmarks/7366\n2. Create an SNS topic that the alarm will notify\n3. Create an SNS subscription to the topic created in step 2\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided and CloudWatch log group.\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name root_usage_metric --metric-transformations metricName=root_usage_metric ,metricNamespace=METRIC_NAMESPACE,metricValue=1 --filterpattern '{ $.userIdentity.type = Root && $.userIdentity.invokedBy NOT EXISTS && $.eventType != AwsServiceEvent }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify.\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2.\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n```\naws cloudwatch put-metric-alarm --alarm-name root_usage_alarm --metric-name root_usage_metric --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace METRIC_NAMESPACE --alarm-actions sns_topic_arn\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/844440/recommendations/1387886\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n4. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html ",
        "complianceTag": "Monitoring|Baseline",
        "logicHash": "TzjjandyFJPFzq+EecCI9A",
        "ruleId": "D9.AWS.MON.03",
        "category": "Baseline"
    },
    {
        "name": "Ensure a log metric filter and alarm exists for AWS Organizations changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for AWS Organizations changes made in the master AWS Account.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventSource = organizations.amazonaws.com) && (($.eventName = \"AcceptHandshake\") || ($.eventName = \"AttachPolicy\") || ($.eventName = \"CreateAccount\") || ($.eventName = \"CreateOrganizationalUnit\") || ($.eventName = \"CreatePolicy\") || ($.eventName = \"DeclineHandshake\") || ($.eventName = \"DeleteOrganization\") || ($.eventName = \"DeleteOrganizationalUnit\") || ($.eventName = \"DeletePolicy\") || ($.eventName = \"DetachPolicy\") || ($.eventName = \"DisablePolicyType\") || ($.eventName = \"EnablePolicyType\") || ($.eventName = \"InviteAccountToOrganization\") || ($.eventName = \"LeaveOrganization\") || ($.eventName = \"MoveAccount\") || ($.eventName = \"RemoveAccountFromOrganization\") || ($.eventName = \"UpdatePolicy\") || ($.eventName = \"UpdateOrganizationalUnit\")) }')]] length() > 0]",
        "remediation": "\n**From Portal**\nA. To create a metric filter using the CloudWatch console\n1. Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.\n2. In the navigation pane, choose Log groups.\n3. Choose the name of the log group.\n4. Choose Actions, Create metric filter.\n5. For Filter pattern, enter the filter pattern to use:\n{ ($.eventSource = organizations.amazonaws.com) && (($.eventName = \"AcceptHandshake\") || ($.eventName = \"AttachPolicy\") || ($.eventName = \"CreateAccount\") || ($.eventName = \"CreateOrganizationalUnit\") || ($.eventName = \"CreatePolicy\") || ($.eventName = \"DeclineHandshake\") || ($.eventName = \"DeleteOrganization\") || ($.eventName = \"DeleteOrganizationalUnit\") || ($.eventName = \"DeletePolicy\") || ($.eventName = \"DetachPolicy\") || ($.eventName = \"DisablePolicyType\") || ($.eventName = \"EnablePolicyType\") || ($.eventName = \"InviteAccountToOrganization\") || ($.eventName = \"LeaveOrganization\") || ($.eventName = \"MoveAccount\") || ($.eventName = \"RemoveAccountFromOrganization\") || ($.eventName = \"UpdatePolicy\") || ($.eventName = \"UpdateOrganizationalUnit\")) }\n6. Choose Next, and then enter a name for the filter.\n7. Under Metric details, for Metric namespace, enter a name for the CloudWatch namespace where the metric will be published. If this namespace doesn't already exist, be sure that Create new is selected.\n8. For Metric name, enter a name for the new metric.\n9. For Metric value, if your metric filter is counting occurrences of the keywords in the filter, enter 1.\n10. Choose Create metric filter.\n\nB. Create an SNS topic that the alarm will notify here: https://ap-south-1.console.aws.amazon.com/sns\n\nC. Create an SNS subscription to the topic created in step B here: https://ap-south-1.console.aws.amazon.com/sns\n\nD. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step A and an SNS topic created in step B here: https://ap-south-1.console.aws.amazon.com/cloudwatch\n\n**From TF**\nTo create log metric filter for AWS Organization changes:\n```\nresource \"aws_cloudwatch_log_metric_filter\" \"yada\" {\nname           = NAME\npattern        = RELEVANT-FILTER-PATTERN\nlog_group_name = LOG-GROUP-NAME\n...\n}\n```\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern provided which checks for AWS Organizations changes and the LOG-GROUP-NAME\n```\naws logs put-metric-filter --log-group-name LOG-GROUP-NAME --filter-name FILTER-NAME --metric-transformations metricName=METRIC-NAME,metricNamespace=METRIC-NAMESPACE,metricValue=1 --filter-pattern '{ ($.eventSource = organizations.amazonaws.com) && (($.eventName = \"AcceptHandshake\") || ($.eventName = \"AttachPolicy\") || ($.eventName = \"CreateAccount\") || ($.eventName = \"CreateOrganizationalUnit\") || ($.eventName = \"CreatePolicy\") || ($.eventName = \"DeclineHandshake\") || ($.eventName = \"DeleteOrganization\") || ($.eventName = \"DeleteOrganizationalUnit\") || ($.eventName = \"DeletePolicy\") || ($.eventName = \"DetachPolicy\") || ($.eventName = \"DisablePolicyType\") || ($.eventName = \"EnablePolicyType\") || ($.eventName = \"InviteAccountToOrganization\") || ($.eventName = \"LeaveOrganization\") || ($.eventName = \"MoveAccount\") || ($.eventName = \"RemoveAccountFromOrganization\") || ($.eventName = \"UpdatePolicy\") || ($.eventName = \"UpdateOrganizationalUnit\")) }'\n```\n2. Create an SNS topic that the alarm will notify:\n```\naws sns create-topic --name SNS-TOPIC-NAME\n```\n3. Create an SNS subscription to the topic created in step 2:\n```\naws sns subscribe --topic-arn SNS-TOPIC-ARN --protocol PROTOCOL --notification-endpoint SNS-ENDPOINT\n```\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2:\n```\naws cloudwatch put-metric-alarm --alarm-name ALARM-NAME --metric-name METRIC-NAME --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace METRIC-NAMESPACE --alarm-actions SNS-TOPIC-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateMetricFilterProcedure.html\n2. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html\n3. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ConsoleAlarms.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_log_metric_filter\n5. https://docs.aws.amazon.com/cli/latest/reference/logs/put-metric-filter.html",
        "complianceTag": "4.15 | Monitoring|Baseline",
        "logicHash": "2zYqZpAlBOPelbM5Ss12Nw",
        "ruleId": "D9.AWS.MON.24",
        "category": "Baseline"
    },
    {
        "name": "Ensure a support role has been created to manage incidents with AWS Support",
        "description": "AWS provides a support center that can be used for incident notification and response, as well as technical support and customer services. Create an IAM Role to allow authorized users to manage incidents with AWS Support. By implementing least privilege for access control, an IAM Role will require an appropriate IAM Policy to allow Support Center Access in order to manage Incidents with AWS Support.",
        "severity": "Low",
        "logic": "IamPolicy where name='AWSSupportAccess' should not have users isEmpty() and roles isEmpty() and groups isEmpty()",
        "remediation": "\n**From Portal:**\n1. Sign into the AWS console and open the IAM Dashboard.\n2. In the left navigation pane, click Roles and then choose Create Role.\n3. For Role type, choose the Another AWS account.\n4. For Account ID, enter the AWS account ID of the AWS account to which you want to grant access to your resources.\n5. Choose Next: Permissions.\n6. Search for the managed policy AWSSupportAccess.\n7. Select the check box for the AWSSupportAccess managed policy.\n8. Choose Next: Tags.\n9. Choose Next: Review.\n10. For Role name, enter a name for your role. Then click Create role.\n\n**From Command Line:**\n1. Create an IAM role for managing incidents with AWS:\n- Create a trust relationship policy document that allows <iam_user> to manage AWS incidents, and save it locally as /tmp/TrustPolicy.json:\n```\n{\n\"Version\":\"2012-10-17\",\n\"Statement\":[\n{\n\"Effect\":\"Allow\",\n\"Principal\":{\n\"AWS\":\"<iam_user>\"\n},\n\"Action\":\"sts:AssumeRole\"\n}\n]\n}\n```\n2. Create the IAM role using the above trust policy:\n```\naws iam create-role --role-name aws_support_iam_role --assume-role-policy-document file:///tmp/TrustPolicy.json\n```\n3. Attach 'AWSSupportAccess' managed policy to the created IAM role:\n```\naws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AWSSupportAccess --role-name aws_support_iam_role\n```\nReferences:\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html\n4. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html\n5. https://docs.aws.amazon.com/cli/latest/reference/iam/create-user.html\n6. https://docs.aws.amazon.com/cli/latest/reference/iam/attach-role-policy.html\n7. https://docs.aws.amazon.com/cli/latest/reference/iam/create-role.html\n8. https://workbench.cisecurity.org/benchmarks/679 ",
        "complianceTag": "1.17 | Identity and Access Management|Baseline",
        "logicHash": "NFoJMkFFcqlvNL1VESSzmg",
        "ruleId": "D9.AWS.IAM.25",
        "category": "Baseline"
    },
    {
        "name": "Ensure credentials unused for 90 days or greater are disabled (Console password)",
        "description": "AWS IAM users can access AWS resources using different types of credentials, such as passwords or access keys. It is recommended that all credentials that have been unused in 90 or greater days be deactivated or removed.\nDisabling or removing unnecessary credentials will reduce the window of opportunity for credentials associated with a compromised or abandoned account to be used.",
        "severity": "Low",
        "logic": "IamUser where passwordEnabled='true' should have passwordLastUsed after(-90, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Click on Security Credentials\n6. In section Sign-in credentials, Console password click Manage\n7. Under Console Access select Disable\n8. Click Apply\n\n**From Command Line**\nTo disable an IAM User console password, run:\n```\naws iam delete-login-profile --user-name USER-NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_finding-unused.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-login-profile.html\n",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "PSG3VeFeD/LuNQ7xAwYXgg",
        "ruleId": "D9.AWS.IAM.04",
        "category": "Baseline"
    },
    {
        "name": "Ensure multi-factor authentication (MFA) is enabled for all IAM users that have a console password",
        "description": "Multi-Factor Authentication (MFA) adds an extra layer of protection on top of a username and password. With MFA enabled, when a user signs in to an AWS  website, they will be prompted for their username and password as well as for an authentication code from their AWS MFA device. It is recommended to enabe MFA for all accounts that have a console password. Enabling MFA provides increased security for console access as it requires the authenticating principal to possess a device that emits a time-sensitive key and have knowledge of a credential.",
        "severity": "Low",
        "logic": "IamUser where passwordEnabled='true' should have mfaActive='true'",
        "remediation": "\n**From Portal**\nPerform the following steps to enable MFA:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/\n2. In the navigation pane, choose Users.\n3. In the User Name list, choose the name of the intended MFA user.\n4. Choose the Security Credentials tab, and then choose Manage MFA Device.\n5. In the Manage MFA Device wizard, choose A virtual MFA device, and then choose Next Step.\nNote: IAM generates and displays configuration information for the virtual MFA device, including a QR code graphic. The graphic is a representation of the 'secret configuration key' that is available for manual entry on devices that do not support QR codes.\n6. Open your virtual MFA application. (For a list of apps that you can use for hosting virtual MFA devices, see Virtual MFA Applications.) If the virtual MFA application supports multiple accounts (multiple virtual MFA devices), choose the option to create a new account (a new virtual MFA device).\n7. Determine whether the MFA app supports QR codes, and then do one of the following:\n7.1 Use the app to scan the QR code. For example, you might choose the camera icon or choose an option similar to Scan code, and then use the device's camera to scan the code.\n7.2 In the Manage MFA Device wizard, choose Show secret key for manual configuration, and then type the secret configuration key into your MFA application. When you are finished, the virtual MFA device starts generating one-time passwords.\n8. In the Manage MFA Device wizard, in the Authentication Code 1 box, type the one-time password that currently appears in the virtual MFA device. Wait up to 30 seconds for the device to generate a new one-time password. Then type the second one-time password into the Authentication Code 2 box. Choose Active Virtual MFA.\n\n**From Command Line**\n1.\tFirst of all we need to create the virtual MFA device.\n```\naws iam create-virtual-mfa-device --virtual-mfa-device-name MFA_DEVICE_NAME --outfile FILENAME.PNG --bootstrap-method QRCodePNG\n```\n2.\tSync your mobile device with the desired MFA authenticator.\nNote: You need to open Authenticator app and scan the QRCode generated from above step.\n\n3.\tGenerate two authentication codes with the MFA authenticator, Note down the codes and use those in below command.\n\n4.\tNext step is to enable the virtual MFA device for user using the two MFA codes generated in previous step.\n```\naws iam enable-mfa-device --user-name USER_NAME --serial-number MFA_DEVICE_ARN --authentication-code1 ENTER CODE1 --authentication-code2 ENTER CODE2\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/43739/recommendations/115378\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#enable-mfa-for-privileged-users\n4. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "mkw5QPVL/sfHn1ZCnIhxLw",
        "ruleId": "D9.AWS.IAM.02",
        "category": "Baseline"
    },
    {
        "name": "Ensure only usable Customer Managed Keys are in the AWS KMS",
        "description": "CMKs are enabled by default. If you disable a CMK, or schedule it for deletion, it becomes unusable, and cannot be used to encrypt or decrypt data. It is recommended to remove all the KMS Customer Managed Keys (CMKs) that are not usable to ensure proper key management process and to lower your monthly AWS bill.",
        "severity": "Low",
        "logic": "KMS where isCustomerManaged=true should not have keyState='Disabled' or keyState='PendingDeletion'",
        "remediation": "\n**From Portal**\nUse following steps to enable KMS CMKs which are disabled:\n1. Sign into the AWS console\n2. In the console, select the specific region\n3. Navigate to Key Management Service (KMS)\n4. Click 'Customer managed keys' (Left Panel)\n5. Select reported KMS Customer managed key\n6. Click 'Key actions' dropdown\n7. Click 'Enable'\n\nDelete CMKs only when you are sure that you don't need to use them anymore. If you are not sure, consider disabling the CMK instead of deleting it. To enable KMS CMKs which are scheduled for deletion, perform the following:\n1. Sign into the AWS console\n2. In the console, select the specific region\n3. Navigate to Key Management Service (KMS)\n4. Click 'Customer managed keys' (Left Panel)\n5. Select reported KMS Customer managed key\n6. Click 'Key actions' dropdown\n7. Click 'Cancel key deletion'\n8. Click 'Enable'\n\n**From TF**\nUse following terraform code to enable a KMS key\n```\nresource \"aws_kms_key\" \"example1\" {\nkey_id = \"kms_key_id\"\n+ is_enabled = true\n}\n```\n\n**From Command Line**\nRun following command to cancel the AWS KMS key deletion process (to recover the KMS key scheduled for deletion):\n```\naws kms cancel-key-deletion --region AWS_region_name --key-id kms_key_id\n```\nUse following command to enable a KMS key:\n```\naws kms enable-key --key-id kms_key_id\n```\n\n**References**\n1. https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html\n2. https://docs.aws.amazon.com/kms/latest/developerguide/deleting-keys.html\n3. https://docs.aws.amazon.com/kms/latest/developerguide/enabling-keys.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kms_key\n5. https://docs.aws.amazon.com/cli/latest/reference/kms/schedule-key-deletion.html\n6. https://docs.aws.amazon.com/cli/latest/reference/kms/cancel-key-deletion.html\n7. https://docs.aws.amazon.com/cli/latest/reference/kms/enable-key.html ",
        "complianceTag": "Operational|Baseline",
        "logicHash": "wvo3RhrHt2ROGjxM03s2TA",
        "ruleId": "D9.AWS.OPE.06",
        "category": "Baseline"
    },
    {
        "name": "Ensure security contact information is registered",
        "description": "AWS provides customers with the option of specifying the contact information for account's security team. It is recommended that this information be provided.Specifying security-specific contact information will help ensure that security advisories sent by AWS reach the team in your organization that is best equipped to respond to them.",
        "severity": "Low",
        "logic": "Account should have alternateContacts with [ alternateContactType='SECURITY' ]",
        "remediation": "\n**From Console\n1. Sign in to the AWS Management Console https://console.aws.amazon.com/\n2. Click on your account name at the top right corner of the console.\n3. From the drop-down menu Click My Account\n4. Scroll down to the Alternate Contacts section\n5. Enter contact information in the Security section,Update.\n\n\n**From Command Line**\n1. Use below command to update the alternateContacts\n```\naws account put-alternate-contact [--account-id VALUE] --alternate-contact-type VALUE --email-address VALUE --name VALUE --phone-number VALUE --title VALUE [--cli-input-json VALUE ] [--generate-cli-skeleton VALUE]\n```\nFor example:\n```\naws account put-alternate-contact --alternate-contact-type SECURITY --email-address test@example.com  --name Example --phone-number +1234567890 --title Example\n```\n\n**From TF**\n1. Use resource: aws_account_alternate_contact and update the arguments. Make sure type SECURITY.\n\nresource \"aws_account_alternate_contact\" \"SECURITY\" {\nalternate_contact_type = \"SECURITY\"\nname          = \"Example\"\ntitle         = \"Example\"\nemail_address = \"test@example.com\"\nphone_number  = \"+1234567890\"\n}\n\n**References**\n1. https://docs.aws.amazon.com/accounts/latest/reference/manage-acct-update-contact.html\n2. https://docs.aws.amazon.com/cli/latest/reference/account/put-alternate-contact.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/account_alternate_contact",
        "complianceTag": "Operational|Baseline",
        "logicHash": "D9XczwtDy5kEoOgSzU1a9A",
        "ruleId": "D9.AWS.OPE.22",
        "category": "Baseline"
    },
    {
        "name": "Ensure that all the expired SSL/TLS certificates stored in AWS IAM are removed",
        "description": "\u0e40\u0e23\u0e37\u0e48\u0e2d\u0e07\u0e01\u0e32\u0e23 Enforce \u0e43\u0e19\u0e01\u0e23\u0e13\u0e35\u0e17\u0e35\u0e48 Cert \u0e2b\u0e21\u0e14\u0e2d\u0e32\u0e22\u0e38 Removing expired SSL/TLS certificates prevents accidental invalid certificate usage and is recommended as a best practice.",
        "severity": "Low",
        "logic": "IamServerCertificate should not have expiration before(0, 'days')",
        "remediation": "\n**From Command Line**\nTo list all IAM server certificates, run:\n```\naws iam list-server-certificates\n```\nTo delete an expired IAM server certificate, run:\n```\naws iam delete-server-certificate --server-certificate-name CERTIFICATE-NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://docs.aws.amazon.com/cli/latest/reference/iam/delete-server-certificate.html\n",
        "complianceTag": "1.19 | Encryption and Key Management|Baseline",
        "logicHash": "eRPUO4HUpUjQxUWRi5N/2Q",
        "ruleId": "D9.AWS.CRY.56",
        "category": "Baseline"
    },
    {
        "name": "Ensure the number of private gateways is within the AWS limit for each region",
        "description": "Checks the number of private gateways in each AWS region in your account is not close to the AWS imposed limit.  If the number of gateways approaches the limit in a particular VPC, you will receive an alert. As per AWS recommendation Virtual private gateway per region limit is 5. This policy will trigger an alert if Virtual private gateway per region reached 80% (i.e. 4) of resource availability limit allocated.",
        "severity": "Low",
        "logic": "VPC should not have vpnGateways length()>3",
        "remediation": "\n**From Portal**\n1. Log in to the AWS console.\n2. In the console, select the specific region.\n3. Navigate to VPC Dashboard.\n4. Click 'Virtual Private Gateways'.\n5. Select the Virtual Private Gateway you want to delete, which is not used or required.\n6. Click 'Actions' dropdown.\n7. Click 'Virtual Private Gateway'.\n8. In the 'Delete Virtual Private Gateway' popup dialog, click 'Yes, Delete'\n\nNOTE: If Virtual Private Gateway is already in use it can not be deleted. Make sure to un-associate VPC gateways before deleting it. If existing Virtual Private Gateways are properly associated and exhausted your VPC Virtual Private Gateway limit allocation, you can contact AWS for a service limit increase.\n\n**From Command Line**\nUse following command to delete a VPC gateway:\n```\naws ec2 delete-vpn-gateway --vpn-gateway-id gateway_id\n```\nNote:  You must first detach the virtual private gateway from the VPC. Note that you don't need to delete the virtual private gateway if you plan to delete and recreate the VPN connection between your VPC and your network.\n\n**References**\n1. http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html\n2. https://docs.aws.amazon.com/general/latest/gr/vpc-service.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete-vpn-gateway.html ",
        "complianceTag": "Operational|Baseline",
        "logicHash": "Kp+DAhilBs2vYEDjw3uw5w",
        "ruleId": "D9.AWS.OPE.09",
        "category": "Baseline"
    },
    {
        "name": "Identify unused AWS VPCs",
        "description": "It is recommended to delete these VPCs that do not have resources attached to them to reduce AWS cost.",
        "severity": "Low",
        "logic": "VPC should have subnets length()>=1",
        "remediation": "\n**From Portal**\n1. Log in to the AWS console.\n2. In the console, select the specific region.\n3. Navigate to VPC Dashboard.\n4. Click 'Your VPCs' and select the reported VPC.\n5. If you want to use the reported VPC, associate subnets to the VPC.\n6. If you want to delete the VPC, click 'Actions' and select 'Delete VPC' from the dropdown.\n\n**From Command Line**\nUse following command to delete a unused VPC:\n```\naws ec2 delete-vpc --vpc-id vpc_id\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/working-with-vpcs.html#VPC_Deleting\n2. https://docs.aws.amazon.com/vpc/latest/userguide/working-with-subnets.html\n3. https://docs.aws.amazon.com/prescriptive-guidance/latest/aws-startup-security-baseline/acct-09.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete-vpc.html ",
        "complianceTag": "Operational",
        "logicHash": "h69FXnDx5oMJDB/H6Cw8iw",
        "ruleId": "D9.AWS.OPE.10",
        "category": ""
    },
    {
        "name": "Password Policy must require at least one number",
        "description": "It is recommended that the password policy require at least one number. Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure passwords consist of different character sets. Setting a password complexity policy increases account resiliency against brute force login attempts.",
        "severity": "Low",
        "logic": "Iam should have passwordPolicy.requireNumbers=true",
        "remediation": "\n**From Portal**\nPerform the following to set the password policy as prescribed: Via AWS Console\n1. Login to AWS Console (with appropriate permissions to View Identity Access Management Account Settings)\n2. Go to IAM Service on the AWS Console\n3. Click on Account Settings on the Left Pane\n4. Check 'Require at least one number'\n5. Click 'Apply password policy'\n\n**From TF**\n```\nresource \"aws_iam_account_password_policy\" \"test\" {\nminimum_password_length        = 8\nrequire_lowercase_characters   = true\n+ require_numbers                = true\nrequire_uppercase_characters   = true\nrequire_symbols                = true\nallow_users_to_change_password = true\n}\n```\n**From Command Line**\nTo add a password policy with required condition, run:\n```\naws iam update-account-password-policy --require-numbers\n```\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html\n2. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n3. https://docs.aws.amazon.com/config/latest/developerguide/iam-password-policy.html\n4. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-account-password-policy.html\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_account_password_policy",
        "complianceTag": "Identity and Access Management|Baseline",
        "logicHash": "G3LbqsCtDDlA9JbndVu9QA",
        "ruleId": "D9.AWS.IAM.11",
        "category": "Baseline"
    },
    {
        "name": "ACM has soon to be expired certificates",
        "description": "ACM provides managed renewal for your Amazon-issued SSL/TLS certificates. Check the ACM for soon to be expired certificates. Certificates that will be expired in less than a month, certificates whose the notAfter time has passed but still in status ISSUED",
        "severity": "Informational",
        "logic": "AcmCertificate should have status like 'ISSUED' and notAfter after(30, 'days')",
        "remediation": "\n**From Portal**\nACM provides managed renewal for your Amazon-issued SSL/TLS certificates. This means that ACM will either renew your certificates automatically (if you are using DNS validation) or it will send you email notices when expiration is approaching. These services are provided for both public and private ACM certificates.\n\nUse following steps to renew the expiring certificates.\n1. Login into your AWS account\n2. Navigate to the ACM service at: https://console.aws.amazon.com/acm\n3. Select the certificate that is expiring soon.\n4. Click the Actions button from the dashboard top menu and select Reimport certificate option from the dropdown menu and do the follow actions:\na. For Certificate body*, paste the PEM-encoded certificate to import, purchased from your SSL certificate provider.\nb. For Certificate private key*, paste the PEM-encoded, un-encrypted private key that matches the SSL/TLS certificate public key.\nc. For Certificate chain, paste the PEM-encoded certificate chain delivered with the certificate body specified at step a.\nd. Click Review and import button to continue the process.\n5. On the Review and import page, review the imported certificate details then click Import to confirm the action and complete the renewal process.\n\n**From Command Line**\nRun following command to import and renew the selected AWS ACM certificate (use the certificate ARN that you want to renew).\n```\naws acm import-certificate --certificate-arn imported_certificate_ARN --certificate file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html\n2. https://docs.aws.amazon.com/acm/latest/userguide/troubleshooting.html\n3. https://docs.aws.amazon.com/acm/latest/userguide/managed-renewal.html\n4. https://docs.aws.amazon.com/acm/latest/userguide/manual-renewal.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/import-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "Tslep8nZ3w4p28Tc33tkPw",
        "ruleId": "D9.AWS.CRY.54",
        "category": ""
    },
    {
        "name": "Amazon System Manager Document should not be publicly available",
        "description": "Ensure that your AWS System Manager documents are not publicly exposed (unless it is really necessary!). In case the document has been publicly exposed by accident, make it private immediately. In case the document should be publicly exposed then make sure it does not contain any sensitive information like S3 bucket names, keys, users etc.",
        "severity": "Critical",
        "logic": "SystemManagerDocument should not have accountSharingInfoList contain [ accountId='all' ]",
        "remediation": "\n**From Portal**\nTo block public sharing of your SSM documents\n1. Open the AWS Systems Manager console at https://console.aws.amazon.com/systems-manager/.\n2. In the navigation pane, choose Documents.\n-or- If the AWS Systems Manager home page opens first, choose the menu icon to open the navigation pane, and then choose Documents in the navigation pane.\n3. Choose Preferences, and then choose Edit in the Block public sharing section.\n4. Select the Block public sharing check box, and then choose Save.\n\n**From TF**\nThe permissions attribute specifies how you want to share the document. If you share a document privately, you must specify the AWS user account IDs for those people who can use the document. If you share a document publicly, you must specify All as the account ID.\n```\nresource \"aws_ssm_document\" \"example\" {\nname          = \"document_name\"\ndocument_format = \"YAML\"\ndocument_type = \"value\"\n\npermissions {\ntype = \"Share\"\n\n# use AWS user accounts ID who can use the document\naccount_ids = \"AWSuser_account_id\"\n}\n```\n\n**From Command Line**\n1. Run following command to block public sharing of your SSM documents.\n```\naws ssm update-service-setting --setting-id service_setting_id --setting-value Disable --region AWS_Region (you want to block public sharing in)\n```\n2. Configure your AWS System Manager document to be private by running the following command:\n```\naws ssm modify-document-permission --name Document_Name --permission-type Share --account-ids-to-remove All\n```\n3. In case you would like to share with specific AWS accounts, run the following command:\n```\naws ssm modify-document-permission --name Document_Name --permission-type Share --account-ids-to-add AWS_account_id\n```\n\n**References**\n1. https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-share-block.html\n2. https://docs.aws.amazon.com/cli/latest/reference/ssm/update-service-setting.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ssm/modify-document-permission.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ssm_document\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ssm_document#account_ids\n6. https://github.com/hashicorp/terraform-provider-aws/issues/5308 ",
        "complianceTag": "Vulnerability and Threat Management",
        "logicHash": "gapWU/GhLJl4EcFpVmEdQQ",
        "ruleId": "D9.AWS.VLN.04",
        "category": ""
    },
    {
        "name": "EksCluster should not be publicly accessed",
        "description": "Allowing your EksCluster Public access leave you asset expose for attacks",
        "severity": "Critical",
        "logic": "EksCluster should not have resourcesVpcConfig.endpointPublicAccess=true or resourcesVpcConfig.endpointPrivateAccess=false",
        "remediation": "\n**From Portal:**\n1. Log in to the AWS Management Console.\n2. Open the Amazon EKS service.\n3. Choose the name of the cluster to display your cluster information.\n4. Under Networking, click 'Manage networking'.\n5. For Private access, choose 'Private'.\n6. Save the changes.\n\n**From TF:**\n```\nresource \"aws_eks_cluster\" \"example1\" {\nname     = \"example\"\nrole_arn = \"aws_iam_role.arn\"\n\nvpc_config {\nsubnet_ids = [\"subnet_id\"]\n\nendpoint_public_access = False\n}\n}\n```\n\n**From Command Line:**\n```\naws eks update-cluster-config --region region-code --name my-cluster --resources-vpc-config endpointPublicAccess=false,endpointPrivateAccess=true\n```\n\nReferences:\n1. https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster#endpoint_public_access\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/eks/update-cluster-config.html ",
        "complianceTag": "Network Security",
        "logicHash": "jMAM4iL5DUQY67ixAiK6ag",
        "ruleId": "D9.AWS.NET.71",
        "category": ""
    },
    {
        "name": "Ensure ACM certificate was not issued before the Heartbleed security bug fix",
        "description": "Ensure that certificates stored in AWS Certificate Manager are not exposed to the Heartbleed security bug (Issued before April 8, 2014).",
        "severity": "Critical",
        "logic": "AcmCertificate where status='ISSUED' should have ( notBefore>1396915200 and issuedAt=-62135596800 ) or issuedAt>1396915200",
        "remediation": "\n**From Portal**\n1. Go to 'Certificate Manager'\n2. Identify certificates that were issued before 'April 8, 2014' (Unix timestamp: 1396915200).\n3. Delete the certificates.\n\n**From TF**\nTo delete an ACM certificate, delete the relevant entity:\n```\nresource \"aws_acm_certificate\" \"example_cert\" {\n...\n}\n```\n\n**From Command Line**\nTo list all ACM certificates, run:\n```\naws acm --region REGION list-certificates\n```\nTo check an ACM certificate issue date, run:\n```\naws acm describe-certificate --region REGION --certificate-arn CERTIFICATE-ARN\n```\nTo delete an ACM certificate, run:\n```\naws acm delete-certificate --region REGION --certificate-arn CERTIFICATE-ARN\n```\n\n**References**\n1. https://heartbleed.com/\n2. https://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/acm_certificate\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/list-certificates.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/describe-certificate.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/delete-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "uLNANfR7edIwA4cmlJQ1gQ",
        "ruleId": "D9.AWS.CRY.59",
        "category": ""
    },
    {
        "name": "Ensure AWS IAM managed policies do not have 'getObject' or full S3 action permissions",
        "description": "Ensuring AWS IAM managed policies do not have 'getObject' or full S3 action permissions, prevents potential Amazon S3 data exfiltration or manipulation.",
        "severity": "Critical",
        "logic": "IamPolicy where name regexMatch /AWS/ should not have document.Statement contain [ Effect='Allow' and (Action='S3:*' or Action='s3:getObject') ]",
        "remediation": "\nNote: AWS managed policies cannot be deleted.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Policies'\n3. For each incompliant policy, make sure there are no IAM entities attached to it:\n4. Choose the incompliant policy\n5. Under 'Policy usage', detach any IAM entity attached to it\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified role., run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#aws-managed-policies\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-delete.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-user-policy.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-group-policy.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-role-policy.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "A7DTKfb9wg4dHk+xGESG+Q",
        "ruleId": "D9.AWS.IAM.71",
        "category": ""
    },
    {
        "name": "Ensure AWS Redshift clusters are not publicly accessible",
        "description": "AWS Redshift clusters should not be defined with public interface. Firewall and router configurations should be used to restrict connections between untrusted networks and any system components in the cloud environment.",
        "severity": "Critical",
        "logic": "Redshift should not have isPublic=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console.\n2. In the console, select the specific region.\n3. Navigate to the 'Redshift' service.\n4. Click the identified Redshift cluster name.\n5. In the top menu options, click 'Cluster' and choose 'Actions' as the option.\n6. Click on 'Modify Publicly accessible setting' option.\n7. Choose 'enable' option and click 'save changes'.\n\n**From TF**\n```\nresource \"aws_redshift_cluster\" \"test\" {\ncluster_identifier = \"tf-redshift-cluster\"\ndatabase_name      = \"mydb\"\nmaster_username    = \"foo\"\nmaster_password    = \"Mustbe8characters\"\nnode_type          = \"dc1.large\"\ncluster_type       = \"single-node\"\n+ publicly_accessible = false\n}\n```\n\n**From Command Line**\nTo Disbale 'Publicly-accessible' Run:\n```\naws redshift modify-cluster --region us-east-1 --cluster-identifier redshift-cluster-1 --no-publicly-accessible\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/redshift-cluster-private-public/\n",
        "complianceTag": "Network Security",
        "logicHash": "8Afr2WxkzPaecSDRgfGsww",
        "ruleId": "D9.AWS.NET.51",
        "category": ""
    },
    {
        "name": "Ensure AWS VPC subnets have automatic public IP assignment disabled",
        "description": "A VPC subnet is a part of the VPC, with its own rules for traffic. Subnets with automatic Public IP assignment can inadvertently expose the instances within this subnet to the internet. It is recommended to disable this feature for subnets.",
        "severity": "Critical",
        "logic": "Subnet should not have mapPublicIpOnLaunch=true",
        "remediation": "\n**From Portal**\n1. Log in to the AWS console and open Amazon VPC console https://console.aws.amazon.com/vpc/home.\n2. In the console, select the specific region  .\n3. Navigate to the 'VPC' service.\n4. In the navigation pane, click 'Subnets'.\n5. Select the identified Subnet and click on Actions and Select the option 'Edit subnet settings.\n6. Disable the 'Auto-Assign IP' option and save it.\n\n**From TF**\nTo disable automatic public IP assignment :\n```\nresource \"aws_subnet\" \"main_public_1\" {\n+ map_public_ip_on_launch = false\n- map_public_ip_on_launch = true\n}\n```\n\n**From Command Line**\nTo disable public IP assignment on AWS VPC subnets , run:\n```\naws ec2 modify-subnet-attribute --subnet-id SUBNET-ID --no-map-public-ip-on-launch\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/config/latest/developerguide/subnet-auto-assign-public-ip-disabled.html\n3. https://docs.aws.amazon.com/cli/latest/reference/ec2/modify-subnet-attribute.html",
        "complianceTag": "Network Security",
        "logicHash": "MTVrwqstSz0OqM40oI/9CQ",
        "ruleId": "D9.AWS.NET.47",
        "category": ""
    },
    {
        "name": "Ensure EKS cluster version is up to date",
        "description": "Ensure EKS cluster version is not lower than 1.27",
        "severity": "Informational",
        "logic": "EksCluster should have version split('.') getValue(1) >= 27",
        "remediation": "\n**From Portal**\n1. Login to AWS Console\n2. Navigate to EKS\n3. Select the EKS cluster\n4. Click on 'Update Now'\n\n**From Command Line**\n1.\n```\naws eks update-cluster-version --name EXAMPLE_CLUSTER_NAME --kubernetes-version 1.27\n```\n\n**References**\n1. https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html\n",
        "complianceTag": "Operational",
        "logicHash": "ceKxo0eLtNOkS6ljLMZtTA",
        "ruleId": "D9.AWS.OPE.25",
        "category": ""
    },
    {
        "name": "Ensure IAM server certificate was not uploaded before the Heartbleed security bug fix",
        "description": "Ensure that SSL/TLS server certificates stored in AWS IAM are not exposed to the Heartbleed security bug (Uploaded before April 8, 2014).",
        "severity": "Critical",
        "logic": "IamServerCertificate should not have uploadDate < 1396915200",
        "remediation": "\n**From Command Line**\nTo list all IAM server certificates, run:\n```\naws iam list-server-certificates\n```\n*Ensure no IAM server certificate was uploaded before 'April 8, 2014' (Unix timestamp: 1396915200).\nTo delete an IAM server certificate, run:\n```\naws iam delete-server-certificate --server-certificate-name CERTIFICATE-NAME\n```\n\n**References**\n1. https://heartbleed.com/\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-server-certificates.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-server-certificate.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "NhvkNBJi8Xkl+B02IBtwtw",
        "ruleId": "D9.AWS.CRY.58",
        "category": ""
    },
    {
        "name": "Ensure S3 Bucket exists for A records routing traffic to an S3 Bucket website endpoint",
        "description": "A domain with an A record that directs its traffic to an S3 Bucket website endpoint is exposed to domain takeover - if no matching S3 Bucket exists.",
        "severity": "Critical",
        "logic": "Route53RecordSetGroup where recordSets contain [ aliasTarget.dnsName regexMatch /s3-website/ ] should have getResources('S3Bucket') contain [join('.' , name, '  ') = join(' ' , ~getValue('name'), ' ')]",
        "remediation": "\n**From Portal**\n1. Go to 'Route 53'\n2. In the menu choose 'Hosted zones' and select the relevant domain name\n3. Delete the A record name that routes its traffic to a non-exists S3 Bucket website endpoint\n*Alternative: Create a new S3 Bucket with a name identical to your domain/subdomain\nNote: AWS Route 53 expects the S3 bucket name to be identical to the subdomain\n\n**From TF**\nTo delete the vulnerable A record, remove the relevant Terraform resource:\n```\nresource \"aws_route53_record\" \"route53_record_example\" {\n..\ntype = \"A\"\n..\n}\n```\n\n**From Command Line**\nTo list all hosted zone records sets, use:\n```\naws route53 list-resource-record-sets --hosted-zone-id HOSTED-ZONE-ID\n```\nTo delete a record set, use:\n```\naws route53 change-resource-record-sets --hosted-zone-id HOSTED-ZONE-ID --change-batch CHANGE-BATCH-STRUCTURE\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/rrsets-working-with.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53/list-resource-record-sets.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53/change-resource-record-sets.html\n",
        "complianceTag": "DNS Management",
        "logicHash": "NQEn1tl/cBiBkaZ0oDfmFQ",
        "ruleId": "D9.AWS.DNS.07",
        "category": ""
    },
    {
        "name": "Ensure S3 Bucket exists for CNAME records routing traffic to an S3 Bucket website endpoint",
        "description": "A domain with a CNAME record that directs its traffic to an S3 Bucket website endpoint is exposed to domain takeover - if no matching S3 Bucket exists.",
        "severity": "Critical",
        "logic": "Route53RecordSetGroup where recordSets contain [ records contain [ assetMetadata.type='S3Bucket'] ] should have recordSets contain [ records contain-all [ assetMetadata.type='S3Bucket' and assetMetadata.exists=true] ]",
        "remediation": "\n**From Portal**\n1. Go to 'Route 53'\n2. In the menu choose 'Hosted zones' and select the relevant domain name\n3. Delete the CNAME record name that routes its traffic to a non-exists S3 Bucket website endpoint\n*Alternative: Create a new S3 Bucket with a name identical to your domain/subdomain\nNote: AWS Route 53 expects the S3 bucket name to be identical to the subdomain\n\n**From TF**\nTo delete the vulnerable CNAME record, remove the relevant Terraform resource:\n```\nresource \"aws_route53_record\" \"route53_record_example\" {\n..\ntype = \"CNAME\"\n..\n}\n```\n\n**From Command Line**\nTo list all hosted zone records sets, use:\n```\naws route53 list-resource-record-sets --hosted-zone-id HOSTED-ZONE-ID\n```\nTo delete a record set, use:\n```\naws route53 change-resource-record-sets --hosted-zone-id HOSTED-ZONE-ID --change-batch CHANGE-BATCH-STRUCTURE\n```\n\n**References**\n1. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/rrsets-working-with.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route53_record\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53/list-resource-record-sets.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/route53/change-resource-record-sets.html\n",
        "complianceTag": "DNS Management",
        "logicHash": "Kdra/SEhnGSWXn4iIZTAmg",
        "ruleId": "D9.AWS.DNS.06",
        "category": ""
    },
    {
        "name": "Ensure SNS Topics administrative actions aren't publicly executable without a condition",
        "description": "SNS Topics might contain sensitive information or initiate critical tasks. Determine the specific principals the their required actions, and then craft IAM policy with the required permissions.",
        "severity": "Critical",
        "logic": "SnsTopic should not have policy.Statement contain [Effect='Allow' and (Principal='*' or Principal.AWS='*') and (Action contain-any ['SNS:GetTopicAttributes' or 'SNS:SetTopicAttributes'  or 'SNS:AddPermission' or 'SNS:RemovePermission' or 'SNS:DeleteTopic' or 'SNS:ListSubscriptionsByTopic']) and Condition isEmpty()]",
        "remediation": "\n**From Console**\n1. Open the Amazon SNS console https://console.aws.amazon.com/sns/\n2. In the left navigation pane, choose Topics.\n3. Choose your Amazon SNS topic's name.\n4. Choose the Edit button.\n5. Expand the Access policy - optional section.\n6. Edit the access policy to grant the required permissions for your use case.(You can also use AWS policy generator tool: https://awspolicygen.s3.amazonaws.com/policygen.html)\n7. In the policy When Effect is 'Allow' and Action contains one of the following- 'SNS:GetTopicAttributes' or 'SNS:SetTopicAttributes'  or 'SNS:AddPermission' or 'SNS:RemovePermission' or 'SNS:DeleteTopic' or 'SNS:ListSubscriptionsByTopic' , Make sure you DO NOT mention Principal='*' or Principal.AWS='*' , and add make sure you add a condition in the policy statement.\n8. Choose Save Changes.\n\n**From CLI**\n1. Create a json file with policy statement where, When Effect is 'Allow' and Action contains one of the following- 'SNS:GetTopicAttributes' or 'SNS:SetTopicAttributes'  or 'SNS:AddPermission' or 'SNS:RemovePermission' or 'SNS:DeleteTopic' or 'SNS:ListSubscriptionsByTopic' , Make sure you DO NOT mention Principal='*' or Principal.AWS='*' , and add make sure you add a condition in the policy statement.\n2. Use below CLI Command to update the policy.\n```\naws sns set-topic-attributes --topic-arn TOPIC_ARN --attribute-name policy --attribute-value FILE://UPDATE_ATTRIBUTES.json\n```\n**From CFT**\n1. See below example, When Effect is 'Allow' and Action contains one of the following- 'SNS:GetTopicAttributes' or 'SNS:SetTopicAttributes'  or 'SNS:AddPermission' or 'SNS:RemovePermission' or 'SNS:DeleteTopic' or 'SNS:ListSubscriptionsByTopic' , Make sure you DO NOT mention Principal='*' or Principal.AWS='*' , and add make sure you add a condition in the policy statement.\n```\nResources:\nSampleSNSPolicy:\nType: AWS::SNS::TopicPolicy\nProperties:\nPolicyDocument:\nVersion: '2012-10-17'\nId: __default_policy_ID\nStatement:\n- Sid: __default_statement_ID\nEffect: Allow\nPrincipal:\nAWS: \"111122223333\"\nAction:\n- SNS:GetTopicAttributes\nResource: arn:aws:sns:us-east-2:444455556666:MyTopic\nCondition:\nStringEquals:\nAWS:SourceOwner: '444455556666'\nTopics:\n- \"arn:aws:sns:us-east-2:444455556666:MyTopic\"\n```\n\n**From TF**\n1. See below example, When Effect is 'Allow' and Action contains one of the following- 'SNS:GetTopicAttributes' or 'SNS:SetTopicAttributes'  or 'SNS:AddPermission' or 'SNS:RemovePermission' or 'SNS:DeleteTopic' or 'SNS:ListSubscriptionsByTopic' , Make sure you DO NOT mention Principal='*' or Principal.AWS='*' , and add make sure you add a condition in the policy statement.\n\n```\nresource \"aws_sns_topic_policy\" \"default\" {\narn = \"arn:aws:sns:us-east-2:444455556666:MyTopic\"\npolicy = data.aws_iam_policy_document.sns_topic_policy.json\n}\n\ndata \"aws_iam_policy_document\" \"sns_topic_policy\" {\npolicy_id = \"__default_policy_ID\"\nstatement {\nactions = [\n\"SNS:DeleteTopic\"\n]\ncondition {\ntest     = \"StringEquals\"\nvariable = \"AWS:SourceOwner\"\nvalues = [\n444455556666,\n]\n}\neffect = \"Allow\"\nprincipals {\ntype        = \"AWS\"\nidentifiers = [\"111122223333\"]\n}\nresources = [\narn:aws:sns:us-east-2:444455556666:MyTopic,\n]\nsid = \"__default_statement_ID\"\n}\n}\n```\n**References**\n1. https://docs.aws.amazon.com/sns/latest/dg/sns-access-policy-use-cases.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/set-topic-attributes.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sns_topic_policy\n4. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-sns-policy.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "EuvYhejexzddsvDdgrfpvw",
        "ruleId": "D9.AWS.IAM.58",
        "category": ""
    },
    {
        "name": "Ensure SNS Topics aren't publicly accessible",
        "description": "SNS Topics might contain sensitive information. Determine the specific principals with their required actions, and then craft IAM policy with the required permissions.",
        "severity": "Critical",
        "logic": "SnsTopic where policy.Statement contain [Effect='Allow' and (Principal='*' or Principal.AWS='*')] should have policy.Statement contain [Condition]",
        "remediation": "\n**From Portal**\nPerform the following in order to set a new SNS Topic policy:\n1. Login to AWS Console\n2. Navigate to SNS Service, click on topics\n3. Select the relevant topic and click Edit\n4. Look for \"Access policy\", and edit the policy.\nYou can use AWS policy generator tool: https://awspolicygen.s3.amazonaws.com/policygen.html\n\n**From TF**\n```\nresource \"aws_sns_topic\" \"test\" {\npolicy = <<EOF\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Action\": \"*\",\n\"Principal\": {\n-   \"AWS\": \"*\"\n+   \"AWS\": \"arn:aws:iam::<account_number>:root\"\n},\n\"Effect\": \"Allow\",\n\"Sid\": \"\"\n}]\n}\nEOF\n}\n```\n\n**From Command Line**\n```\naws sns set-topic-attributes --topic-arn Topic_ARN --attribute-name policy --attribute-value File:update_attributes.json\n```\nNote: Where the file should contain the new policy for the topic.\n\n**References**\n1. https://docs.aws.amazon.com/sns/latest/dg/sns-access-policy-use-cases.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/set-topic-attributes.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "mD+y/2SJjVMnHzY66l9OvA",
        "ruleId": "D9.AWS.IAM.57",
        "category": ""
    },
    {
        "name": "Ensure no security groups allow ingress from 0.0.0.0/0 to ALL ports and protocols",
        "description": "Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access",
        "severity": "Critical",
        "logic": "SecurityGroup should not have inboundRules with [ scope='0.0.0.0/0' and portTo=0]",
        "remediation": "Reduce the scope of the inbound rules to just the necessary scope, protocol, and ports.\n\n**From Portal**\n1. Login to the AWS Management Console and open Amazon VPC console https://console.aws.amazon.com/vpc/home\n2. In the navigation pane, choose Security Groups.\n3. For each security group, perform the following:\na. Select the security group\nb. Click the Inbound Rules tab\nc. Identify the rules to be removed or edited\nd. Edit the inbound rule , change the source cidr range or Delete the rule.\n4. Click Save\n\n**From TF**\nAdd CIDR range, port, protocol to restrict ingress access from all port, protocol and range.\n```\nresource \"aws_security_group\" \"test\" {\nname        = \"allow_tls4\"\ndescription = \"Allow TLS inbound traffic\"\n\ningress {\ndescription = \"TLS from VPC\"\nfrom_port   = 3389      # any port number apart from 0\nto_port     = 3389      # any port number apart from 0\n-   protocol    = \"ALL\"\n+   protocol    = \"tcp\"\n-   cidr_blocks = [\"0.0.0.0/0\"]\n+   cidr_blocks = [\"10.92.168.0/28\"]\n}\n}\n```\n**From Command Line**\nTo make sure security groups doesn't allow ingress from 0.0.0.0/0 to all port, run:\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP-NAME --protocol PROTOCOL --port PORT --cidr 0.0.0.0/0\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html?highlight=ingress\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group#ingress",
        "complianceTag": "Network Security",
        "logicHash": "ogk93PrYXDcQN07JVbRFPg",
        "ruleId": "D9.AWS.NET.08",
        "category": ""
    },
    {
        "name": "Ensure no security groups allow ingress from 0.0.0.0/0 to RDP (TCP:3389)",
        "description": "Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to port 3389.",
        "severity": "Critical",
        "logic": "SecurityGroup should not have inboundRules with [scope =  '0.0.0.0/0' and port<=3389 and portTo>=3389]",
        "remediation": "Removing unfettered connectivity to remote console services, such as RDP, reduces a server's exposure to risk.\n**From Portal**\n1. Login to the AWS Management Console and open Amazon VPC console https://console.aws.amazon.com/vpc/home\n2. In the navigation pane, choose Security Groups.\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Inbound Rules tab\n6. Identify the rules to be removed\n7. Edit the inbound rule , change the source cidr range or Delete the rule.\n8. Click Save\n\n**From TF**\nAdd CIDR range to restrict ingress access to port 3389.\n```\nresource \"aws_security_group\" \"test\" {\nname        = \"allow_tls4\"\ndescription = \"Allow TLS inbound traffic\"\n\ningress {\ndescription = \"TLS from VPC\"\nfrom_port   = 3389\nto_port     = 3389\nprotocol    = \"tcp\"\n-   cidr_blocks = [\"0.0.0.0/0\"]\n+   cidr_blocks = [\"10.92.168.0/28\"]\n}\n}\n```\n**From Command Line**\nTo make sure security groups doesn't allow ingress from 0.0.0.0/0 to RDP (TCP:3389), run:\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP-NAME --protocol PROTOCOL --port 3389 --cidr 0.0.0.0/0\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html?highlight=ingress\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group#ingress",
        "complianceTag": "Network Security",
        "logicHash": "34oRmSqy7ajkZ3rTFp1PmQ",
        "ruleId": "D9.AWS.NET.02",
        "category": ""
    },
    {
        "name": "Ensure no security groups allow ingress from 0.0.0.0/0 to SSH (TCP:22)",
        "description": "Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to port 22.",
        "severity": "Critical",
        "logic": "SecurityGroup should not have inboundRules with [scope =  '0.0.0.0/0' and port<=22 and portTo>=22]",
        "remediation": " Removing unfettered connectivity to remote console services, such as SSH, reduces a server's exposure to risk.\n**From Portal**\n1. Login to the AWS Management Console and open Amazon VPC console https://console.aws.amazon.com/vpc/home\n2. In the navigation pane, choose Security Groups.\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Inbound Rules tab\n6. Identify the rules to be removed\n7. Edit the inbound rule , change the source cidr range or Delete the rule.\n8. Click Save\n\n**From TF**\nAdd CIDR range to restrict ingress access to port 22.\n```\nresource \"aws_security_group\" \"test\" {\nname        = \"allow_tls4\"\ndescription = \"Allow TLS inbound traffic\"\n\ningress {\ndescription = \"TLS from VPC\"\nfrom_port   = 22\nto_port     = 22\nprotocol    = \"tcp\"\n-   cidr_blocks = [\"0.0.0.0/0\"]\n+   cidr_blocks = [\"10.92.168.0/28\"]\n}\n}\n```\n**From Command Line**\nTo make sure security groups doesn't allow ingress from 0.0.0.0/0 to SSH (TCP:22), run:\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP-NAME --protocol PROTOCOL --port 22 --cidr 0.0.0.0/0\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html?highlight=ingress\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group#ingress",
        "complianceTag": "Network Security",
        "logicHash": "4gQXr/FUdkD3nfc0k2HekQ",
        "ruleId": "D9.AWS.NET.01",
        "category": ""
    },
    {
        "name": "Ensure no security groups allow ingress from ::/0 to remote server administration ports",
        "description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389.Public access to remote server administration ports, such as 22 and 3389, increases resource attack surface and unnecessarily raises the risk of resource compromise.",
        "severity": "Critical",
        "logic": "SecurityGroup should not have inboundRules with [ (scope='::/0') and ( ( port<=22 and portTo>=22) or ( port<=3389 and portTo>=3389 ) ) ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. In the left pane, click Security Groups\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Inbound Rules tab\n6. Click the Edit inbound rules button\n7. Identify the rules to be edited or removed\n8. Either A) update the Source field to a range other than ::/0, or, B) Click Delete to remove the offending inbound rule\n9. Click Save rules.\n\n**From Command Line**\n1.  List all security groups with an ingress rule of ::/0.\n```\naws ec2 describe-security-groups --filters Name=ip-permission.ipv6-cidr,Values='::/0' --query \"SecurityGroups[*].{Name:GroupName,ID:GroupId}\"\n```\n2. Remove the rule which has port 22 or 3389 when ingress is ::/0.\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --ip-permissions IpProtocol=PROTOCOL,FromPort=PORT,ToPort=PORT,Ipv6Ranges=\"[{CidrIpv6=::/0}]\"\n```\n3. Now add the inbound rules with different parameters, When port is 22 or 3389 set cidr value other than ::/0 e.g. 2001:db8:1234:1a00::/64 or any suitable range.\n```\naws ec2 authorize-security-group-ingress --region REGION --group-name GROUP_NAME --ip-permissions IpProtocol=PROTOCOL,FromPort=PORT,ToPort=PORT,Ipv6Ranges=\"[{CidrIpv6=CIDR_BLOCK}]\"\n\n```\n\n**From TF**\nUse the resource aws_security_group. When port is 22 or 3389, make sure property ingress.cidr_blocks has specific cidr range other than \"::/0\" e.g. \"2001:db8:1234:1a00::/64\" or any suitable range. See below example template;\n```\nresource \"aws_security_group\" \"example\" {\n...\ningress {\nfrom_port        = PORT\nto_port          = PORT\nprotocol         = \"tcp\"\nipv6_cidr_blocks    = [\"CIDR_BLOCK\"]\n}\n...\n}\n```\n**References**\n1. https://workbench.cisecurity.org/sections/844441/recommendations/2319229\n2. https://docs.aws.amazon.com/cli/latest/reference/ec2/revoke-security-group-ingress.html\n3. https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-security-groups.html\n4. https://docs.aws.amazon.com/cli/latest/reference/ec2/authorize-security-group-ingress.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group",
        "complianceTag": "Network Security",
        "logicHash": "Kt56QGBbUrXg587zDptjBg",
        "ruleId": "D9.AWS.NET.91",
        "category": ""
    },
    {
        "name": "Ensure that AWS Elastic Container Registry (ECR) repositories are not exposed to everyone.",
        "description": "Protect the Amazon ECR image repositories available within your AWS account from any unauthorized access. Amazon Elastic Container Registry uses resource-based policies to control access. These types of permission policies let you specify who has access to your ECR repositories and what actions they can perform on them. Allowing public access to your Amazon ECR image repositories through resource-based policies can lead to data leakage and/or data loss.",
        "severity": "Critical",
        "logic": "EcrRepository should not have policy.document.Statement contain [ Effect='Allow' and (Principal='*' or Principal.AWS='*') and not Condition]",
        "remediation": "\n**From Portal**\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region that contains the repository to set a policy statement on.\n3. In the navigation pane, choose Repositories.\n4. On the Repositories page, choose the repository to set a policy statement on to view the contents of the repository.\n5. From the repository image list view, in the navigation pane, choose Permissions, Edit.\n6. Under Permission statements, select the policy statement that has Effect set to \"Allow\" and Principal set to \"*\", click on the Edit button to enter the edit mode.\n7. In the edit mode, explicitly grant permission to a specified entity (principal) when the effect is 'Allow'.\n8. Within Principal section, uncheck Everybody (*) checkbox and enter the AWS account ID or AWS service name in the Principal box, or select the IAM entity (user, group, role) allowed to access the selected ECR repository from All IAM entities table, based on your requirements.\n9. Save.\n\n**From TF**\nUse the resource \"aws_ecr_repository_policy\" to create policy. When the effect is 'Allow' Make sure that you don't have Principal='*' or 'AWS:*' in your policy document.\n```\nresource \"aws_ecr_repository_policy\" \"testpolicy\" {\nrepository = example-repository\n\npolicy =\n{\n...\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": [\n\"arn:aws:iam::account-id:user/user-1\",\n]\n}\n...\n}\n```\n\n**From Command Line**\nUse the following command to set repository policy. when the effect is 'Allow' Make sure that you don't have Principal='*' or 'AWS:*' in your policy policy.document.Statement without any condition.\n```\naws ecr set-repository-policy --repository-name example-repository --policy-text file://my-policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/set-repository-policy.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/set-repository-policy.html#\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository_policy ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "dvQo2hX+XYdzFOehn8QwZQ",
        "ruleId": "D9.AWS.IAM.102",
        "category": ""
    },
    {
        "name": "Ensure that EC2 AMIs are not publicly accessible",
        "description": "One or more AMI exposed to the public internet. It is recommended to not publicly shared with the other AWS accounts in order to avoid sensitive data exposure. If required, AMI images should only be shared with relevant AWS accounts without making them public.",
        "severity": "Critical",
        "logic": "AMI should have isPublic=false",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the left navigation panel select AMIs under Images.\n3. Select the relevant image, and then choose Actions, Edit AMI permissions.\nIf the selected image is public,  the following status will be displayed on the EC2 dashboard: 'This image is currently Public.'.\n4.Change it to Private and save changes.\n5. Change the AWS region from the navigation bar and repeat steps 1-4 for the all the regions.\n\n**From TF**\nWe cannot change the permission of AMI from public to private using terraform code.\nTo change the AMI's permission from Public to Private we need to use portal or CLI.\n\n**From Command Line**\nTo change the permission of AMI to private, run:\n```\naws ec2 modify-image-attribute --region us-east-1 --image-id AMI-ID --launch-permission \"Remove=[{Group=all}]\"\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-intro.html\n2. https://docs.aws.amazon.com/cli/latest/reference/ec2/modify-image-attribute.html",
        "complianceTag": "Network Security",
        "logicHash": "e4j9PbeKiHbUkNpOhEPECA",
        "ruleId": "D9.AWS.NET.29",
        "category": ""
    },
    {
        "name": "Ensure that EC2 instance's custom AMI is not publicly shared",
        "description": "Avoid publicly sharing AMIs to reduce the risk of exposing sensitive information.",
        "severity": "Critical",
        "logic": "Instance where imageDetails.imageLocation regexMatch /^(?!amazon|aws-marketplace\\/).+/ should not have imageDetails.isPublic",
        "remediation": "\nNote: The following instructions refer to the native 'Public' case, provided within the portal under 'AMI availability'. For further cases and instructions, please follow AWS documentation.\n\n**From Portal**\n1. Go to 'EC2 Dashboard'\n2. In the left menu, under 'Images', select 'AMIs'\n3. Select the publicly shared AMI\n4. Under 'Actions', select 'Edit AMI permissions'\n5. Change 'AMI availability' to 'Private'\n6. Save\n\n**From TF**\nTo remove the publicly shared AMI permissions, remove the relevant 'aws_ami_launch_permission' block:\n```\nresource \"aws_ami_launch_permission\" \"ami_launch_permission_example\" {\n..\nimage_id = AMI-ID\ngroup    = \"all\"\n..\n}\n```\n\n**From Command Line**\nTo remove the publicly shared AMI permissions, run:\n```\naws ec2 modify-image-attribute --image-id AMI-ID --launch-permission \"Remove=[{Group=all}]\"\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharing-amis.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ami_launch_permission\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify-image-attribute.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "eeB9W6MXa4q4BGFi0cMA4Q",
        "ruleId": "D9.AWS.IAM.106",
        "category": ""
    },
    {
        "name": "Ensure that Lambda Function URL is secured with IAM authentication",
        "description": "When Lambda Function URL authorization type is set to 'NONE', IAM authentication bypass is allowed as a public endpoint.",
        "severity": "Critical",
        "logic": "Lambda where urlConfigs should not have urlConfigs contain [ authType='NONE' ]",
        "remediation": "\n**From Portal**\n1. Open the Amazon Lambda console at https://us-east-1.console.aws.amazon.com/lambda/\n2. In the navigation pane, choose 'Functions' and select the relevant Lambda Function\n3. Under 'Configurations', choose 'Function URL' and press 'Edit'\n4. Set 'Auth type' to 'AWS_IAM' and save\n\n**From TF**\nTo set the authorization type for a Lambda Function URL, update the 'authorization_type' argument within the 'aws_lambda_function_url' block:\n```\nresource \"aws_lambda_function_url\" \"lambda_function_url_example\" {\n..\nauthorization_type = \"AWS_IAM\"\n..\n}\n```\n\n**From Command Line**\nTo set the authorization type for a Lambda Function URL, use:\n```\naws lambda update-function-url-config --function-name FUNCTION-NAME --auth-type AWS_IAM\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/lambda-urls.html\n2. https://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function_url\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/update-function-url-config.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "DMMFXrNy3fXhdQNFt8XIYw",
        "ruleId": "D9.AWS.IAM.107",
        "category": ""
    },
    {
        "name": "Ensure that Lambda Function is not publicly exposed via resource policy without a condition",
        "description": "Determine the specific resource-based principals' permissions needed by your Lambda Functions, and then craft a resource-based policy for these principals only.",
        "severity": "Critical",
        "logic": "Lambda should not have resourcePolicy.Statement contain [ Effect='Allow' and (Principal = '*' or Principal.AWS = '*') and not Condition ]",
        "remediation": "\n**From Portal**\n1. Go to 'Lambda' dashboard\n2. In the left menu, select 'Functions'\n3. Select the relevant Lambda Function\n4. Under 'Configurations', go to 'Permissions'\n5. Under 'Resource-based policy statements', select the relevant statement\n6. Edit the statement according to the principle of least privilege\n\n**From TF**\nTo edit a resource-based policy, edit the following arguments within 'aws_lambda_permission' block:\n```\nresource \"aws_lambda_permission\" \"lambda_permission_example\" {\n..\nprincipal   = PRINCIPAL\nsource_arn  = SOURCE-ARN\n..\n}\n```\n\n**From Command Line**\nTo remove a resource-based policy statement from a Lambda Function, run:\n```\naws lambda remove-permission --function-name FUNCTION-NAME --statement-id STATEMENT-ID\n```\nTo apply a resource-based policy statement to a Lambda Function, run:\n```\naws lambda add-permission --function-name FUNCTION-NAME--action ACTION --statement-id STATEMENT-ID --principal PRINCIPAL\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_permission\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/remove-permission.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/add-permission.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "ETmx06xSl5VNJU/K2xwXHA",
        "ruleId": "D9.AWS.IAM.105",
        "category": ""
    },
    {
        "name": "Ensure that S3 Bucket policy doesn't allow actions from all principals without a condition",
        "description": "Misconfigured S3 buckets can leak private information to the entire internet or allow unauthorized data tampering / deletion. S3 bucket policy should ensure that the principle of least privilege is being followed. A condition statement can be used to control the scope of the policy.",
        "severity": "Critical",
        "logic": "S3Bucket should not have policy.Statement with [Effect='Allow' and (Principal='*' or Principal.AWS='*') and Condition isEmpty()]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under Bucket policy, choose Edit. This opens the Edit bucket policy page.\n5. In the Policy box, edit the existing policy.\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nAdd a policy document with required permissions and appropriate condition as needed as follows:\n```\ndata \"aws_iam_policy_document\" \"example\" {\n...\nstatement {\neffect = \"Allow\"\n\nactions = [\nREQUIRED_ACTIONS\n]\nprincipals {\nREQUIRED_PRINCIPALS\n}\n\nresources = [\n\"S3_BUCKET_ARN\",\n]\n\ncondition {\ntest     = TEST\nvariable = CONTEXT_VARIABLE\n\nvalues = [\nVALUES\n]\n}\n}\n...\n}\n```\n\n**From Command Line**\nTo add a policy with required permissions and appropriate condition as needed, run:\n```\naws s3api put-bucket-policy --bucket BUCKET-NAME --policy file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-policy.html\n2. https://registry.terraform.io/providers/hashicorp/aws/3.3.0/docs/data-sources/iam_policy_document\n3. https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html\n4. https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "sSP6Wsq/z1vVUNrSKjj7RQ",
        "ruleId": "D9.AWS.IAM.40",
        "category": ""
    },
    {
        "name": "Ensure that S3 bucket ACLs don't allow 'FULL_CONTROL' access for anonymous / AWS authenticated users",
        "description": "Granting 'FULL_CONTROL' ACL permission within your S3 Bucket allows users full administrative control on the bucket. To protect your S3 Bucket's data from unauthorized access, make sure to avoid granting ACL permissions to anonymous / AWS authenticated users.",
        "severity": "Critical",
        "logic": "S3Bucket should not have acl.grants contain [ (uri = 'http://acs.amazonaws.com/groups/global/AuthenticatedUsers' or uri = 'http://acs.amazonaws.com/groups/global/AllUsers') and premission = 'FULL_CONTROL']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under ACL, choose Edit and modify the ACL configuration for the S3 bucket.\n5. On the Edit ACL page, Under Objects uncheck the relevant permission box.\nCheck the box which say \"I understand the effects of these changes on my objects and buckets\".\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nRemove the relevant ACL policy block:\n```\nresource \"aws_s3_bucket_acl\" \"example_s3_bucket_acl\" {\n..\naccess_control_policy {\ngrant {\ngrantee {\nuri  = ACL-URI\ntype = \"Group\"\n}\npermission = \"FULL_CONTROL\"\n..\n}\n```\n\n**From Command Line**\nTo deny the ACLs permissions for everyone, run:\n```\naws s3api put-bucket-acl --bucket BUCKET-NAME --acl private\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/s3-public-access-acl/\n2. https://awscli.amazonaws.com/v2/documentation/api/2.0.34/reference/s3api/put-bucket-acl.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_acl\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "NWz+HLmAse7murhTb0KZ8Q",
        "ruleId": "D9.AWS.IAM.100",
        "category": ""
    },
    {
        "name": "Ensure that S3 bucket ACLs don't allow 'READ' access for anonymous / AWS authenticated users",
        "description": "Granting 'READ' ACL permission within your S3 Bucket allows users to list the objects in the bucket. To protect your S3 Bucket's data from unauthorized access, make sure to avoid granting ACL permissions to anonymous / AWS authenticated users.",
        "severity": "Critical",
        "logic": "S3Bucket should not have acl.grants contain [ (uri = 'http://acs.amazonaws.com/groups/global/AuthenticatedUsers' or uri = 'http://acs.amazonaws.com/groups/global/AllUsers') and premission = 'READ']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under ACL, choose Edit and modify the ACL configuration for the S3 bucket.\n5. On the Edit ACL page, Under Objects uncheck the relevant permission box.\nCheck the box which say \"I understand the effects of these changes on my objects and buckets\".\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nRemove the relevant ACL policy block:\n```\nresource \"aws_s3_bucket_acl\" \"example_s3_bucket_acl\" {\n..\naccess_control_policy {\ngrant {\ngrantee {\nuri  = ACL-URI\ntype = \"Group\"\n}\npermission = \"READ\"\n..\n}\n```\n\n**From Command Line**\nTo deny the ACLs permissions for everyone, run:\n```\naws s3api put-bucket-acl --bucket BUCKET-NAME --acl private\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/s3-public-access-acl/\n2. https://awscli.amazonaws.com/v2/documentation/api/2.0.34/reference/s3api/put-bucket-acl.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_acl\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "C5sTkbzhR+rZAmWa869zOw",
        "ruleId": "D9.AWS.IAM.29",
        "category": ""
    },
    {
        "name": "Ensure that S3 bucket ACLs don't allow 'WRITE' access for anonymous / AWS authenticated users",
        "description": "Granting 'WRITE' ACL permission within your S3 Bucket allows users to delete, overwrite and create new objects in the bucket. To protect your S3 Bucket's data from unauthorized access, make sure to avoid granting ACL permissions to anonymous / AWS authenticated users.",
        "severity": "Critical",
        "logic": "S3Bucket should not have acl.grants contain [ (uri = 'http://acs.amazonaws.com/groups/global/AuthenticatedUsers' or uri = 'http://acs.amazonaws.com/groups/global/AllUsers') and premission = 'WRITE']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under ACL, choose Edit and modify the ACL configuration for the S3 bucket.\n5. On the Edit ACL page, Under Objects uncheck the relevant permission box.\nCheck the box which say \"I understand the effects of these changes on my objects and buckets\".\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nRemove the relevant ACL policy block:\n```\nresource \"aws_s3_bucket_acl\" \"example_s3_bucket_acl\" {\n..\naccess_control_policy {\ngrant {\ngrantee {\nuri  = ACL-URI\ntype = \"Group\"\n}\npermission = \"WRITE\"\n..\n}\n```\n\n**From Command Line**\nTo deny the ACLs permissions for everyone, run:\n```\naws s3api put-bucket-acl --bucket BUCKET-NAME --acl private\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/s3-public-access-acl/\n2. https://awscli.amazonaws.com/v2/documentation/api/2.0.34/reference/s3api/put-bucket-acl.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_acl\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "ZWY3PBWd/wHa/b9r1hMeDg",
        "ruleId": "D9.AWS.IAM.31",
        "category": ""
    },
    {
        "name": "Ensure that S3 bucket ACLs don't allow 'WRITE_ACP' access for anonymous / AWS authenticated users",
        "description": "Granting 'WRITE_ACP' ACL permission within your S3 Bucket allows users to write the ACL for the bucket. To protect your S3 Bucket's data from unauthorized access, make sure to avoid granting ACL permissions to anonymous / AWS authenticated users.",
        "severity": "Critical",
        "logic": "S3Bucket should not have acl.grants contain [ (uri = 'http://acs.amazonaws.com/groups/global/AuthenticatedUsers' or uri = 'http://acs.amazonaws.com/groups/global/AllUsers') and premission = 'WRITE_ACP']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under ACL, choose Edit and modify the ACL configuration for the S3 bucket.\n5. On the Edit ACL page, Under Objects uncheck the relevant permission box.\nCheck the box which say \"I understand the effects of these changes on my objects and buckets\".\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nRemove the relevant ACL policy block:\n```\nresource \"aws_s3_bucket_acl\" \"example_s3_bucket_acl\" {\n..\naccess_control_policy {\ngrant {\ngrantee {\nuri  = ACL-URI\ntype = \"Group\"\n}\npermission = \"WRITE_ACP\"\n..\n}\n```\n\n**From Command Line**\nTo deny the ACLs permissions for everyone, run:\n```\naws s3api put-bucket-acl --bucket BUCKET-NAME --acl private\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/s3-public-access-acl/\n2. https://awscli.amazonaws.com/v2/documentation/api/2.0.34/reference/s3api/put-bucket-acl.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_acl\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "h8x7qlWzEOufVguIrU2AOw",
        "ruleId": "D9.AWS.IAM.33",
        "category": ""
    },
    {
        "name": "Ensure that SQS policy won't allow all actions from all principals without a condition",
        "description": "SQS might contain sensitive information. Determine the specific principals the their required actions, and then craft IAM policy with the required permissions.",
        "severity": "Critical",
        "logic": "Sqs should not have policy.Statement contain [Effect='Allow' and ((Principal='*' or Principal.AWS='*') and Action contain ['%SQS:*%']) and not Condition]",
        "remediation": "\n**From console**\n1. Open the Amazon SQS console at https://console.aws.amazon.com/sqs/.\n2. In the navigation pane, choose Queues.\n3. Choose a queue and choose Edit.\n4. Scroll to the Access policy section.\n4. Edit the access policy statements in the input box. or You can use AWS policy generator tool: https://awspolicygen.s3.amazonaws.com/policygen.html.\n5. In the policy When Effect is 'Allow' Make sure you DO NOT mention Action = 'sqs:*', and Principal = '*'. And add a condition in the policy statement.\n5. When you finish configuring the access policy, choose Save.\n\n**From CLI**\n1. Create a .json file with policy statement\n```\naws sqs set-queue-attributes --queue-url QUEUE_URL --attributes FILE:UPDATE_ATTRIBUTES.JSON\n\n```\nWhere the file should contain the new policy for the queue.\n**From CFT**\nWhen Effect is 'Allow' Make sure you DO NOT mention Action = 'sqs:*', and Principal = '*' and add a condition in your policy document.\nSee below sample template.\n\nResource: AWS::SQS::QueuePolicy\n\n```\nResources:\nSampleSQSPolicy:\nType: AWS::SQS::QueuePolicy\nProperties:\nQueues:\n- 'https://sqs:us-east-2.amazonaws.com/444455556666/myqueue'\nPolicyDocument:\nStatement:\nAction: [ 'SQS:SendMessage' , 'SQS:ReceiveMessage' ]\nEffect: Allow\nPrincipal:\nAWS:\n- '111122223333'\nCondition:\nArnEquals:\n'aws:SourceArn': '${aws_sns_topic.example.arn}'\n```\n\n**From TF**\n```\nresource \"aws_sqs_queue_policy\" \"positive2\" {\nqueue_url = aws_sqs_queue.q.id\n\npolicy = <<POLICY\n{\n\"Version\": \"2012-10-17\",\n\"Id\": \"sqspolicy\",\n\"Statement\": [\n{\n\"Sid\": \"First\",\n\"Effect\": \"Allow\",\n\"Principal\": \"*\",\n- \"Action\": \"*\",\n+ \"Action\": \"...\",  # i.e \"sqs:SendMessage\",\n\"Resource\": \"${aws_sqs_queue.q.arn}\",\n\"Condition\": {\n\"ArnEquals\": {\n\"aws:SourceArn\": \"${aws_sns_topic.example.arn}\"\n}\n}\n}\n]\n}\nPOLICY\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-authentication-and-access-control.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/set-queue-attributes.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-sqs-policy.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue_policy",
        "complianceTag": "Identity and Access Management",
        "logicHash": "mgrnpbTRKpb4IdthMA31CA",
        "ruleId": "D9.AWS.IAM.56",
        "category": ""
    },
    {
        "name": "Ensure that Security Groups are not open to all",
        "description": "Security Groups should not be open to the internet. If you expand or modify your cloud presence, for instance by adding additional services, or additional regions, you can modify the security policies consistently for all regions from one console",
        "severity": "Critical",
        "logic": "SecurityGroup where networkAssetsStats contain-any [ count != 0 ] or networkInterfaces length()>0 should not have inboundRules with [ scope='0.0.0.0/0' and portTo=0]",
        "remediation": "\n**From Portal:**\nConfigure your Security Groups to only allow access from internal networks and limited access scope. If public interface exists, remove it and limit the access scope within the network only to applications or instances that requires access.\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. In the left pane, click Security Groups\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Inbound Rules tab\n6. Identify the rules to be removed\n7. Click the x in the Remove column\n8. Click Save\n\n**From TF:**\nRemove any inbound rule with scope 0.0.0.0/0 and port 0 and create entry for specific port and protocol.\n```\nresource \"aws_security_group\" \"example\" {\n...\ningress {\nfrom_port   = desired_port\nto_port     = desired_port\nprotocol    = \"tcp\"\n-   cidr_blocks = [\"0.0.0.0/0\"]\n+   cidr_blocks = [\"specific_IP_range\"]\n}\n}\n```\n\n**From Command Line:**\nUse below command to remove the inbound rules that permits unrestricted ingress to any port and protocol.\n```\naws ec2 revoke-security-group-ingress --region region_name --group-name security_group_name --protocol protocol_name --port port_name --cidr 0.0.0.0/0\n```\nOptionally add a more restrictive ingress rule to the selected Security Group:\n```\naws ec2 authorize-security-group-ingress --region region_name --group-name security_group_name --protocol protocol_name --port port_name --cidr specific_IP_range\n```\n\nReferences:\n1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html#create-a-base-security-group\n2. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n3. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/working-with-security-groups.html#updating-security-group-rules\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-security-groups.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html ",
        "complianceTag": "Network Security",
        "logicHash": "yb2s/Q0b86kG3hLLXr4ymQ",
        "ruleId": "D9.AWS.NET.56",
        "category": ""
    },
    {
        "name": "Ensure that public access is not given to RDS Instance",
        "description": "RDS should not be open to a public scope. Firewall and router configurations should be used to restrict connections between untrusted networks and any system components in the cloud environment.",
        "severity": "Critical",
        "logic": "RDS where isPublic='true' should not have inboundRules with [scope isPublic()]",
        "remediation": "\n**From Portal:**\nUse following steps to verify connectivity settings for RD databases.\n1. Login to AWS console and Navigate to RDS.\n2. In the left navigation, select Databases.\n3. Select RDS instance that you want to edit.\n4. In Connectivity & security, within Publicly accessible section, Verify value as No.\n5. Remove the public interface as well as limit the scope to the VPC If publicly accessible section value is Yes.\n6. Go to Security group rules section and click on each active security group name to select it for editing.\n7. On the VPC Security Groups page, select the Inbound rules tab from the bottom panel and click the Edit button to edit the selected security group ingress rules.\n8. In the Edit inbound rules dialog box, identify any inbound rules which have set the Source to Anywhere (0.0.0.0/0) and update them by using one of the following actions:\nTo grant access to a certain IP address:\na. Select Custom IP from the Source dropdown list.\nb. Enter the CIDR that you want to authorize in the Source field.\nc. Click the Save button to save the changes.\nTo grant access to an EC2 Security Group:\na. Select Custom IP from the Source dropdown list.\nb. Enter the EC2 security group ID that you want to authorize in the Source field.\nc. Click the Save button to save the changes.\n\n**From Command Line:**\n1. Run following command to disable the Publicly Accessible flag for an RDS instance.\n```\naws rds modify-db-instance --region region_name --db-instance-identifier RDS_instance_name --no-publicly-accessible --apply-immediately\n```\n2. Run following command to revoke the VPC security group inbound rule with the public scope CIDR set to 0.0.0.0/0 that grants access to everyone.\n```\naws ec2 revoke-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --cidr 0.0.0.0/0\n```\n3. Run following command to authorize custom access based on IP/CIDR to the instances associated with the selected VPC security group (Instance access authorization based on IP/CIDR).\n```\naws ec2 authorize-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --cidr specific_CIDR_value\n```\n4. Run following command to authorize custom access based on existing EC2 security groups (Instance access authorization based on EC2 security group)\n```\naws ec2 authorize-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --source-group source_security_group_id\n```\n\nReferences:\n1. http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.html\n2. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.RDSSecurityGroups.html\n3. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html\n4. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-instance.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/authorize-security-group-ingress.html ",
        "complianceTag": "Network Security",
        "logicHash": "MQP05P8rZKt+OjSeqIqsng",
        "ruleId": "D9.AWS.NET.17",
        "category": ""
    },
    {
        "name": "Ensure that the API Endpoint type in API Gateway is set to Private and is not exposed to the public internet",
        "description": "API Gateway private endpoints are made possible via AWS PrivateLink interface VPC endpoints. Interface endpoints work by creating elastic network interfaces in subnets that you define inside your VPC. Those network interfaces then provide access to services running in other VPCs, or to AWS services such as API Gateway. When configuring your interface endpoints, you specify which service traffic should go through them. API Gateway as a fully managed service runs its infrastructure in its own VPCs. When you interface with API Gateway publicly accessible endpoints, it is done through public networks. When they re configured as private, the public networks are not made available to route your API. Instead, your API can only be accessed using the interface endpoints that you have configured.",
        "severity": "Critical",
        "logic": "ApiGateway should have endpointConfiguration.types contain-all ['Private']",
        "remediation": "\n**From Portal:**\nTo change the API endpoint type of your API, perform one of the following sets of steps:\n\n1. To convert a public endpoint from regional or edge-optimized and vice versa\na. Sign in to the API Gateway console at https://console.aws.amazon.com/apigateway.\nb. Choose a REST API.\nc. Choose Settings.\nd. Change the Endpoint Type option under Endpoint Configuration from Edge Optimized to Regional or from Regional to Edge Optimized.\ne. Choose Save Changes to start the update.\n\n2. To convert a private endpoint to a regional endpoint\na. Sign in to the API Gateway console at https://console.aws.amazon.com/apigateway.\nb. Choose a REST API.\nc. Edit the resource policy for your API to remove any mention of VPCs or VPC endpoints so that API calls from outside your VPC as well as inside your VPC will succeed.\nd. Choose Settings.\ne. Change the Endpoint Type to Regional.\nf. Choose Save Changes to start the update.\ng. Remove the resource policy from your API.\nh. Redeploy your API so that the changes will take effect.\n\n**From TF:**\n```\nresource \"aws_api_gateway_rest_api\" \"example1\" {\nname = \"private-api-name\"\n\nendpoint_configuration {\n+   types = [\"PRIVATE\"]\n}\n}\n```\n\n**From Command Line:**\n1. To use the AWS CLI to update an edge-optimized API whose API ID is {api-id}, call update-rest-api as follows:\n```\naws apigateway update-rest-api --rest-api-id api_id --patch-operations op=replace,path=/endpointConfiguration/types/EDGE,value=REGIONAL\n```\n2. Update a regional API to an edge-optimized API as follows:\n```\naws apigateway update-rest-api --rest-api-id api_id --patch-operations op=replace,path=/endpointConfiguration/types/REGIONAL,value=EDGE\n```\n\nReferences:\n1. https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-api-migration.html\n2. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html\n3. https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html#apigateway-private-api-create-using-console\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_rest_api\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/apigateway/update-rest-api.html ",
        "complianceTag": "Network Security",
        "logicHash": "Nqd1b1hMt3Jfvxk7w60ZjA",
        "ruleId": "D9.AWS.NET.52",
        "category": ""
    },
    {
        "name": "Instances with Direct Connect virtual interface should not have public interfaces",
        "description": "Ensure that instances with direct connect virtual interface do not have public interfaces",
        "severity": "Critical",
        "logic": "Instance where vpc.vpnGateways contain [directConnectVirtualInterfaces] should have isPublic=false",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Select direct connect service and go to virtual interfaces tab\n3. Verify if any public virtual interface is associated with any instance.\n4. Make sure to fix the configuration to avoid public internet routing through your direct connect interfaces\n\n**References**\n1. https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html\n2. For creating private virtual interface: https://docs.aws.amazon.com/directconnect/latest/UserGuide/create-vif.html ",
        "complianceTag": "Network Security",
        "logicHash": "tu16PLcczgj5crWAZhGrpg",
        "ruleId": "D9.AWS.NET.27",
        "category": ""
    },
    {
        "name": "RDS Databases with Direct Connect virtual interface should not have public interfaces",
        "description": "Ensure that RDS databases with direct connect virtual interface should not have public interfaces",
        "severity": "Critical",
        "logic": "RDS where vpc.vpnGateways contain [directConnectVirtualInterfaces] should have isPublic=false",
        "remediation": "\n**From Portal**\nFirst of all, check the public virtual interfaces under direct connect service\n1. Login to the AWS Management Console.\n2. Select direct connect service and go to virtual interfaces tab\n3. Verify if any public virtual interface is associated with any RDS databases.\n4. Make sure to fix the configuration to avoid public internet routing through your direct connect interfaces.\n\n**References**\n1. https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html\n2. For creating private virtual interface: https://docs.aws.amazon.com/directconnect/latest/UserGuide/create-vif.html ",
        "complianceTag": "Network Security",
        "logicHash": "mdrMnXkrvw0Z1Z9JXMlMwQ",
        "ruleId": "D9.AWS.NET.28",
        "category": ""
    },
    {
        "name": "RDS should not have Public Interface",
        "description": "RDS should not be defined with public interface. Firewall and router configurations should be used to restrict connections between untrusted networks and any system components in the cloud environment.",
        "severity": "Critical",
        "logic": "RDS should not have isPublic = 'true'",
        "remediation": "\n**From Portal**\nUse following steps to verify connectivity settings for RD databases.\n1. Login to AWS console and Navigate to RDS.\n2. In the left navigation, select Databases.\n3. Select RDS instance that you want to edit.\n4. In Connectivity & security, within Public accessibility section, Verify value as No.\n\nUse following steps to disable public access for RDS databases.\n1. Sign in to the AWS Management Console and open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the navigation pane, choose Databases, and then choose the DB instance that you want to modify.\n3. Choose Modify. The Modify DB instance page appears.\n4. Click 'Additional configuration' under 'Connectivity' section.\n5. Select 'Not publicly accessible'.\n6. Choose 'Continue' and check the summary of modifications.\n7. Choose Modify DB instance to save your changes.\n\n**From TF**\n```\nresource \"aws_db_instance\" \"example\" {\n..\npublicly_accessible = false\n..\n}\n```\n\n**From Command Line**\nFor Linux, macOS, or Unix: Use following command to disable Publicly Accessible for the RDS instance.\n```\naws rds modify-db-instance --db-instance-identifier DB_INSTANCE --no-publicly-accessible\n```\nFor Windows: Use following command to disable Publicly Accessible for the RDS instance.\n```\naws rds modify-db-instance --db-instance-identifier DB_INSTANCE --no-publicly-accessible\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-instance.html ",
        "complianceTag": "Network Security",
        "logicHash": "y0NC6vbvXF/a+/gcd8hYXg",
        "ruleId": "D9.AWS.NET.16",
        "category": ""
    },
    {
        "name": "SSL/TLS certificates expire in 45 days",
        "description": "Ensure that SSL/TLS server certificates stored in AWS IAM are renewed before their expiration date.",
        "severity": "Informational",
        "logic": "IamServerCertificate should not have expiration before(45, 'days')",
        "remediation": "\nUse the AWS IAM API to send an UploadServerCertificate request to update or replace the certificate in IAM.\nAlternatively, where possible, use the AWS Certificate Manager (ACM) to manage your certificates, and automatically renew them.\n\n**From Command Line**\nTo list all IAM server certificates, run:\n```\naws iam list-server-certificates\n```\nTo delete an expired IAM server certificate, run:\n```\naws iam delete-server-certificate --server-certificate-name CERTIFICATE-NAME\n```\nTo upload a new IAM server certificate, run:\n```\naws iam upload-server-certificate --server-certificate-name CERTIFICATE-NAME --certificate-body CERTIFICATE-BODY-FILE --private-key CERTIFICATE-KEY-FILE --certificate-chain CERTIFICATE-CHAIN-FILE\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-server-certificates.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-server-certificate.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/upload-server-certificate.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "xy5UCRGCtrghmd943IApyA",
        "ruleId": "D9.AWS.CRY.57",
        "category": ""
    },
    {
        "name": "ALB secured listener certificate expires in one week",
        "description": "Ensure that SSL/TLS certificates stored in AWS IAM are renewed one week before expiry.",
        "severity": "High",
        "logic": "ApplicationLoadBalancer should not have listeners contain [ certificates contain [ expiration before(7, 'days') ] ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard\n3. Go to Load Balancing and click Load Balancers.\n4. Select the Application Load Balancer for which certificate is expiring in one week.\n5. Navigate to the Load Balancer section, and then the Listeners tab. Select the listener and click on View/edit certificates tab, and then click Add Certificate. You can add or import ACM or IAM certificates from here.\n\n**From Command Line**\nRun below Command to replace the SSL certificates that are about to expire with new certificates uploaded to IAM.\n```\naws iam upload-server-certificate --server-certificate-name EXAMPLE_CERTIFICATE --certificate-body file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\nRun below command to replace the ELB existing SSL certificate with the newly one uploaded to AWS IAM through upload command in previous step.\n```\naws elb set-load-balancer-listener-ssl-certificate --load-balancer-name EXAMPLE_NAME --load-balancer-port 443 --ssl-certificate-id EXAMPLE_CERTIFICATE_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://aws.amazon.com/certificate-manager/\n3. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-certificates.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "gZRA+JwglD1829FJnsKpYg",
        "ruleId": "D9.AWS.CRY.12",
        "category": ""
    },
    {
        "name": "AWS Kinesis data streams have server side encryption (SSE) enabled",
        "description": "Enable Server Side Encryption (SSE) of your AWS Kinesis Server data at rest, in order to protect your data and metadata from breaches or unauthorized access, and fulfill compliance requirements for data-at-rest encryption within your organization.",
        "severity": "High",
        "logic": "Kinesis should have encrypted=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Console.\n2. Go to Amazon Kinesis Service.\n3. Select the reported Kinesis data stream and click on 'configuration'.\n4. Choose 'Encryption' tab under 'configuration'.\n5. Check 'Enable serve-side encryption' box and select desired encryption type.\n6. Click Save Changes\n\n**From TF**\n```\nresource \"aws_kinesis_stream\" \"test\" {\nname        = \"stream_name\"\ndestination = \"extended_s3\"\n\n# i.e\n+ server_side_encryption {\n+   enabled  = true\n+   key_type = \"CUSTOMER_MANAGED_CMK\"\n+   key_arn  = \"arn\"\n+ }\n# OR\n+ server_side_encryption {\n+   enabled  = true\n+   key_type = \"AWS_OWNED_CMK\"\n+ }\n}\n```\n**From Command Line**\n```\naws kinesis start-stream-encryption --encryption-type KMS --key-id KMS_KEY_ID --stream-name EXAMPLE_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/streams/latest/dev/creating-using-sse-master-keys.html\n2. https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html\n3. https://docs.aws.amazon.com/streams/latest/dev/amazon-kinesis-streams.html\n4. https://registry.terraform.io/modules/rodrigodelmonte/kinesis-stream/aws/latest\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kinesis_stream ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "0IKN0KBQtd0CmLdd/k4lIw",
        "ruleId": "D9.AWS.CRY.24",
        "category": ""
    },
    {
        "name": "Amazon EBS snapshots should not be publicly accessible",
        "description": "EBS snapshots are used to back up the data on your EBS volumes to Amazon S3 at a specific point in time. You can use the snapshots to restore previous states of EBS volumes. It is rarely acceptable to share a snapshot with the public. Typically the decision to share a snapshot publicly was made in error or without a complete understanding of the implications. This check helps ensure that all such sharing was fully planned and intentional.",
        "severity": "High",
        "logic": "EbsSnapshot should not have createVolumePermissions contain [ ( group='all' or userId='null' ) ]",
        "remediation": "\n**From Portal**\nTo remediate this issue, update your EBS snapshot to make it private instead of public. Use following steps to make a public EBS snapshot private\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. In the navigation pane, under Elastic Block Store, choose Snapshots menu and then choose your public snapshot.\n3. From Actions, choose Modify permissions.\n4. Choose Private.\n5. Choose Save.\n\n**From Command Line**\nUse following command to make a public EBS snapshot private.\n```\naws ec2 modify-snapshot-attribute --snapshot-id snapshot_id --attribute createVolumePermission --operation-type remove --group-names all\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html\n2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html\n3. https://docs.aws.amazon.com/cli/latest/reference/ec2/modify-snapshot-attribute.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "vbEHf8bj93qjN2pW4MF6TQ",
        "ruleId": "D9.AWS.IAM.113",
        "category": ""
    },
    {
        "name": "CodeBuild S3 logs should be encrypted",
        "description": "Encryption of data at rest is a recommended best practice to add a layer of access management around your data. Encrypting the logs at rest reduces the risk that a user not authenticated by AWS will access the data stored on disk. It adds another set of access controls to limit the ability of unauthorized users to access the data.",
        "severity": "High",
        "logic": "CodeBuildProject should have logsConfig.s3Logs.encryptionDisabled=false",
        "remediation": "\n**From Portal**\nTo change the settings for a build project, perform the following procedure:\n1. Open the AWS CodeBuild console at https://console.aws.amazon.com/codesuite/codebuild/home.\n2. In the navigation pane, choose Build projects.\n3. Do one of the following:\na. Choose the link for the build project you want to change, and then choose Build details.\nb. Choose the button next to the build project you want to change, choose View details, and then choose Build details.\n4. Go to Logs section and choose Edit.\n5. Select S3 logs and ensure that the 'Disable S3 log encryption' box is not selected.\n\n**From Command Line**\nTo update a CodeBuild project with the AWS CLI, you create a JSON file with the updated properties and pass that file to the update-project command. Any properties not contained in the update file remain unchanged.\n\nNote: Json file should include the s3 logs encryption detail as per below format. Please follow reference links for more details on jason file creation.\n\"s3Logs\": {\n\"status\": \"s3-logs-status\",\n\"location\": \"s3-logs-location\",\n\"encryptionDisabled\": \"s3-logs-encryption-enabled\"\n}\n```\naws codebuild update-project --cli-input-json file://example-update-project.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/codebuild/latest/userguide/change-project-console.html\n2. https://docs.aws.amazon.com/codebuild/latest/userguide/change-project.html\n3. https://docs.aws.amazon.com/codebuild/latest/userguide/change-project-cli.html\n4. https://docs.aws.amazon.com/codebuild/latest/userguide/create-project-cli.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "p6wzwCUkR/El8HcTHl3y6w",
        "ruleId": "D9.AWS.CRY.84",
        "category": ""
    },
    {
        "name": "ECS Cluster At-Rest Encryption",
        "description": "Ensure that AWS ECS clusters are encrypted. Data encryption at rest, prevents unauthorized users from accessing sensitive data on your AWS ECS clusters and associated cache storage systems.",
        "severity": "High",
        "logic": "EcsCluster where( not containerInstances isEmpty()) should have containerInstances with [ instance.volumes contain [ encrypted=true ] ]",
        "remediation": "\n**From Portal**\nECS can be launched using ECS Fargate launch type or EC2 Instance. ECS Fargate launch type pulls images from the Elastic Container Registry, which are transmitted over HTTPS and are automatically encrypted at rest using S3 server-side encryption. To encrypt data at rest for EC2 instances using EBS(Elastic Block Store), please follow the remediation steps below. Please note that existing EBS volumes or snapshots cannot be encrypted, but when you copy unencrypted snapshots, or restore unencrypted volumes, the resulting snapshots or volumes are encrypted.\n\nECS remediation steps to encrypt new EBS volumes:\n1. From within the AWS Management Console, select EC2.\n2. Under 'Elastic Block Store' select 'Volumes'.\n3. Select 'Create Volume'.\n4. Enter the required configuration for your Volume.\n5. Select the checkbox for 'Encrypt this volume'.\n6. Select the KMS Customer Master Key (CMK) to be used under 'Master Key'.\n7. Select 'Create Volume'.\n\nThere is no option to encrypt existing EBS volume. To encrypt new EBS volumes use the following steps to create a snapshot and encrypt the resulting new volume or snapshot using your default CMK:\n\n1. Select your unencrypted volume.\n2. Select 'Actions' and click on 'Create Snapshot'.\n3. When the snapshot is complete, select Snapshots under Elastic Block Store. Select your newly created snapshot.\n4. Select 'Actions' and Click on 'Create volume from snapshot'\n5. Check the box 'Encrypt this volume'\n6. Select the KMS key to use as required\n7. Click on Create Volume Copy, the volume now created from this snapshot will be encrypted.\n\n**From TF**\n```\nresource \"aws_ebs_volume\" \"example\" {\navailability_zone = \"ZONE_NAME\"\nsize = VALUE\n\ntags = {\nName = \"HelloWorld\"\n}\n}\n```\n```\nresource \"aws_ebs_snapshot\" \"example_snapshot\" {\nvolume_id = VALUE\n\ntags = {\nName = \"HelloWorld_snap\"\n}\n}\n```\n\n**From Command Line**\n1. Run below command to create a new encrypted volume\n```\naws ec2 create-volume --volume-type VALUE --size VALUE --encrypted --kms-key-id KEY_ID --availability-zone VALUE\n```\n2. Run following command to encrypt existing Amazon EBS volumes\n\na. Run create-snapshot command to create a new snapshot from the existing volume\n```\naws ec2 create-snapshot --volume-id VALUE --description PUT_DESCRIPTION\n```\nb. Run copy-snapshot command to copy the EBS volume snapshot created during the previous steps.\nNote: --encrypted parameter will encrypt the snapshot copy using default master key and --kms-key-id parameter will encrypt the snapshot with a customer-managed Customer CMK.\n```\naws ec2 copy-snapshot --region REGION_NAME --source-region SOURCE_REGION_NAME --source-snapshot-id PUT_VALUE --encrypted\n```\nc. Run create-volume command to create a new EBS volume from the encrypted snapshot created during previous step.\n```\naws ec2 create-volume --region REGION_NAME --volume-type VALUE --size VALUE --encrypted --kms-key-id KEY_ID --availability-zone VALUE --snapshot-id PUT_VALUE\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\n2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-volume.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ebs_volume\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ebs_snapshot\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-snapshot.html\n6. https://awscli.amazonaws.com/v2/documentation/api/2.7.12/reference/ec2/create-volume.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "xXG7uqAgnuWrfji9MsshJQ",
        "ruleId": "D9.AWS.CRY.19",
        "category": ""
    },
    {
        "name": "ECS Cluster should not have running container instances with unconnected agents",
        "description": "The Amazon ECS container agent associates container instances to your cluster and tells Docker when to start, stop, and query the containers you have specified to run. If the agent is unable to access the service, the container instance is not able to operate as a member of your ECS cluster.",
        "severity": "High",
        "logic": "EcsCluster should not have containerInstances contain [ agentConnected = false and status != 'DRAINING' ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and navigate to ECS service.\n2. On ECS dashboard, select cluster you want to check.\n3. Click on ECS Instances tab available on the main page of cluster details.\n4. Select the container instance you want to examine under ECS Instances.\n5. Verify the status, it should be 'ACTIVE' rather than 'DRAINING'\n\nNote: Follow this link to troubleshoot disconnected Amazon ECS container instances: https://aws.amazon.com/premiumsupport/knowledge-center/ecs-agent-disconnected/\n\n**From Command Line**\nTo verify that the container agent is running on the affected container instance, run the following command:\n```\nsudo status ecs\n```\nIf the container agent isn't running on your container instance, then run the following command to start the agent:\n```\nsudo start ecs\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/ecs-agent-disconnected/ ",
        "complianceTag": "Network Security",
        "logicHash": "En2dTGAmpMaocraQXvKeIw",
        "ruleId": "D9.AWS.NET.33",
        "category": ""
    },
    {
        "name": "ECS Service with Admin Roles",
        "description": "It is recommended and considered a standard security advice to grant least privileges that is, granting only the permissions required to perform a task. IAM policies are the means by which privileges are granted to users, groups, services or roles. Determine what services and/or users need to do and then craft policies for them that let the users perform only those tasks, instead of granting full administrative privileges.",
        "severity": "High",
        "logic": "EcsService should not have role.combinedPolicies contain [name like '%admin%']",
        "remediation": "\n**From Portal:**\nFor each ECS Service with Admin Roles - perform the following to detach the policy that has full administrative privileges:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, click Policies and then search for the policy name found in the audit step.\n3. Select the policy that needs to be deleted.\n4. In the policy action menu, select first Detach\n5. Select all Users, Groups, Roles that have this policy attached\n6. Click Detach Policy\n7. In the policy action menu, select Detach\n\n**From TF**\n```\nresource \"aws_ecs_service\" \"test\" {\nname            = \"mongodb\"\ncluster         = aws_ecs_cluster.foo.id\ntask_definition = aws_ecs_task_definition.mongo.arn\ndesired_count   = 3\n- iam_role        = \"admin\"\ndepends_on      = [aws_iam_role_policy.foo]\n}\n```\n\n**From Command Line:**\n1. Lists all IAM users, groups, and roles that the specified managed policy is attached to.\n```\naws iam list-entities-for-policy --policy-arn policy_arn\n```\n2. Detach the policy from all IAM Users:\n```\naws iam detach-user-policy --user-name iam_user --policy-arn policy_arn\n```\n3. Detach the policy from all IAM Groups:\n```\naws iam detach-group-policy --group-name iam_group --policy-arn policy_arn\n```\n4. Detach the policy from all IAM Roles:\n```\naws iam detach-role-policy --role-name iam_role --policy-arn policy_arn\n```\n\nReferences:\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html\n3. https://docs.aws.amazon.com/cli/latest/reference/iam/index.html#cli-aws-iam\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecs_service\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-group-policy.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-role-policy.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-user-policy.html\n8. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-entities-for-policy.html\n9. https://workbench.cisecurity.org/sections/19694/recommendations/44859 ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "BPqGJqAruf6TVd9hPdXKZA",
        "ruleId": "D9.AWS.IAM.49",
        "category": ""
    },
    {
        "name": "ELB - Recommended SSL/TLS protocol version",
        "description": "Using insecure ciphers for your ELB Predefined or Custom Security Policy, could make the SSL connection between the client and the load balancer vulnerable to exploits. TLS 1.0 was recommended to be disabled by PCI Council after June 30, 2016",
        "severity": "High",
        "logic": "ELB should not have elbListeners with [ policies contain [ attributes contain-any [$ in ('Protocol-SSLv3', 'Protocol-TLSv1') ] ] ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard.\n3. In the navigation panel, under Load balancing, click Load Balancers.\n4. Select your Elastic Load Balancer.\n5. Select the Listeners tab from the bottom panel. In the Cipher column of the HTTPS listener, click Change.\n6. Scan the SSL Ciphers section for any insecure / deprecated cipher definitions.\n\nFollow this link to see a list of all the insecure ciphers that require to be removed: http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-security-policy-table.html\n\n**From TF**\n```\nresource \"aws_elb\" \"example\" {\nname               = \"example\"\n}\n\nresource \"aws_lb_ssl_negotiation_policy\" \"test\" {\nname          = \"test-policy\"\nload_balancer = aws_elb.lb.id\nlb_port       = 443\n\nattribute {\nname  = \"...\" # Weak protocol \"Protocol-SSLv2\"  \"Protocol-SSLv3\", \"Protocol-TLSv1\", \"Protocol-TLSv1.1\"\n- value = \"true\"\n+ value = \"false\"\n}\n}\n```\n\n**From Command Line**\nFollowing command will create an SSL negotiation policy for the specified HTTPS load balancer using the recommended security policy.\n```\naws elb create-load-balancer-policy --load-balancer-name my-load-balancer --policy-name my-SSLNegotiation-policy --policy-type-name SSLNegotiationPolicyType --policy-attributes AttributeName=Reference-Security-Policy,AttributeValue=ELBSecurityPolicy-2015-03\n```\n\nFollowing command will create an SSL negotiation policy for your HTTPS load balancer using a custom security policy by enabling the protocols and the ciphers.\n```\naws elb create-load-balancer-policy --load-balancer-name my-load-balancer --policy-name my-SSLNegotiation-policy --policy-type-name SSLNegotiationPolicyType --policy-attributes AttributeName=Protocol-SSLv3,AttributeValue=true AttributeName=Protocol-TLSv1.1,AttributeValue=true AttributeName=DHE-RSA-AES256-SHA256,AttributeValue=true AttributeName=Server-Defined-Cipher-Order,AttributeValue=true\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-policy-table.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_ssl_negotiation_policy\n3. https://docs.aws.amazon.com/cli/latest/reference/elb/create-load-balancer-policy.html\n4. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ssl-config-update.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "b5IB452FJM3wEFaJIEPeOQ",
        "ruleId": "D9.AWS.CRY.07",
        "category": ""
    },
    {
        "name": "ELB secured listener certificate expires in one week",
        "description": "Ensure that SSL/TLS certificates stored in AWS IAM are renewed one week before expiry.",
        "severity": "High",
        "logic": "ELB should not have elbListeners contain [ certificate.expiration before(7, 'days') ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard\n3. Go to Load Balancing and click Load Balancers.\n4. Select the Elastic Load Balancer for which certificate is expiring in one week.\n5. Navigate to the Load Balancer section, and then the Listeners tab. Select the listener and click on View/edit certificates tab, and then click Add Certificate. You can add or import ACM or IAM certificates from here.\n\n**From Command Line**\nRun below Command to replace the SSL certificates that are about to expire with new certificates uploaded to IAM.\n```\naws iam upload-server-certificate --server-certificate-name EXAMPLE_CERTIFICATE --certificate-body file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\nRun below command to replace the ELB existing SSL certificate with the newly one uploaded to AWS IAM through upload command in previous step.\n```\naws elb set-load-balancer-listener-ssl-certificate --load-balancer-name EXAMPLE_NAME --load-balancer-port 443 --ssl-certificate-id EXAMPLE_CERTIFICATE_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://aws.amazon.com/certificate-manager/\n3. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-certificates.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "nfBXxa7VTQxi6E9/4hlKQw",
        "ruleId": "D9.AWS.CRY.10",
        "category": ""
    },
    {
        "name": "Ensure 'root' account does not have an active X.509 signing certificate",
        "description": "An X.509 is a signing certificate used to make secure SOAP-protocol requests to some AWS services. Ensuring AWS 'root' account does not have an active X.509 signing certificate is recommended as a best practice (The root account should not be used to perform day to day operations).\nNote: Government cloud accounts do not have a root user, and so, should exclude this rule in the CloudGuard UI -> Posture Management -> Exclusions -> Create New Exclusion (for each relevant ruleset)",
        "severity": "High",
        "logic": "IamUser where name like '%root_account%' should have firstCertificate.isActive=false and secondCertificate.isActive=false",
        "remediation": "\n**From Portal**\n1. Click on the AWS account name/number in the upper-right corner\n2. Choose 'Security credentials' in the menu\n2. Under 'X.509 certificate', change all certificates with 'Active' status to 'Inactive'.\n\n**From Command Line**\nTo generate a credentials report, run:\n```\naws iam generate-credential-report\n```\nTo get the generated credentials report, run:\n```\naws iam get-credential-report\n```\nNote: The 'Content' field from the JSON response should be decoded from Base64 into a CSV file. After that, 'cert_1_active' and 'cert_2_active' columns should be verified as 'FALSE' for the 'root' user.\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/generate-credential-report.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-credential-report.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "QaTJpfgZYqRak2WPuexo7Q",
        "ruleId": "D9.AWS.IAM.68",
        "category": ""
    },
    {
        "name": "Ensure ACM certificate is using a minimum of 2048-bit key for RSA certificate",
        "description": "It is recommended to use a minimum of 2048-bit key for RSA certificates, an update to the widely-accepted recommendation of a 1024-bit minimum.",
        "severity": "High",
        "logic": "AcmCertificate where (keyAlgorithm regexMatch /RSA/ and status like 'ISSUED' ) should have keyAlgorithm regexMatch /[1-9]\\d{4}|[3-9]\\d{3}|2([1-9]\\d{2}|0([5-9]\\d|4[89]))/",
        "remediation": "\n**From Portal**\n1. Go to 'Certificate Manager'\n2. Identify certificates with 'Public key info' below 'RSA-2048'\n3. Update the relevant certificates to use at least 'RSA-2048' keys\n\n**From Command Line**\nTo list all ACM certificates, run:\n```\naws acm --region REGION list-certificates\n```\nTo check an ACM certificate's key algorithm, run:\n```\naws acm describe-certificate --region REGION --certificate-arn CERTIFICATE-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/acm_certificate\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/list-certificates.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/describe-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "OZMRMcf5nz1VZKdWacPe6w",
        "ruleId": "D9.AWS.CRY.60",
        "category": ""
    },
    {
        "name": "Ensure AWS Application Load Balancer (ALB) listeners block connection requests over HTTP",
        "description": "Checks for Application Load Balancer (ALB) listeners that are configured to accept connection requests over HTTP instead of HTTPS. It is recommended to use the HTTPS instead of HTTP, to encrypt the communication between the application clients and the application load balancer.",
        "severity": "High",
        "logic": "ApplicationLoadBalancer should not have listeners contain [ protocol='HTTP' ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and open EC2 console at https://console.aws.amazon.com/ec2/.\n2. Select 'Load Balancers' (Left Panel)\n3. Select the Application Load Balancer\n4. Select 'Listeners' tab\n5. 'Edit' the 'Listener ID' rule that uses HTTP\n6. Select 'HTTPS' and other options in the 'Protocol : port'\n\n**From TF**\nUse HTTPS protocol instead of HTTP protocol :\n```\nresource \"aws_lb_target_group\" \"test\" {\nload_balancer_arn = aws_lb.front_end.arn\nport = 443\n- protocol = \"HTTP\"\n+ protocol = \"HTTPS\"\nssl_policy        = \"ELBSecurityPolicy-2016-08\"\ncertificate_arn   = \"arn:aws:iam::187416307283:server-certificate/test_cert_rab3wuqwgja25ct3n4jdj2tzu4\"\n\ndefault_action {\ntype             = \"forward\"\ntarget_group_arn = aws_lb_target_group.front_end.arn\n}\n}\n```\n**From Command Line**\nTo modify the existing load balancer , run:\n```\naws elbv2 modify-listener --region us-east-1 --listener-arn ARN --default-actions file://FILE.json\n```\nOR\nTo create a new load balancer , run:\n```\naws elbv2 create-listener --region us-east-1 --load-balancer-arn ARN --protocol HTTPS --port 443 --certificates CERTIFIATE --ssl-policy POLICY --default-actions Type=forward,TargetGroupArn=ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-application-load-balancer.html\n2. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/tutorial-application-load-balancer-cli.html\n3. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/application-load-balancers.html\n4. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-listeners.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_listener",
        "complianceTag": "Network Security",
        "logicHash": "E2mTCx9tWwPDTTvExOfcSQ",
        "ruleId": "D9.AWS.NET.40",
        "category": ""
    },
    {
        "name": "Ensure AWS ElastiCache Redis clusters have encryption for data at rest enabled",
        "description": "In order to protect sensitive data,  AWS ElastiCache Redis clusters should be encrypted rest. Encryption of data at rest prevents unauthorized access to your sensitive data stored on AWS ElastiCache Redis clusters and associated cache storage.",
        "severity": "High",
        "logic": "ElastiCache where engine='redis' should have atRestEncryptionEnabled=true",
        "remediation": "\n**From Portal**\nAWS ElastiCache Redis cluster at-rest encryption can be set only at the time of the creation of the cluster. To fix this issue, create a new cluster with at-rest encryption, migrate all required ElastiCache Redis cluster data from the unencrypted cluster to the new cluster,  and then delete the old cluster.\n\nTo create new ElastiCache Redis cluster with at-rest encryption set, perform the following:\n1. Sign in on the AWS console\n2. In the console, select the specific region\n3. Navigate to ElastiCache Dashboard\n4. Click Redis\n5. Click 'Create' button\n6. On the 'Create your Amazon ElastiCache cluster' page:\na. Select 'Redis' cache engine type.\nb. Enter a name for the new cache cluster\nc. Select Redis engine version from 'Engine version compatibility' dropdown list.\nNote: As of July 2018, In-transit encryption can be enabled only for AWS ElastiCache clusters with Redis engine version 3.2.6 and 4.0.10.\nd. Click 'Advanced Redis settings' to expand the cluster advanced settings panel\ne. Select 'Encryption at-rest' checkbox to enable encryption along with other necessary parameters\n7. Click 'Create' button to launch your new ElastiCache Redis cluster\n\nTo delete reported ElastiCache Redis cluster, perform the following:\n1. Sign in on the AWS console\n2. In the console, select the specific region\n3. Navigate to ElastiCache Dashboard\n4. Click Redis\n5. Select reported Redis cluster\n6. Click 'Delete' button\n7. In the 'Delete Cluster' dialog box, if you want a backup for your cluster select 'Yes' from the 'Create final backup' dropdown menu, provide a name for the cluster backup, then click 'Delete'.\n\n**From TF**\nresource \"aws_elasticache_replication_group\" \"default\"{\n...\nreplication_group_id          = \"default-1\"\n+ at_rest_encryption_enabled    = true\n...\n}\n\n**From Command Line**\nEnabling At-Rest Encryption on a Redis (Cluster Mode Disabled) cluster.\n```\naws elasticache create-replication-group --replication-group-id GROUP_ID --replication-group-description GROUP_DESCRIPTION --cache-node-type NODE_TYPE --engine redis --at-rest-encryption-enabled --num-cache-clusters VALUE\n```\nEnabling At-Rest Encryption on a Cluster for Redis (Cluster Mode Enabled).\n```\naws elasticache create-replication-group --replication-group-id GROUP_ID --replication-group-description GROUP_DESCRIPTION --num-cache-clusters VALUE --cache-node-type NODE_TYPE --engine redis --engine-version VALUE --at-rest-encryption-enabled --cache-parameter-group PARAMETER_GROUP\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/at-rest-encryption.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elasticache_replication_group\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elasticache/create-replication-group.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "OtXBXGrEahNh7YknLWZpxA",
        "ruleId": "D9.AWS.CRY.31",
        "category": ""
    },
    {
        "name": "Ensure AWS ElastiCache Redis clusters have in-transit encryption enabled",
        "description": "In order to protect sensitive data,  AWS ElastiCache Redis clusters should be encrypted in transit. Encryption of data in transit protects data from unauthorized access as it travels through the network, between clients and cache servers. ",
        "severity": "High",
        "logic": "ElastiCache where engine='redis' should have transitEncryptionEnabled=true",
        "remediation": "\n**From Portal**\nAWS ElastiCache Redis cluster in-transit encryption can only be set when the cluster is created. To resolve this issue, create a new cluster with in-transit encryption enabled, migrate all required ElastiCache Redis cluster data from the unencrypted cluster, then delete it\n\nTo create new ElastiCache Redis cluster with In-transit encryption set, perform the following:\n1. Sign in to the AWS console\n2. In the console, select the specific region\n3. Navigate to ElastiCache Dashboard\n4. Click Redis clusters\n5. Click 'Create redis cluster' button\n6. On the 'Create your Amazon ElastiCache cluster' page,\na. Select 'Redis' cache engine type.\nb. Enter a name for the new cache cluster\nc. Select Redis engine version from 'Engine version compatibility' dropdown list.\nNote: As of July 2018, In-transit encryption can be enabled only for AWS ElastiCache clusters with Redis engine version 3.2.6 and 4.0.10.\nd. Click 'Advanced Redis settings' to expand the cluster advanced settings panel\ne. Select 'Encryption in-transit' checkbox to enable encryption along with other necessary parameters\n7. Click 'Create' button to launch your new ElastiCache Redis cluster\n\nTo delete reported ElastiCache Redis cluster, perform the following:\n1. Sign in to the AWS console\n2. In the console, select the specific region\n3. Navigate to ElastiCache Dashboard\n4. Click Redis\n5. Select the reported Redis cluster\n6. Click 'Delete' button\n7. In the 'Delete Cluster' dialog box, if you want a backup for your cluster select 'Yes' from the 'Create final backup' dropdown menu, provide a name for the cluster backup, then click 'Delete'.\n\n**From TF**\n```\nresource \"aws_elasticache_replication_group\" \"example\"{\n...\nreplication_group_id          = \"default-1\"\n+ transit_encryption_enabled    = true\n...\n}\n```\n\n**From Command Line**\n```\naws elasticache create-replication-group --region VALUE --replication-group-id GROUP_ID --replication-group-description GROUP_DESCRIPTION --num-cache-clusters VALUE --cache-node-type VALUE --engine Redis --engine-version VALUE --security-group-ids SG_ID --automatic-failover-enabled --transit-encryption-enabled\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/in-transit-encryption.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elasticache_replication_group\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elasticache/create-replication-group.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "zpPuumuZu1++CE++ehBvmA",
        "ruleId": "D9.AWS.CRY.32",
        "category": ""
    },
    {
        "name": "Ensure AWS IAM policies do not grant 'assume role' permission across all services",
        "description": "Typically, you use AssumeRole within your account for cross-account access. In order to follow least privilege principles, it is recommended NOT to use AssumeRole across ALL the accounts.",
        "severity": "High",
        "logic": "IamPolicy should not have document.Statement contain-any [ Action='sts:AssumeRole' and Effect = 'Allow' and (Resource regexMatch /\\*/ or Resource contain-any [$ regexMatch /\\*/]) and Condition.StringEquals isEmpty() and Condition.StringLike isEmpty()]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Console\n2. Navigate to the 'IAM' service\n3. Identify the reported policy\n4. Change the Service element of the policy document to be more restrictive so that it only allows AssumeRole permission on select services.\n\n**From TF**\nNote: User with an administrative AWS account can allow a another user to assume an IAM role. To do that, you create a new policy and attach it to that user. The policy must include a statement with the Allow effect on the sts:AssumeRole action, plus the Amazon Resource Name (ARN) of the role in a Resource element, as shown in the following example. Users that get the policy, either through group membership or direct attachment, can switch to the specified role.\n\n```\nresource \"aws_iam_role\" \"CloudTrailRoleForCloudWatchLogs-management-events\" {\nname = \"CloudTrailRoleForCloudWatchLogs-management-events\"\n\npolicy = <<EOF\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Action\": \"sts:AssumeRole\",\n\"Effect\": \"Allow\",\n\"Resource\": \"arn:aws:iam::aws_account_id:role/workdocs_app_role\"\n}\n]\n}\nEOF\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html\n2. https://docs.aws.amazon.com/workdocs/latest/developerguide/wd-iam-grantdev.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "//N98ssZF1e4TOs8ZItCww",
        "ruleId": "D9.AWS.IAM.53",
        "category": ""
    },
    {
        "name": "Ensure AWS Redshift instances are encrypted",
        "description": "AWS Redshift instances should be encrypted at rest to help protecting sensitive data from breaches.",
        "severity": "High",
        "logic": "Redshift should have dataEncrypted=true",
        "remediation": "\n**From Portal**\nFollowing steps will enable encryption for the desired redshift cluster:\n1. Login to the AWS Management Console.\n2. Navigate to Redshift dashboard at https://console.aws.amazon.com/redshift/.\n3. In the navigation panel, under Redshift Dashboard, click 'Clusters'.\n4. Choose the Redshift cluster that you want to modify encryption settings and click on 'Properties' tab.\n5. Verify the Encryption status (Disabled/enabled) under the Cluster Properties.\n6. Click on 'Edit' tab on the right side and go to edit encryption.\n7. Select the desired encryption type and save it.\n\n**From TF**\n```\nresource \"aws_redshift_cluster\" \"test\" {\ncluster_identifier = \"tf-redshift-cluster\"\ndatabase_name      = \"mydb\"\nmaster_username    = \"foo\"\nmaster_password    = \"Mustbe8characters\"\nnode_type          = \"dc1.large\"\ncluster_type       = \"single-node\"\n+ encrypted          = true\n}\n```\n\n**From Command Line**\nTo turn on encryption for Redshift cluster\n```\naws redshift modify-cluster --cluster-identifier PUT_VALUE --encrypted\n```\n\n**References**\n1. https://docs.aws.amazon.com/redshift/latest/mgmt/managing-clusters-console.html#create-cluster\n2. https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-db-encryption.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/redshift_cluster\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/redshift/modify-cluster.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "3Y2R7Uf/jlCmh2nMYZBpoA",
        "ruleId": "D9.AWS.CRY.34",
        "category": ""
    },
    {
        "name": "Ensure Amazon SQS queues enforce Server-Side Encryption (SSE)",
        "description": "Server-side encryption (SSE) lets you transmit sensitive data in encrypted queues. SSE protects the contents of messages in queues using SQS-owned encryption keys (SSE-SQS) or keys managed in the AWS Key Management Service (SSE-KMS).",
        "severity": "High",
        "logic": "Sqs should have sqsManagedSseEnabled=true or cryptoKey.enabled=true",
        "remediation": "\n**From Portal**\n1. Go to 'Amazon SQS' queues\n2. Under each unencrypted queue, go to the 'Encryption' tab and press 'Edit'\n3. Under 'Encryption' set 'Server-side encryption' to 'Enabled'\n4. Set the 'Encryption key type' and 'Save'\nNote: If 'SSE-KMS' key type was choosen, make sure the key is not disabled.\n\n**From TF**\nFor 'SSE-SQS' managed encryption, set 'sqs_managed_sse_enabled' to 'true':\n```\nresource \"aws_sqs_queue\" \"queue_example\" {\n..\nsqs_managed_sse_enabled = true\n..\n}\n```\nFor 'SSE-KMS' encryption, set the 'kms_master_key_id' property:\n```\nresource \"aws_sqs_queue\" \"queue_example\" {\n..\nkms_master_key_id = \"KMS-MASTER-KEY-ID\"\n..\n}\n```\n\n**From Command Line**\nFor 'SSE-SQS' managed encryption, run:\n```\naws sqs set-queue-attributes --queue-url QUEUE-URL --attributes SqsManagedSseEnabled=true\n```\nFor 'SSE-KMS' encryption, run:\n```\naws sqs set-queue-attributes --queue-url QUEUE-URL --attributes KmsMasterKeyId=KMS-MASTER-KEY-ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/set-queue-attributes.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "8qScFpgU7x7eLTf09hWSEQ",
        "ruleId": "D9.AWS.CRY.44",
        "category": ""
    },
    {
        "name": "Ensure EBS Volume Encryption is Enabled in all Regions",
        "description": "With Amazon EBS encryption, you aren't required to build, maintain, and secure your own key management infrastructure. Also it ensures that the data is encrypted and rest and during transit from EBS to EC2.",
        "severity": "High",
        "logic": "Volume should have encrypted=true",
        "remediation": "\n**From Portal**\n1. Login to AWS Management Console and open the Amazon EC2 console using https://console.aws.amazon.com/ec2/\n2. Under `Account attributes`, click `EBS encryption`.\n3. Click `Manage`.\n4. Click the `Enable` checkbox.\n5. Click `Update EBS encryption`\n6. Repeat for every region requiring the change.\n\nNote: EBS volume encryption is configured per region.\n\n**From TF**\nSet encrypted to true in the terraform file:\n```\nresource \"aws_ebs_volume\" \"example_volume\" {\n...\nencrypted = true\n...\n\n}\n```\n\n**From Command Line**\n1. Run\n```\naws --region REGION ec2 enable-ebs-encryption-by-default\n```\n2. Verify that `\"EbsEncryptionByDefault\": true` is displayed.\n3. Repeat every region requiring the change.\n\nNote: EBS volume encryption is configured per region.\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\n2. https://aws.amazon.com/blogs/aws/new-opt-in-to-default-encryption-for-new-ebs-volumes/\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ebs_volume#encrypted",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "WOGlCrEXBOGzQErmokpK9Q",
        "ruleId": "D9.AWS.CRY.61",
        "category": ""
    },
    {
        "name": "Ensure EMR clusters nodes should not have public IP",
        "description": "EMR cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances. Each instance in the cluster is called a node. AwsEmrInstance has an associated public IP address. Although it allows to create a secure access using SSH tunnel, associating the master node with public IP address directly and not within a VPC or a private subnet that has IPv4 does not stand with security best practices.",
        "severity": "High",
        "logic": "EmrCluster should not have instances with [ isPublic=true ]",
        "remediation": "\n**From Portal**\nIt is recommended to create a new cluster in VPC private subnet. After launch, it is not possible to manually disassociate a public IPv4 address from that instance. Following are the steps to create a new cluster in VPC private subnet.\n1. Sign in to the AWS Management Console, and open the Amazon EMR console at https://console.aws.amazon.com/emr.\n2. Under EMR on EC2 in the left navigation pane, choose Clusters, and then choose Create cluster.\n3. Under Networking, go to the Virtual private cloud (VPC) field. Enter the name of your VPC or choose Browse to select your VPC. Alternatively, choose Create VPC to create a VPC that you can use for your cluster.\n4. Choose any other options that apply to your cluster.\n5. To launch your cluster, choose Create cluster.\n\n**From TF**\nUse following code to create new cluster into a VPC, Subnet id represent the VPC ID.\n```\nresource \"aws_emr_cluster\" \"example\" {\nname          = \"emr-test-arn\"\nrelease_label = \"release_version_name\"\n\nec2_attributes {\nsubnet_id     = \"aws_VPC_subnet_id\"\n}\n```\n\n**From Command Line**\nUse Following example command to creates a cluster in an Amazon VPC subnet. Instance group details may vary as per specific requirement.\n```\naws emr create-cluster --ec2-attributes SubnetId=VPC_subnet_id --release-label release_version_name --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=2,InstanceType=m4.large --auto-terminate\n```\n\n**References**\n1. https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-vpc-launching-job-flows.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/emr_cluster\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/emr/create-cluster.html ",
        "complianceTag": "Network Security",
        "logicHash": "QTo+7zOXwggbUxbN6p4Nmw",
        "ruleId": "D9.AWS.NET.93",
        "category": ""
    },
    {
        "name": "Ensure IAM policies that allow full '*:*' administrative privileges are not attached",
        "description": "It is recommended and considered a standard security advice to grant least privileges that is, granting only the permissions required to perform a task. IAM policies are the means by which privileges are granted to users, groups, or roles. Determine what users need to do and then craft policies for them that let the users perform only those tasks, instead of granting full administrative privileges.",
        "severity": "High",
        "logic": "IamPolicy where (arn!='arn:aws:iam::aws:policy/AdministratorAccess' and arn!='arn:aws-us-gov:iam::aws:policy/AdministratorAccess' and arn!='arn:aws-cn:iam::aws:policy/AdministratorAccess') and document.Statement contain-any [Effect = 'Allow' and (Resource ='*' or Resource contain[$='*'] ) and (Action ='*' or Action contain[$='*']) ] should have users isEmpty() and roles isEmpty() and groups isEmpty()",
        "remediation": "\n**From Portal**\nUsing the GUI, perform the following to detach the policy that has full administrative privileges:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, click Policies and then search for the policy name found in the audit step.\n3. Select the policy that needs to be deleted.\n4. In the policy action menu, select first Detach\n5. Select all Users, Groups, Roles that have this policy attached\n6. Click Detach Policy\n7. In the policy action menu, select Detach\n\n**From TF**\n```\nresource \"aws_iam_role_policy\" \"test\" {\nname = \"test-policy\"\ndescription = \"A-test-policy\"\n\npolicy = <<EOF\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n-     \"Action\": [\"*\"],\n+     \"Action\": [\"some:action\"],\n\"Resource\": \"*\"\n}\n]\n}\nEOF\n}\n```\n\n**From Command Line**\nTo detach AWS IAM users, roles, and groups from policy, run below commands respectively:\n```\naws iam detach-user-policy --user-name USERNAME --policy-arn POLICY_ARN\n\naws iam detach-role-policy --role-name ROLE_NAME --policy-arn POLICY_ARN\n\naws iam detach-group-policy --group-name GROUP_NAME --policy-arn POLICY_ARN\n\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/config/latest/developerguide/iam-policy-no-statements-with-admin-access.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n4. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html\n5. https://docs.aws.amazon.com/cli/latest/reference/iam/index.html#cli-aws-iam\n6. https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "Cy7OTgTPVUXmiroMVP4EOQ",
        "ruleId": "D9.AWS.IAM.27",
        "category": ""
    },
    {
        "name": "Ensure IAM user password is rotated every 90 days or less",
        "description": "It is recommended that passwords be regularly rotated. If your AWS account does have a password policy that requires password rotation, ensure that the IAM user passwords are changed according to the current password policy.\nRotating passwords will reduce the window of opportunity for a password that is associated with a compromised or terminated account to be used.\npasswords should be rotated to ensure that data cannot be accessed with an old password which might have been lost, cracked, or stolen.",
        "severity": "High",
        "logic": "IamUser where passwordEnabled='true' should have passwordLastChanged after(-90, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Under 'Sign-in credentials' go to 'Console password' and click on 'Manage'\n8. select 'Require password reset'\nNote : make sure that the user has permission to change his or her password.\n9. Login to this user account and create new password.\n10. Repeat steps 5-9 for other relevant IAM users.\n\n**From Command Line**\n\n1. To update password, run:\n```\naws iam update-login-profile --user-name USER_NAME --password NEW_PASSWORD --password-reset-required\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_admin-change-user.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_enable-user-change.html\n3. https://docs.aws.amazon.com/cli/latest/reference/iam/update-login-profile.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "uI3R85oXQ/ue3rBHXOseLw",
        "ruleId": "D9.AWS.IAM.98",
        "category": ""
    },
    {
        "name": "Ensure Lambda functions are not using deprecated runtimes",
        "description": "Lambda runtimes for .zip file archives are built around a combination of operating system, programming language, and software libraries that are subject to maintenance and security updates. When security updates are no longer available for a component of a runtime, Lambda deprecates the runtime. You should not use already deprecated runtime for Lambda functions",
        "severity": "High",
        "logic": "Lambda should not have environment in($Lambda_Deprecated_Runtime)",
        "remediation": "\n**From Portal:**\nIt is recommended to update Lambda functions to a supported runtime so that you continue to receive security patches and remain eligible for technical support. Use following steps to update the Lambda function runtime version.\n1. Open the Functions page of the Lambda console.\n2. Choose the function to update and choose the Code tab.\n3. Scroll down to the Runtime settings section, which is under the code editor.\n4. Choose Edit.\na. For Runtime, select the runtime identifier.\nb. For Handler, specify file name and handler for your function.\nc. For Architecture, choose the instruction set architecture to use for your function.\n5. Choose Save.\n\nNote: If you update the function configuration to use a new runtime, you may need to update the function code to be compatible with the new runtime. If you update the function configuration to use a different runtime, you must provide new function code that is compatible with the runtime and architecture.\n\n**From TF**\nresource \"aws_lambda_function\" \"example\" {\nfunction_name    = \"lambda_function_name\"\ns3_bucket        = \"s3_bucket_name\"\ns3_key           = \"s3_key\"\nrole             = \"aws_iam_role_arn\"\nhandler          = \"lambda_handler\"\nmemory_size      = 1024\ntimeout          = 45\n\n# Use 'runtime' parameter to upgrade the runtime version\nruntime          = \"supported_runtime_version\"\n\n**From Command Line:**\nRun following command to upgrade the runtime environment for Lambda function.\n```\naws lambda update-function-configuration --region REGION_NAME --function-name LAMBDA_FUNCTION_NAME\n--runtime RUNTIME_VERSION_NAME\n```\n\nReferences:\n1. https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html\n2. https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-zip.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/update-function-configuration.html ",
        "complianceTag": "Vulnerability and Threat Management",
        "logicHash": "Nr4xmP0E3GdVkdGYucnavA",
        "ruleId": "D9.AWS.VLN.08",
        "category": ""
    },
    {
        "name": "Ensure NAT gateway state is available",
        "description": "To ensure proper operation, NAT gateway state should be available without any failure codes",
        "severity": "High",
        "logic": "NatGateway should not have failureCode",
        "remediation": "\n**From Portal**\nTo check the status and failure code of NAT gateway, follow the steps below:\n1. Sign in to the Amazon VPC console at https://console.aws.amazon.com/vpc/\n2. Choose NAT Gateways\n3. Check for State and State message in the main screen.\n4. Follow the references according to the state message.\n\n**From Command Line**\nUse describe-nat-gateways command to verify the status and failure code of NAT gateway:\n```\naws ec2 describe-nat-gateways\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/nat-gateway-troubleshooting.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-nat-gateways.html ",
        "complianceTag": "Monitoring",
        "logicHash": "3/YSE/O/mQTAmI/KK0uq7w",
        "ruleId": "D9.AWS.MON.17",
        "category": ""
    },
    {
        "name": "Ensure Network firewall delete protection enabled",
        "description": "The network firewall helps you protect your VPC. Set Delete protection in order to avoid accidental deletion of the firewall.",
        "severity": "High",
        "logic": "NetworkFirewall should have deleteProtection=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console\n2. In the console, select the specific region\n3. Navigate to the 'AWS Network Firewall' service.\n4. In the left pane under 'Network Firewall' click on Firewall.\n5. Select desired firewall and click on 'Firewall details'.\n6. Go to 'change protection' and click on 'Edit'.\n7. Choose 'enable' for Delete protection option and click 'save'.\n\n**From TF**\n```\nresource \"aws_networkfirewall_firewall\" \"example\" {\n- delete_protection  = false\n+ delete_protection = true\n}\n```\n\n**From Command Line**\nIn order to set Networks firewall delete protection to TRUE, use to following CLI command:\n```\naws network-firewall update-firewall-delete-protection --region REGION_NAME --firewall-name FIREWALL_NAME --delete-protection\n```\nNote: The flag --delete-protection will set the deletion protection to TRUE. The firewall deletion process through the console disables this protection, Therefore it is not shown in the console. Through the API, you must explicitly disable delete protection before you can delete the firewall.\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/developerguide/firewall-settings.html\n2. CLI: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/update-firewall-delete-protection.html",
        "complianceTag": "Network Security",
        "logicHash": "Y0WYxPkf1aSvlTsVT4fDUw",
        "ruleId": "D9.AWS.NET.62",
        "category": ""
    },
    {
        "name": "Ensure Network firewall have policy change protection enabled",
        "description": "The network firewall helps you protect your VPC. Set policy change protection to protect against accidental modification of the firewall policy.",
        "severity": "High",
        "logic": "NetworkFirewall should have firewallPolicyChangeProtection=true",
        "remediation": "\n**From TF**\n```\nresource \"aws_networkfirewall_firewall\" \"example\" {\n- firewall_policy_change_protection = false\n+ firewall_policy_change_protection = true\n}\n```\n\n**From Command Line**\nIn order to set Networks firewall PolicyChangeProtection to TRUE, use to following CLI command:\n```\naws network-firewall update-firewall-policy-change-protection --region REGION_NAME --firewall-name FIREWALL_NAME --firewall-policy-change-protection\n```\nNote: The flag --firewall-policy-change-protection will set the policy change protection to TRUE.\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/APIReference/API_UpdateFirewallPolicyChangeProtection.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/update-firewall-policy-change-protection.html\n",
        "complianceTag": "Network Security",
        "logicHash": "auMwb6oh5isrhW85HT4O3g",
        "ruleId": "D9.AWS.NET.64",
        "category": ""
    },
    {
        "name": "Ensure Network firewall have subnet change protection enabled",
        "description": "The network firewall helps you protect your VPC. Set subnet change protection to protect against accidental modification of the subnet associations, which might expose a protected subnet.",
        "severity": "High",
        "logic": "NetworkFirewall should have subnetChangeProtection=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console\n2. In the console, select the specific region\n3. Navigate to the 'AWS Network Firewall' service.\n4. In the left pane under 'Network Firewall' click on Firewall.\n5. Select desired firewall and click on 'Firewall details'.\n6. Go to 'change protection' and click on 'Edit'.\n7. Choose 'enable' for Subnet change protection option and click 'save'.\n\n**From TF**\n```\nresource \"aws_networkfirewall_firewall\" \"example\" {\n- subnet_change_protection = false\n+ subnet_change_protection = true\n}\n```\n\n**From Command Line**\nIn order to set Subnet change protection to TRUE, use to following CLI command:\n```\naws network-firewall update-subnet-change-protection --firewall-arn FW_ARN --subnet-change-protection\n```\nNote: The flag --subnet-change-protection will set the subnet change protection to TRUE.\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/APIReference/API_UpdateSubnetChangeProtection.html\n2. CLI: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/update-subnet-change-protection.html ",
        "complianceTag": "Network Security",
        "logicHash": "IMsywDBF6+y4/8FTTeMGhA",
        "ruleId": "D9.AWS.NET.63",
        "category": ""
    },
    {
        "name": "Ensure Network firewall status is not FAILED",
        "description": "The network firewall protects the availability zone where it resides. Make sure that the network firewall status is not FAILED, otherwise your VPC won't be protected.",
        "severity": "High",
        "logic": "NetworkFirewall should not have firewallStatus.status='FAILED'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console\n2. In the console, select the specific region\n3. Navigate to the 'AWS Network Firewall' service.\n4. In the left pane under 'Network Firewall' click on Firewall.\n5. Select desired firewall and identify the 'Firewall status'.\n\n**From Command Line**\nYou can identify the status of your network firewall by using the following CLI command:\n```\naws network-firewall describe-firewall --region REGION_NAME --firewall-name FIREWALL_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/APIReference/API_FirewallStatus.html\n",
        "complianceTag": "Network Security",
        "logicHash": "Sk2lJLEQsRRVrnavO1a7HA",
        "ruleId": "D9.AWS.NET.66",
        "category": ""
    },
    {
        "name": "Ensure S3 Bucket Policy is set to deny HTTP requests",
        "description": "To protect data in transit, an S3 bucket policy should deny all HTTP requests to its objects and allow only HTTPS requests. HTTPS uses Transport Layer Security (TLS) to encrypt data, which preserves integrity and prevents tampering.",
        "severity": "High",
        "logic": "S3Bucket should have policy.Statement contain [Effect='Deny' and Condition.Bool.aws:SecureTransport='false' and ((Action contain ['s3:GetObject'] and Action contain ['s3:PutObject']) or Action contain ['s3:*'] or Action contain ['*'] ) ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under Bucket policy, choose Edit. This opens the Edit bucket policy page.\n5. On the Edit bucket policy page, explore Policy examples in the Amazon S3 User Guide, choose Policy generator to generate a policy automatically, or edit the JSON in the Policy section. Here add a policy statement that will Deny request with SecureTransport=false\n6. In the Policy box, edit the existing policy or paste the bucket policy from the Policy generator. Make sure to resolve security warnings, errors, general warnings, and suggestions before you save your policy.\n7. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nIf a bucket policy is defined in an aws_s3_bucket policy field, ensure the JSON document contains ALL of the following properties.\nOne or more valid actions: *, s3:*, s3:GetObject\nValid effect: Deny\nValid condition: aws:SecureTransport: false\nIf a bucket policy as defined as an aws_s3_bucket_policy, ensure the JSON document in the policy field contains ALL of the properties listed above.\n```\nresource \"aws_s3_bucket\" \"example\" {\nbucket = \"my-tf-test-bucket\"\n# other required fields here\n}\n\nresource \"aws_s3_bucket_policy\" \"example2\" {\nbucket = aws_s3_bucket.b.id\n\npolicy = json_encode({\nVersion = \"2012-10-17\"\nId      = \"MYBUCKET_POLICY\"\nStatement = [\n{\nSid       = \"IPAllow\"\nEffect    = \"Deny\"\nPrincipal = \"*\"\nAction    = \"s3:*\"\nResource = [\naws_s3_bucket.b.arn,\n\"${aws_s3_bucket.b.arn}/*\",\n]\nCondition = {\nBool = {\n\"aws:SecureTransport\" = \"false\"\n}\n}\n},\n]\n})\n```\n\n**From Command Line**\nTo add a policy to deny non-secure transport, run:\n```\naws s3api put-bucket-policy --bucket BUCKET-NAME --policy file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonS3/latest/user-guide/add-bucket-policy.html\n2. https://aws.amazon.com/blogs/security/how-to-use-bucket-policies-and-apply-defense-in-depth-to-help-secure-your-amazon-s3-data/\n3. https://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-policy-for-config-rule/\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_policy\n6. https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-policy.html",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "xDl1IPqATLZffqj1wVOtMw",
        "ruleId": "D9.AWS.CRY.04",
        "category": ""
    },
    {
        "name": "Ensure SageMaker Notebook Instance Data Encryption is enabled",
        "description": "SageMaker is a fully-managed AWS service that enables developers and data engineers to quickly and easily build, train and deploy machine learning models at any scale. An AWS SageMaker notebook instance is a fully managed ML instance that is running the Jupyter Notebook open-source web application. It is highly recommended that the data stored on Machine Learning (ML) storage volumes attached to your AWS SageMaker notebook instances is encrypted in order to protect your data from breaches or unauthorized access and fulfill compliance requirements for data-at-rest encryption within your organization.",
        "severity": "High",
        "logic": "SageMakerNotebook should have kmsKey",
        "remediation": "\n**From Portal**\nThere is no possibility to enable encryption to an existing SageMaker instance. You need to re-create these with the necessary encryption configuration to ensure SageMaker notebook instances are encrypted. You can enable data-at-rest encryption and copy your existing data to it, perform the following actions.\n1. Log in to the AWS Management Console.\n2. Go to to SageMaker service dashboard at https://console.aws.amazon.com/sagemaker/.\n3. Click on 'Create notebook Instance'.\n4. Under 'Permissions and encryption' section, select the key from the Encryption key drop down. (select Enter a KMS key ARN option, then enter the full ARN of the AWS KMS default key)\n5. Complete the rest of the configurations and Create your notebook instance.\n\n**From TF**\n```\nresource \"aws_sagemaker_notebook_instance\" \"test\" {\nname          = \"my-notebook-instance\"\nrole_arn      = aws_iam_role.role.arn\ninstance_type = \"ml.t2.medium\"\n+ kms_key_id = \"KEY_ARN\"\n\ntags = {\nName = \"foo\"\n}\n}\n```\n\n**From Command Line**\n1. We can not enable encryption to an existing SageMaker instance. Create a new notebook instance using below command to enable encryption for that instance.\nNote: --kms-key-id parameter will enable encryption for the required notebook instance.\n```\naws sagemaker create-notebook-instance --notebook-instance-name INSTANCE_NAME --instance-type VALUE --kms-key-id KEY_ARN\n```\n2. Copy your data from the old notebook instance to the newly created instance.\n3. Once data is copied, you can remove the old notebook instance using below command.\n```\naws sagemaker delete-notebook-instance --notebook-instance-name INSTANCE_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sagemaker_notebook_instance\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/create-notebook-instance.html\n4. https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "UzIMlyyEdUpbCXcCcOYg8w",
        "ruleId": "D9.AWS.CRY.35",
        "category": ""
    },
    {
        "name": "Ensure SageMaker notebook instance storage volumes are encrypted with Amazon KMS Customer Master Keys (CMKs)",
        "description": "To enhance data security and compliance, it's advisable to encrypt storage volumes for Amazon SageMaker notebook instances using KMS Customer Master Keys (CMKs) instead of AWS managed-keys, providing greater control over data encryption/decryption.",
        "severity": "High",
        "logic": "SageMakerNotebook should have kmsKeyId",
        "remediation": "\n**From Portal**\n1. Log in to the AWS Management Console.\n2. Go to the Amazon KMS console (https://console.aws.amazon.com/kms/) and choose 'Customer managed keys' from the left panel.\n3. Select the appropriate AWS region matching your SageMaker instance.\n4. Click 'Create Key' to start setup.\n5. Choose Symmetric under Key type, select KMS for Key material origin, click Next.\n6. For Add labels, provide name and description. Click Next.\n7. Define key administrative permissions for IAM users/roles through KMS API. Click Next.\n8. For key usage permissions, specify IAM users/roles that can use the key for operations. Optionally, allow other AWS accounts. Click Next.\n9. Review and edit key policy, then click Finish to create the CMK.\n10. In the Amazon SageMaker console (https://console.aws.amazon.com/sagemaker/), select Notebook > 'Notebook instances'.\n11. Copy instance details of the notebook you want to recreate.\n12. Create a new notebook instance with matching configuration.\n13. Provide a unique name, instance type, Elastic Inference (optional), platform, lifecycle configuration (optional), volume size, IAM role, KMS key, VPC, subnet, security groups, direct internet access, Git repositories, and tags.\n14. Launch the new notebook instance.\n15. Copy data from the old instance to the new one.\n\n**From TF**\nTo make sure the KMS Master key exists, use the following key template:\n```\nresource 'aws_sagemaker_notebook_instance' 'example_sagemaker_notebook' {\n...\nkms_key_id = 'example_key'\n...\n}\n```\n\n**From Command Line**\nrun\n```\naws kms create-key --region REGION --description DESCRIPTION --policy POLICY --query QUERY\naws kms create-alias --region REGION --alias-name ALIAS_NAME --target-key-id KEY_ID\n```\n\nTo get configuration of your sagemaker notebook run:\n\n```\naws sagemaker describe-notebook-instance --region REGION --notebook-instance-name INSTANCE_NAME\n```\n\nrun\n```\naws sagemaker create-notebook-instance --region REGION --notebook-instance-name INSTANCE_NAME --instance-type INSTANCE_TYPE --role-arn ROLE_ARN --kms-key-id KMS_KEY_ID --subnet-id SUBNET_ID --security-group-ids SECURITY_GROUP_IDS_LIST\n```\n\nCopy the data from the source notebook instance to the new (destination) instance.\n\nrun\n```\naws sagemaker delete-notebook-instance --region REGION --notebook-instance-name INSTANCE_NAME\n```\n\n**References**\n1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/index.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kms/index.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sagemaker_notebook_instance\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "naQ0ekhBWIe8QG0VvEJJLw",
        "ruleId": "D9.AWS.CRY.36",
        "category": ""
    },
    {
        "name": "Ensure a log metric filter and alarm exist for IAM login profile changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for changes made to Identity and Access Management (IAM) login profiles.\nMonitoring changes to IAM login profiles will help ensure authentication and authorization controls remain intact.",
        "severity": "High",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventName=CreateAccessKey)||($.eventName=CreateLoginProfile)||($.eventName=UpdateLoginProfile)}')] length() > 0]",
        "remediation": "\n**From Portal**\nNote: This remediation process assumes SNS topic and log group are already configured.\n\n1. Go to 'CloudWatch'\n2. In the menu, under 'Logs', choose 'Log groups' and choose the relevant log group\n3. Press 'Create new metric filter' and add the following 'Filter pattern': '{($.eventName=CreateAccessKey)||($.eventName=CreateLoginProfile)||($.eventName=UpdateLoginProfile)}'\n4. Review and create the new metric filter\n5. In the menu, under 'Alarms', choose 'All alarms' and choose the relevant log group\n6. Press 'Create alarm' and choose the relevant metric and press 'Next'\n7. Under 'Metric', make sure 'Statistic' is set to 'Sum'\n8. Under 'Conditions', make sure the threshold type is set to 'Static', an alarm condition is set to 'Greater/Equal' and the threshold value is set to '1'\n9. Configure your SNS topic under 'Notification'\n10. Create the alarm\n\n**From TF**\nCreate a new CloudWatch metric filter:\n```\nresource \"aws_cloudwatch_log_metric_filter\" \"metric_filter_example\" {\n..\nname             = \"FILTER-NAME\"\npattern          = \"{($.eventName=CreateAccessKey)||($.eventName=CreateLoginProfile)||($.eventName=UpdateLoginProfile)}\"\nlog_group_name   = \"LOG-GROUP-NAME\"\n\nmetric_transformation {\nname      = \"METRIC-NAME\"\nnamespace = \"NAMESPACE-NAME\"\nvalue     = \"1\"\n..\n}\n}\n```\nCreate a new CloudWatch metric alarm:\n```\nresource \"aws_cloudwatch_metric_alarm\" \"metric_alarm_example\" {\n..\nalarm_name            = \"ALARM-NAME\"\ncomparison_operator   = \"GreaterThanOrEqualToThreshold\"\nevaluation_periods    = \"1\"\nmetric_name           = \"METRIC-NAME\"\nnamespace             = \"NAMESPACE-NAME\"\nperiod                = \"PERIOD\"\nstatistic             = \"Sum\"\nthreshold             = \"1\"\nalarm_actions         = [\"SNS-TOPIC-ARN\"]\n..\n}\n```\n\n**From Command Line**\nCreate a new CloudWatch metric filter:\n```\naws logs put-metric-filter --region REGION --log-group-name LOG-GROUP-NAME --filter-name FILTER-NAME --filter-pattern '{($.eventName=CreateAccessKey)||($.eventName=CreateLoginProfile)||($.eventName=UpdateLoginProfile)}' --metric-transformations metricName=METRIC-NAME,metricNamespace=METRIC-NAMESPACE,metricValue=1\n```\nCreate a new CloudWatch metric alarm:\n```\naws cloudwatch put-metric-alarm --region REGION --alarm-name ALARM-NAME --metric-name METRIC-NAME --statistic Sum --period PERIOD --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE --alarm-actions SNS-TOPIC-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateMetricFilterProcedure.html\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ConsoleAlarms.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/put-metric-filter.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/put-metric-alarm.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_log_metric_filter\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm\n7. https://docs.aws.amazon.com/IAM/latest/APIReference/API_Operations.html ",
        "complianceTag": "Monitoring",
        "logicHash": "l3vyvj8DciQp1DH0IxOq+g",
        "ruleId": "D9.AWS.MON.21",
        "category": ""
    },
    {
        "name": "Ensure a log metric filter and alarm exist for SSM actions",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for actions done by the Systems Manager Agent (SSM). Monitoring actions done by the Systems Manager Agent (SSM), will help ensure authentication and authorization controls remain intact.",
        "severity": "High",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventName=ListCommands)||($.eventName=ListCommandInvocations)||($.eventName=SendCommand)||($.eventName=StartSession)||($.eventName=DescribeSessions)||($.eventName=GetConnectionStatus)||($.eventName=DescribeInstanceProperties)||($.eventName=DescribeInstanceInformation)||($.eventName=TerminateSession)||($.eventName=ResumeSession)}')] length() > 0]",
        "remediation": "\nNote: This remediation process assumes SNS topic and log group are already configured.\n\n**From Portal**\n1. Go to 'CloudWatch'\n2. In the menu, under 'Logs', choose 'Log groups' and choose the relevant log group\n3. Press 'Create new metric filter' and add the following 'Filter pattern': '{($.eventName=ListCommands)||($.eventName=ListCommandInvocations)||($.eventName=SendCommand)||($.eventName=StartSession)||($.eventName=DescribeSessions)||($.eventName=GetConnectionStatus)||($.eventName=DescribeInstanceProperties)||($.eventName=DescribeInstanceInformation)||($.eventName=TerminateSession)||($.eventName=ResumeSession)}'\n4. Review and create the new metric filter\n5. In the menu, under 'Alarms', choose 'All alarms' and choose the relevant log group\n6. Press 'Create alarm' and choose the relevant metric and press 'Next'\n7. Under 'Metric', make sure 'Statistic' is set to 'Sum'\n8. Under 'Conditions', make sure the threshold type is set to 'Static', an alarm condition is set to 'Greater/Equal' and the threshold value is set to '1'\n9. Configure your SNS topic under 'Notification'\n10. Create the alarm\n\n**From TF**\nCreate a new CloudWatch metric filter:\n```\nresource \"aws_cloudwatch_log_metric_filter\" \"metric_filter_example\" {\n..\nname             = \"FILTER-NAME\"\npattern          = \"{($.eventName=ListCommands)||($.eventName=ListCommandInvocations)||($.eventName=SendCommand)||($.eventName=StartSession)||($.eventName=DescribeSessions)||($.eventName=GetConnectionStatus)||($.eventName=DescribeInstanceProperties)||($.eventName=DescribeInstanceInformation)||($.eventName=TerminateSession)||($.eventName=ResumeSession)}\"\nlog_group_name   = \"LOG-GROUP-NAME\"\n\nmetric_transformation {\nname      = \"METRIC-NAME\"\nnamespace = \"NAMESPACE-NAME\"\nvalue     = \"1\"\n..\n}\n}\n```\nCreate a new CloudWatch metric alarm:\n```\nresource \"aws_cloudwatch_metric_alarm\" \"metric_alarm_example\" {\n..\nalarm_name            = \"ALARM-NAME\"\ncomparison_operator   = \"GreaterThanOrEqualToThreshold\"\nevaluation_periods    = \"1\"\nmetric_name           = \"METRIC-NAME\"\nnamespace             = \"NAMESPACE-NAME\"\nperiod                = \"PERIOD\"\nstatistic             = \"Sum\"\nthreshold             = \"1\"\nalarm_actions         = [\"SNS-TOPIC-ARN\"]\n..\n}\n```\n\n**From Command Line**\nCreate a new CloudWatch metric filter:\n```\naws logs put-metric-filter --region REGION --log-group-name LOG-GROUP-NAME --filter-name FILTER-NAME --filter-pattern '{($.eventName=ListCommands)||($.eventName=ListCommandInvocations)||($.eventName=SendCommand)||($.eventName=StartSession)||($.eventName=DescribeSessions)||($.eventName=GetConnectionStatus)||($.eventName=DescribeInstanceProperties)||($.eventName=DescribeInstanceInformation)||($.eventName=TerminateSession)||($.eventName=ResumeSession)}' --metric-transformations metricName=METRIC-NAME,metricNamespace=METRIC-NAMESPACE,metricValue=1\n```\nCreate a new CloudWatch metric alarm:\n```\naws cloudwatch put-metric-alarm --region REGION --alarm-name ALARM-NAME --metric-name METRIC-NAME --statistic Sum --period PERIOD --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE --alarm-actions SNS-TOPIC-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateMetricFilterProcedure.html\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ConsoleAlarms.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/put-metric-filter.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/put-metric-alarm.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_log_metric_filter\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm\n7. https://docs.aws.amazon.com/systems-manager/latest/APIReference/API_Operations.html ",
        "complianceTag": "Monitoring",
        "logicHash": "qdyKXy3rJHcUdCYVuK7AdA",
        "ruleId": "D9.AWS.MON.23",
        "category": ""
    },
    {
        "name": "Ensure a log metric filter and alarm exist for STS 'AssumeRole' action",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for changes done by the Security Token Service 'AssumeRole' action. Monitoring changes done by the Security Token Service 'AssumeRole' action, will help ensure authentication and authorization controls remain intact.",
        "severity": "High",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventName=AssumeRole)}')] length() > 0]",
        "remediation": "\nNote: This remediation process assumes SNS topic and log group are already configured.\n\n**From Portal**\n1. Go to 'CloudWatch'\n2. In the menu, under 'Logs', choose 'Log groups' and choose the relevant log group\n3. Press 'Create new metric filter' and add the following 'Filter pattern': '{($.eventName=AssumeRole)}'\n4. Review and create the new metric filter\n5. In the menu, under 'Alarms', choose 'All alarms' and choose the relevant log group\n6. Press 'Create alarm' and choose the relevant metric and press 'Next'\n7. Under 'Metric', make sure 'Statistic' is set to 'Sum'\n8. Under 'Conditions', make sure the threshold type is set to 'Static', an alarm condition is set to 'Greater/Equal' and the threshold value is set to '1'\n9. Configure your SNS topic under 'Notification'\n10. Create the alarm\n\n**From TF**\nCreate a new CloudWatch metric filter:\n```\nresource \"aws_cloudwatch_log_metric_filter\" \"metric_filter_example\" {\n..\nname             = \"FILTER-NAME\"\npattern          = \"{($.eventName=AssumeRole)}\"\nlog_group_name   = \"LOG-GROUP-NAME\"\n\nmetric_transformation {\nname      = \"METRIC-NAME\"\nnamespace = \"NAMESPACE-NAME\"\nvalue     = \"1\"\n..\n}\n}\n```\nCreate a new CloudWatch metric alarm:\n```\nresource \"aws_cloudwatch_metric_alarm\" \"metric_alarm_example\" {\n..\nalarm_name            = \"ALARM-NAME\"\ncomparison_operator   = \"GreaterThanOrEqualToThreshold\"\nevaluation_periods    = \"1\"\nmetric_name           = \"METRIC-NAME\"\nnamespace             = \"NAMESPACE-NAME\"\nperiod                = \"PERIOD\"\nstatistic             = \"Sum\"\nthreshold             = \"1\"\nalarm_actions         = [\"SNS-TOPIC-ARN\"]\n..\n}\n```\n\n**From Command Line**\nCreate a new CloudWatch metric filter:\n```\naws logs put-metric-filter --region REGION --log-group-name LOG-GROUP-NAME --filter-name FILTER-NAME --filter-pattern '{($.eventName=AssumeRole)}' --metric-transformations metricName=METRIC-NAME,metricNamespace=METRIC-NAMESPACE,metricValue=1\n```\nCreate a new CloudWatch metric alarm:\n```\naws cloudwatch put-metric-alarm --region REGION --alarm-name ALARM-NAME --metric-name METRIC-NAME --statistic Sum --period PERIOD --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace NAMESPACE --alarm-actions SNS-TOPIC-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateMetricFilterProcedure.html\n2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ConsoleAlarms.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/put-metric-filter.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/put-metric-alarm.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_log_metric_filter\n6. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm\n7. https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html ",
        "complianceTag": "Monitoring",
        "logicHash": "2s94GXa97EwvpOOerg9NLA",
        "ruleId": "D9.AWS.MON.22",
        "category": ""
    },
    {
        "name": "Ensure in-transit and at-rest encryption is enabled for Amazon EMR clusters",
        "description": "Data encryption helps prevent unauthorized users from reading data on a cluster and associated data storage systems. This includes data saved to persistent media, known as data at rest, and data that may be intercepted as it travels the network, known as data in transit.",
        "severity": "High",
        "logic": "EmrCluster should have securityConfiguration",
        "remediation": "\n**From Portal**\nEMR versions 4.8.0 and later, supports the use of security configuration to specify settings for encrypting data at rest, data in transit, or both. When you enable at-rest data encryption, you can choose to encrypt EMRFS data in Amazon S3, data in local disks, or both. Each security configuration that you create is stored in Amazon EMR rather than in the cluster configuration, so you can easily reuse a configuration to specify data encryption settings whenever you create a cluster.\n\nFollowing are the steps to create a Security Configuration using the AWS console:\n1. Open the Amazon EMR console at https://console.aws.amazon.com/emr.\n2. In the navigation pane, choose Security Configurations, Create security configuration.\n3. Type a Name for the security configuration.\n4. Choose options for Encryption and Authentication as described in the sections below and then choose Create.\n\n**From TF**\n1. Use following terraform code to create the security configuration for EMR clusters.\n```\nresource \"aws_emr_security_configuration\" \"foo\" {\nname = \"emrsc_example\"\n\nconfiguration = EOF\n{\n\"EncryptionConfiguration\": {\n\"AtRestEncryptionConfiguration\": {\n\"S3EncryptionConfiguration\": {\n\"EncryptionMode\": \"VALUE\"\n},\n\"LocalDiskEncryptionConfiguration\": {\n\"EncryptionKeyProviderType\": \"VALUE\",\n\"AwsKmsKey\": \"KMS_KEY\"\n}\n},\n\"EnableInTransitEncryption\": true\n\"EnableAtRestEncryption\": true\n}\n}\nEOF\n}\n```\n\n2. Use following terraform code to create a new EMR clusters.\nNote: we use EOF in terraform code to pass the json format without escaping it with /  or /n /r\n```\nresource \"aws_emr_cluster\" \"cluster\" {\nname          = \"example_name\"\nrelease_label = \"EMR_RELEASE_VERSION\"\napplications  = [\"Spark\"]\n\nadditional_info = EOF\n{\n\"instanceAwsClientConfiguration\": {\n\"proxyPort\": 8099,\n\"proxyHost\": \"my-proxy.example.com\"\n}\n}\nEOF\n```\n\n**From Command Line**\n1. Use below create-security-configuration command to create a security configuration.\na. For SECURITY_CONFIG_NAME, specify the name of the security configuration. This is the name you specify when you create a cluster that uses this security configuration.\nb. For SEC_CONFIG_DEF, specify an inline JSON structure or the path to a local JSON file, such as file://MySecConfig.json. The JSON parameters define options for Encryption, IAM Roles for EMRFS access to Amazon S3, and Authentication as described in the sections below.\n\n```\naws emr create-security-configuration --name SECURITY_CONFIG_NAME --security-configuration SEC_CONFIG_DEF\n```\n\n2. Use below create-cluster command to create a new cluster.\n```\naws emr create-cluster --release-label EMR_RELEASE_VERSION --instance-type VALUE --instance-count VALUE\n```\nNote: --instance-count parameter, the cluster consists of a single master node running on the EC2 instance type specified. When used together with --instance-count , one instance is used for the master node, and the remainder are used for the core node type.\n\n**References**\n1. https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-create-security-configuration.html\n2. https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-data-encryption-options.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/emr_security_configuration\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/emr_cluster\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/emr/create-cluster.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/emr/create-security-configuration.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "QpyD0/uDEOZrBod8dbwsyg",
        "ruleId": "D9.AWS.CRY.43",
        "category": ""
    },
    {
        "name": "Ensure no Application Load Balancer allows incoming traffic from 0.0.0.0/0 to known TCP DB port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure Application Load Balancers are not exposed incoming traffic from 0.0.0.0/0 to known TCP DB ports.",
        "severity": "High",
        "logic": "ApplicationLoadBalancer where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_DB_TCP_Ports) and protocol in('TCP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1.  Create a new security group to replace the insecure security which is currently attached to the ALB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use set-security-groups command to replace the existing security group with new secure one.\n```\naws elbv2 set-security-groups --region REGION --load-balancer-arn ALB_ARN --security-groups SG_ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-update-security-groups.html\n2. https://docs.aws.amazon.com/cli/latest/reference/elbv2/set-security-groups.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html#cfn-elasticloadbalancingv2-loadbalancer-securitygroups\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb",
        "complianceTag": "Network Ports Security",
        "logicHash": "En0logDa4X0lNxlIm566yg",
        "ruleId": "D9.AWS.NET.84",
        "category": ""
    },
    {
        "name": "Ensure no Application Load Balancer allows incoming traffic from 0.0.0.0/0 to known UDP DB port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure Application Load Balancers are not exposed incoming traffic from 0.0.0.0/0 to known UDP DB ports.",
        "severity": "High",
        "logic": "ApplicationLoadBalancer where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_DB_UDP_Ports) and protocol in('UDP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1.  Create a new security group to replace the insecure security which is currently attached to the ALB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use set-security-groups command to replace the existing security group with new secure one.\n```\naws elbv2 set-security-groups --region REGION --load-balancer-arn ALB_ARN --security-groups SG_ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-update-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elb/apply-security-groups-to-load-balancer.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html#cfn-elasticloadbalancingv2-loadbalancer-securitygroups\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb",
        "complianceTag": "Network Ports Security",
        "logicHash": "kpqjrp6a+Bb4w6NFySSTIg",
        "ruleId": "D9.AWS.NET.85",
        "category": ""
    },
    {
        "name": "Ensure no EC2 instance allows incoming traffic from 0.0.0.0/0 to known UDP DB port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure EC2 instances are not exposed incoming traffic from 0.0.0.0/0 to known UDP DB ports",
        "severity": "High",
        "logic": "Instance where isPublic=true and nics contain [ subnet.routeTable.associations length()>0 and subnet.routeTable.routes contain [ destinationCidrBlock='0.0.0.0/0' and gatewayId like 'igw-%' ] ] should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_DB_UDP_Ports) and protocol in('UDP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console,and Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/ .\n2. In the navigation pane, choose Instances.\n3. Select your instance and, in bottom half of the screen, choose the Security tab.\n4. Security groups lists the security groups that are associated with the instance. Inbound rules displays a list of the inbound rules that are in effect for the instance.\n5. Identify the security group with the scope 0.0.0.0/0 and a Known TCP port from the list in GSL.\n6. On the Edit inbound rules page, modify the traffic source that allow traffic from 0.0.0.0/0 to one of the port from the list.\n7. Select My IP from the Source dropdown list to allow inbound traffic only from your machine or  Select Custom from the Source dropdown list and enter appropriate range of IPs.\n8. Click Save to apply the changes.\n\n**From Command Line**\n1. Identify the security group associated with the instance.Remove the rule which has ingress is 0.0.0.0/0 to one of the from the GSL list.\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --protocol tcp --port PORT_NUMBER --cidr 0.0.0.0/0\n```\n2. Now add the inbound rules with different parameters, Modify the CIDR_BLOCK to appropriate range in order to restrict access from 0.0.0/0 to one of the port from the list.\n```\naws ec2 authorize-security-group-ingress --region REGION --group-name GROUP_NAME --protocol PROTOCOL --port PORT --cidr CIDR_BLOCK\n```\n**From CFT**\nUse the link to the Cloudformation resource from the references.\n\n**From TF**\nUse the link to the terraform resource from the references.\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html#\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance\n5. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html",
        "complianceTag": "Network Ports Security",
        "logicHash": "An92JQy3WoSsfJuSM4e7QA",
        "ruleId": "D9.AWS.NET.81",
        "category": ""
    },
    {
        "name": "Ensure no ECS Services allow ingress from 0.0.0.0/0 to ALL ports and protocols",
        "description": "It is recommended that no ECS Services allows unrestricted ingress access to all ports and protocols.Removing unfettered connectivity to remote console services, such as SSH, reduces a server's exposure to risk.",
        "severity": "High",
        "logic": "EcsService should not have inboundRules with [ scope='0.0.0.0/0' and portTo=0]",
        "remediation": "\n**From Portal**\nFor each ECS service with Security Group, perform the following:\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. In the left pane, click Security Groups\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Inbound Rules tab\n6. Identify the rules to be removed\n7. Click the x in the Remove column\n8. Click Save\n\n**From TF**\nRemove any inbound rule with scope 0.0.0.0/0 and port 0 and create entry for specific port and protocol.\n```\nresource \"aws_security_group\" \"example\" {\n...\ningress {\nfrom_port   = desired_port\nto_port     = desired_port\nprotocol    = \"tcp\"\n-   cidr_blocks = [\"0.0.0.0/0\"]\n+   cidr_blocks = [\"specific_IP_range\"]\n}\n}\n```\n\n**From Command Line**\nUse below command to remove the inbound rules that permits unrestricted ingress to any port and protocol.\n```\naws ec2 revoke-security-group-ingress --region region_name --group-name security_group_name --protocol protocol_name --port port_name --cidr 0.0.0.0/0\n```\nOptionally add a more restrictive ingress rule to the selected Security Group:\n```\naws ec2 authorize-security-group-ingress --region region_name --group-name security_group_name --protocol protocol_name --port port_name --cidr specific_IP_range\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html#create-a-base-security-group\n2. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n3. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/working-with-security-groups.html#updating-security-group-rules\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-security-groups.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html ",
        "complianceTag": "Network Security",
        "logicHash": "vKCJZk0y890S1DhdGsS1Pw",
        "ruleId": "D9.AWS.NET.37",
        "category": ""
    },
    {
        "name": "Ensure no ELB allows incoming traffic from 0.0.0.0/0 to known TCP DB port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure ELBS are not exposed incoming traffic from 0.0.0.0/0 to known TCP DB ports.",
        "severity": "High",
        "logic": "ELB where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_DB_TCP_Ports) and protocol in('TCP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1. Create a new security group to replace the insecure security which is currently attached to the ELB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use the following apply-security-groups-to-load-balancer command to associate a security group with a load balancer in a VPC. The specified security groups override the previously associated security groups.\n```\naws elb apply-security-groups-to-load-balancer --load-balancer-name my-loadbalancer --security-groups sg-ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elb/apply-security-groups-to-load-balancer.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elb",
        "complianceTag": "Network Ports Security",
        "logicHash": "FOe2NWGCRvODE0EuVg7CfQ",
        "ruleId": "D9.AWS.NET.88",
        "category": ""
    },
    {
        "name": "Ensure no ELB allows incoming traffic from 0.0.0.0/0 to known UDP DB port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure ELBS are not exposed incoming traffic from 0.0.0.0/0 to known UDP DB ports.",
        "severity": "High",
        "logic": "ELB where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_DB_UDP_Ports) and protocol in('UDP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1. Create a new security group to replace the insecure security which is currently attached to the ELB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use the following apply-security-groups-to-load-balancer command to associate a security group with a load balancer in a VPC. The specified security groups override the previously associated security groups.\n```\naws elb apply-security-groups-to-load-balancer --load-balancer-name my-loadbalancer --security-groups sg-ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elb/apply-security-groups-to-load-balancer.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elb",
        "complianceTag": "Network Ports Security",
        "logicHash": "edoXwkZni9XLxq/kq8GPDA",
        "ruleId": "D9.AWS.NET.89",
        "category": ""
    },
    {
        "name": "Ensure rotation for customer created symmetric CMKs is enabled",
        "description": "Symmetric Customer Master Key (CMK) rotation is a crucial security practice involving the periodic change of symmetric keys used for encryption and decryption. Unlike asymmetric keys, which have distinct public and private components, symmetric keys use the same key for both operations. Regularly rotating these keys enhances security by limiting the exposure of potentially compromised keys, ensuring data confidentiality, integrity, and compliance with security standards.",
        "severity": "High",
        "logic": "KMS where origin!='AWS_CLOUDHSM' and isCustomerManaged=true and deletionDate<=0 and isSymmetricKey=true should have rotationStatus=true",
        "remediation": "\n**From Portal**\nUse following steps to enable KMS key rotation.\n1. Open the AWS KMS console at https://console.aws.amazon.com/kms.\n2. To change the AWS Region, use the Region selector in the upper-right corner of the page.\n3. Choose Customer managed keys.\n4. Select the desired symmetric CMK you want to enable key rotation from the list of available keys.\n5. Choose Key rotation.\n6. Select Automatically rotate this KMS key every year and then choose Save.\n\n**From TF**\nEnsure Rotation for Customer Created Symmetric CMKs is Enabled:\n```\nresource \"aws_kms_key\" \"kms_key_1\" {\n...\nis_enabled              = true\n+ enable_key_rotation    = true\n}\n```\n\n**From Command Line**\n\nRun the following command to enable key rotation by replacing KMS_KEY_ID with the actual key ID of the symmetric CMK you want to enable rotation for.\n```\naws kms enable-key-rotation --key-id KMS_KEY_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/kms/latest/APIReference/API_EnableKeyRotation.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kms_key\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kms/enable-key-rotation.html\n4. https://aws.amazon.com/kms/faqs/\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "wAHrUSQnoSYlTqmd3E4pyw",
        "ruleId": "D9.AWS.CRY.77",
        "category": ""
    },
    {
        "name": "Ensure that AWS Secrets Manager service enforces data-at-rest encryption using KMS CMKs",
        "description": "Secrets Manager integrates with AWS Key Management Service (AWS KMS) to encrypt every version of every secret with a unique data key that is protected by an AWS KMS customer master key (CMK). This integration protects your secrets under encryption keys that never leave AWS KMS unencrypted. It also enables you to set custom permissions on the CMK and audit the operations that generate, encrypt, and decrypt the data keys that protect your secrets.",
        "severity": "High",
        "logic": "SecretManager should not have kmsKeyId isEmpty()",
        "remediation": "\n**From console**\n1. Open the Secrets Manager console at https://console.aws.amazon.com/secretsmanager\n2. From the list of secrets, choose your secret.\n3. On the secret details page, To update the encryption key, in the Secrets details section, choose Actions, and then choose Edit encryption key.\n4. Select the KMS key or aws/secretsmanager.\n\n**From Command Line**\n1. Use the following CLI command to update the kms hey associated with the secret:\n```\naws secretsmanager update-secret --secret-id MY_SECRET_ID --kms-key-id KMS_KEY_ID\n```\n**From TF**\n```\nresource \"aws_secretsmanager_secret\" \"example\" {\nname = \"example\"\n...\nkms_key_id = \"KMS_KEY_ID\"\n...\n}\n```\n**References**\n1. https://docs.aws.amazon.com/secretsmanager/latest/userguide/manage_update-secret.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/secretsmanager/update-secret.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/secretsmanager_secret#kms_key_id\nCLI: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/secretsmanager/update-secret.html",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "5HOgZCb34Gv72jhKEt79Xw",
        "ruleId": "D9.AWS.CRY.50",
        "category": ""
    },
    {
        "name": "Ensure that Amazon SNS topics enforce Server-Side Encryption (SSE)",
        "description": "Server-side encryption (SSE) lets you store sensitive data in encrypted topics. SSE protects the contents of messages in Amazon SNS topics using keys managed in AWS Key Management Service (AWS KMS). SSE encrypts messages as soon as Amazon SNS receives them. The messages are stored in encrypted form and Amazon SNS decrypts messages only when they are sent.",
        "severity": "High",
        "logic": "SnsTopic should have cryptoKey.enabled=true",
        "remediation": "\n**From Portal**\nPerform the following to set server side encryption to your topic:\n1. Sign on to the  Amazon SNS console\n2. On the navigation panel, choose Topics.\n3. Click on the topic you want to enable encryption for.\n4. In the top-right corner, click Edit.\n5. Under Encryption, select Enable encryption.\n6. Select a customer master key - you can use the default AWS key or a custom key in KMS.\n\n**From TF**\n```\nresource \"aws_sns_topic\" \"example\" {\n...\nname              = \"example_name\"\n+ kms_master_key_id = \"KMS_KEY\"\n}\n```\n\n**From Command Line**\n```\naws sns set-topic-attributes --topic-arn VALUE --attribute-name KmsMasterKeyId --attribute-value KMS_KEY\n```\n\n**References**\n1. https://docs.aws.amazon.com/sns/latest/dg/sns-tutorial-enable-encryption-for-topic.html\n2. https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sns_topic\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/set-topic-attributes.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "oE2LMjGIfP9B0zuCz+tcjQ",
        "ruleId": "D9.AWS.CRY.47",
        "category": ""
    },
    {
        "name": "Ensure that EC2 instance's custom AMI is encrypted at rest",
        "description": "Encrypting EC2 instance's custom AMI adds another layer of protection, keeping the asset compliant in terms of encryption at rest.",
        "severity": "High",
        "logic": "Instance where imageDetails.imageLocation regexMatch /^(?!amazon|aws-marketplace\\/).+/ should not have imageDetails.blockDeviceMappings contain [ ebs.encrypted=false ]",
        "remediation": "\n**From Portal**\n1. Go to 'EC2 Dashboard'\n2. In the left menu, under 'Images', select 'AMIs'\n3. Select the unencrypted AMI\n4. Under 'Actions', select 'Copy AMI'\n5. Select and configure 'Encrypt EBS snapshots of AMI copy'\n6. Press 'Copy AMI'\n\n**From TF**\nTo encrypt a copy of existing AMI, set the 'encrypted' argument under the 'aws_ami_copy' to 'true':\n```\nresource \"aws_ami_copy\" \"ami_copy_example\" {\n..\nencrypted = true\n..\n}\n```\n\n**From Command Line**\nTo, use:\n```\naws ec2 copy-image --source-image-id SOURCE-AMI-ID --source-region SOURCE-REGION --region OUTPUT-REGION --name NEW-AMI-NAME --encrypted\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIEncryption.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ami_copy\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/copy-image.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "cWtByXrTn8rKIs29Wm9lTQ",
        "ruleId": "D9.AWS.CRY.67",
        "category": ""
    },
    {
        "name": "Ensure that EC2 instance's volumes are encrypted",
        "description": "Ensures the security of both data at rest and data in transit between an EC2 Instance and its attached EBS volume.",
        "severity": "High",
        "logic": "Instance should not have volumes contain [ encrypted=false ]",
        "remediation": "\nNote: The following instructions describe how to enable encryption by default. Encrypting attached EBS volumes requires further steps, please follow to the documentation for further instructions.\n\n**From Portal**\n1. Go to 'EC2'\n2. In the upper-right corner, under 'Account attributes', select 'EBS encryption'\n3. Under 'EBS encryption', select 'Manage'\n4. Enable 'Always encrypt new EBS volumes'\n5. Press 'Update EBS encryption'\n\n**From TF**\nTo enable EBS encryption by default for your AWS account, set the 'aws_ebs_encryption_by_default' block as following:\n```\nresource \"aws_ebs_encryption_by_default\" \"ebs_encryption_by_default_example\" {\nenabled = true\n}\n```\n\n**From Command Line**\nTo enable EBS encryption by default for your AWS account in the current region, use:\n```\naws ec2 enable-ebs-encryption-by-default\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ebs_encryption_by_default\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/enable-ebs-encryption-by-default.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "GlKHdKHleAO2uCMByG2dAw",
        "ruleId": "D9.AWS.CRY.66",
        "category": ""
    },
    {
        "name": "Ensure that ECR image scan on push is enabled.",
        "description": "Amazon ECR is a fully managed container registry used to store, manage and deploy container images. ECR Image Scanning assesses and identifies operating system vulnerabilities. Using automated image scans you can ensure container image vulnerabilities are found before getting pushed to production. ECR APIs notify if vulnerabilities were found when a scan completes.",
        "severity": "High",
        "logic": "EcrRepository should have imageScanningConfiguration.scanOnPush=true",
        "remediation": "\n**From Portal**\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region that contains the repository to edit.\n3. In the navigation pane, choose Repositories.\n4. On the Repositories page, choose the Private tab and then select the repository to edit and choose Edit.\n5. Enable the Scan on push toggle, save.\n\n**From Command Line**\nUse the command 'put-image-scanning-configuration', which updates the image scanning configuration for the specified repository.\n```\naws ecr put-image-scanning-configuration --repository-name sample-repo --image-scanning-configuration scanOnPush=true\n```\n\n**From TF**\nUse the resource 'aws_ecr_repository' & property 'image_scanning_configuration.scan_on_push' and set it to 'true'\n```\nresource \"aws_ecr_repository\" \"myrepo\" {\n...\nimage_scanning_configuration {\nscan_on_push = true\n}\n...\n}\n```\n\n**From CFT**\nUse the resource 'AWS::ECR::Repository' & property 'ImageScanningConfiguration::ScanOnPush' and set it to 'true'\n```\nResources:\nImageScanTrue:\nType: AWS::ECR::Repository\nProperties:\n...\nImageScanningConfiguration:\nScanOnPush: true\n...\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-edit.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/put-image-scanning-configuration.html#\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "pHft2Yew1y75D4ZpONwQmw",
        "ruleId": "D9.AWS.CRY.63",
        "category": ""
    },
    {
        "name": "Ensure that ECR image tags are immutable.",
        "description": "You can configure a repository to enable tag mutability to prevent image tags from being overwritten. After the repository is configured for immutable tags, an ImageTagAlreadyExistsException error is returned if you attempt to push an image with a tag that is already in the repository. When tag immutability is enabled for a repository, this affects all tags and you cannot make some tags immutable while others aren't.",
        "severity": "High",
        "logic": "EcrRepository should have imageTagMutability='IMMUTABLE'",
        "remediation": "\n**From Portal**\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region that contains the repository to edit.\n3. In the navigation pane, choose Repositories.\n4. On the Repositories page, choose the Private tab and then select the repository to edit and choose Edit.\n5. For Tag immutability, choose the tag mutability setting for the repository.\n6. Enable the Tag immutability toggle, Save.\n\n**From Command Line**\nTo add a policy with required permissions and appropriate condition as needed, run:\n```\naws ecr put-image-tag-mutability --repository-name NAME --image-tag-mutability IMMUTABLE --region us-east-2\n```\n\n**From TF**\nUse the resource 'aws_ecr_repository' and property 'image_tag_mutability' and set it to 'IMMUTABLE'. See below example;\n```\nresource \"aws_ecr_repository\" \"myrepo\" {\nname                 = \"examplerepo\"\nimage_tag_mutability = \"IMMUTABLE\"\n}\n```\n\n**From CFT**\nUse the resource 'AWS::ECR::Repository' and property 'ImageTagMutability' and set it to 'IMMUTABLE'. See below example;\n```\nResources:\nMyRepository:\nType: AWS::ECR::Repository\nProperties:\n...\nImageTagMutability: \"IMMUTABLE\"\n...\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-tag-mutability.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository\n",
        "complianceTag": "Cloud Assets Management",
        "logicHash": "5pDoT/WYXZPHwJ1jq0HRMQ",
        "ruleId": "D9.AWS.AS.08",
        "category": ""
    },
    {
        "name": "Ensure that ECR repositories are encrypted.",
        "description": "In order to secure your ECR data at rest, make sure you have encrypted your ECR repositories using KMS.",
        "severity": "High",
        "logic": "EcrRepository should not have encryptionConfiguration.kmsKey isEmpty()",
        "remediation": "\n**From Portal**\nCurrently encryption settings for a repository can't be changed once the repository is created, hence create a new repository with enabling encryption and push your current images to it.\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region to create your repository in.\n3. In the navigation pane, choose Repositories.\n4. On the Repositories page, choose the Private tab, and then choose Create repository.\n5. For Visibility settings, verify that Private is selected.\n6. Enter a unique name for your repository.\n7. Enable the KMS Encryption option using the toggle, Create.\n\n**From Command Line**\n1. Create ECR with AWS Managed CMK\n```\naws ecr create-repository --repository-name encryptedrepo --encryption-configuration encryptionType=KMS\n```\n2. Create ECR with Customer Managed CMK.\n```\naws ecr create-repository --repository-name encryptedrepo --encryption-configuration encryptionType=KMS,kmsKey=KmsKeyARN\n```\n\n**From TF**\nUse the resource 'aws_ecr_repository' & property 'image_scanning_configuration.scan_on_push' and set it to 'true'\n```\nresource \"aws_ecr_repository\" \"myrepo\" {\nname= encryptedrepo\n...\nencryption_configuration {\nencryption_type = \"KMS\"\nkms_key = KmsKeyARN\n}\n...\n}\n```\n**From CFT**\nUse the resource 'AWS::ECR::Repository' & property 'ImageScanningConfiguration::ScanOnPush' and set it to 'true'\n```\nResources:\nImageScanTrue:\nType: AWS::ECR::Repository\nProperties:\n...\nEncryptionConfiguration:\nEncryptionType: KMS\nKmsKey: KmsKeyARN\n...\n```\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-create.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/create-repository.html#\n4. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ecr-repository-encryptionconfiguration.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "pSiGYg4tMwR1nXymMkPxKw",
        "ruleId": "D9.AWS.CRY.64",
        "category": ""
    },
    {
        "name": "Ensure that ECS Service managed role doesn't have an overly permissive scope (Contains a wildcard)",
        "description": "Determine the specific resource scope needed by your ECS Service, and then craft IAM policies for these resources only, instead of full resource scope.",
        "severity": "High",
        "logic": "EcsService where not role.path regexMatch /service-role/ should not have role.combinedPolicies contain [ relationType!='AssumeRole' and policyDocument.Statement contain [Effect='Allow' and (Resource contain [$ regexMatch /^(?!arn).*\\*$/] or Resource regexMatch /^(?!arn).*\\*$/) ]]]",
        "remediation": "\nNote: The provided rule covers managed IAM Roles only, AWS service roles are excluded.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Roles'\n3. Select the overly permissive IAM Role\n4. Select the relevant policy\n5. Redefine its permissions based on the principle of least privilege\n\n**From TF**\nTo update an IAM policy, edit the 'Action' argument:\n```\nresource \"aws_iam_policy\" \"example_iam_policy\" {\n..\npolicy = jsonencode({\n..\nStatement = [\n{\n..\nResource = RESOURCES-LIST\n..\n},\n]\n})\n}\n```\n\n**From Command Line**\nTo update a managed policy, use:\n```\naws iam create-policy-version --policy-arn POLICY-ARN --policy-document POLICY-DOCUMENT --set-as-default\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/access-control-identity-based.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "+EW8kdjzFVOhwniQRfauWA",
        "ruleId": "D9.AWS.IAM.110",
        "category": ""
    },
    {
        "name": "Ensure that ECS Service role doesn't have excessive permissions (Contains a wildcard)",
        "description": "Determine the specific permissions needed by your ECS Service, and then craft IAM policies for these permissions only, instead of full administrative privileges. There should not be any policies that grant blanket permissions ('*') to resources. It is recommended and considered a standard security best practice to grant least privileges that is, granting only the permissions required to perform a task.",
        "severity": "High",
        "logic": "EcsService should not have role.combinedPolicies contain [ relationType!='AssumeRole' and policyDocument.Statement contain [Effect='Allow' and (Action contain ['*']) ]]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Roles'\n3. Select the overly permissive IAM Role\n4. Select the relevant policy\n5. Redefine its permissions based on the principle of least privilege\n\n**From TF**\nTo update an IAM policy, edit the 'Action' argument:\n```\nresource \"aws_iam_policy\" \"example_iam_policy\" {\n..\npolicy = jsonencode({\n..\nStatement = [\n{\n..\nAction = ACTIONS-LIST\n..\n},\n]\n})\n}\n```\n\n**From Command Line**\nTo update a managed policy, use:\n```\naws iam create-policy-version --policy-arn POLICY-ARN --policy-document POLICY-DOCUMENT --set-as-default\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/access-control-identity-based.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "RBBO+N/3D0ZLZVoTDrQHIw",
        "ruleId": "D9.AWS.IAM.109",
        "category": ""
    },
    {
        "name": "Ensure that IAM Role doesn't have excessive permissions (Allowing all actions)",
        "description": "To reduce the risk of a misuse or abuse due an overly privileged IAM Role, minimize the actions your IAM Role is allowed to perform according to the principal of least privilege.",
        "severity": "High",
        "logic": "IamRole should not have combinedPolicies contain [ relationType != 'AssumeRole' and policyDocument.Statement contain [ Effect='Allow' and Action contain ['*'] ] ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the AWS IAM console at https://console.aws.amazon.com/iamv2/\n2. From the left pane, under 'Access management' select 'Roles'\n3. Identify and select the relevant IAM Role\n4. Edit its 'Permissions policies' according to the principal of least privilege\n\n**From TF**\nTo edit an IAM Role inline policy, update the policy document referred in the 'policy' argument:\n```\nresource \"aws_iam_role_policy\" \"iam_role_policy_example\" {\n..\npolicy = POLICY-DOCUMENT\n..\n}\n```\nTo edit an IAM Role attached policy, update the policy document correlated to the policy within 'policy_arn' argument:\n```\nresource \"aws_iam_role_policy_attachment\" \"iam_role_policy_attachment_example\" {\n..\nrole       = ROLE-NAME\npolicy_arn = POLICY-ARN\n..\n}\n```\nTo edit an IAM policy document, update the 'actions' arguments within the 'statement' block:\n```\ndata \"aws_iam_policy_document\" \"iam_policy_document_example\" {\nstatement {\n..\nactions = [ ACTIONS-LIST ]\n..\n}\n}\n```\n\n**From Command Line**\nUse following command to update an IAM Role inline policy.\n```\naws iam put-role-policy --role-name ROLE_NAME --POLICY-NAME NAME_OF_POLICY --policy-document POLICY_DOCUMENT_JSON\n```\nUse following command to update a managed policy.\n```\naws iam create-policy-version --policy-arn POLICY_ARN --policy-document POLICY_DOCUMENT_JSON --set-as-default\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/put-role-policy.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/create-policy-version.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "3lB/w/eRPyQESZDZXMjzPA",
        "ruleId": "D9.AWS.IAM.62",
        "category": ""
    },
    {
        "name": "Ensure that Lambda Function execution role policy doesn't have an overly permissive scope (Contains a wildcard)",
        "description": "Determine the specific resource scope needed by your Lambda Functions, and then craft IAM policies for these resources only, instead of full resource scope. Please note, there are few actions where Resource type is accepted as wildcard only, this rule is not applicable to those actions which only support Wildcard '*' as resource type. Pls follow this AWS documentation link for more details: https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonec2.html",
        "severity": "High",
        "logic": "Lambda should not have executionRole.combinedPolicies contain [ relationType!='AssumeRole' and policyDocument.Statement contain [Effect='Allow' and (Resource contain [$ regexMatch /^(?!arn).*\\*$/] or Resource regexMatch /^(?!arn).*\\*$/) ]]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Roles'\n3. Select the overly permissive IAM Role\n4. Select the relevant policy\n5. Redefine its permissions based on the principle of least privilege\n\n**From TF**\nTo update an IAM policy, edit the 'Resource' argument:\n```\nresource \"aws_iam_policy\" \"example_iam_policy\" {\n..\npolicy = jsonencode({\n..\nStatement = [\n{\n..\nResource = RESOURCES-LIST\n..\n},\n]\n})\n}\n```\n\n**From Command Line**\nTo update a managed policy, use:\n```\naws iam create-policy-version --policy-arn POLICY-ARN --policy-document POLICY-DOCUMENT\n```\n\nNote: Additional instructions (For example: How to update inline policies) can be found within the references.\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/access-control-identity-based.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "PcT1e4omMiUgl7ZfdMe94g",
        "ruleId": "D9.AWS.IAM.46",
        "category": ""
    },
    {
        "name": "Ensure that Lambda Function execution role policy doesn't have excessive permissions (Contains a wildcard)",
        "description": "Determine the specific permissions needed by your Lambda Functions, and then craft IAM policies for these permissions only, instead of full administrative privileges.There should not be any policies that grant blanket permissions ('*') to resources. It is recommended and considered a standard security best practice to grant least privileges that is, granting only the permissions required to perform a task.",
        "severity": "High",
        "logic": "Lambda should not have executionRole.combinedPolicies contain [ relationType!='AssumeRole' and policyDocument.Statement contain [Effect='Allow' and (Action contain [$ regexMatch /\\*/] or Action regexMatch /\\*/) ]]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Roles'\n3. Select the overly permissive IAM Role\n4. Select the relevant policy\n5. Redefine its permissions based on the principle of least privilege\n\n**From TF**\nTo update an IAM policy, edit the 'Action' argument:\n```\nresource \"aws_iam_policy\" \"example_iam_policy\" {\n..\npolicy = jsonencode({\n..\nStatement = [\n{\n..\nAction = ACTIONS-LIST\n..\n},\n]\n})\n}\n```\n\n**From Command Line**\nTo update a managed policy, use:\n```\naws iam create-policy-version --policy-arn POLICY-ARN --policy-document POLICY-DOCUMENT\n```\n\nNote: Additional instructions (For example: How to update inline policy) can be found within the references.\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/access-control-identity-based.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "7d5YYMD4BbaJdu4bOeXkxw",
        "ruleId": "D9.AWS.IAM.55",
        "category": ""
    },
    {
        "name": "Ensure that Lambda Function resource-based policy doesn't have excessive permissions (Contains a wildcard)",
        "description": "Determine the specific resource-based permissions needed by your Lambda Functions, and then craft a resource-based policy for these permissions only.",
        "severity": "High",
        "logic": "Lambda should not have resourcePolicy.Statement contain [ Effect='Allow' and (Action contain [$ regexMatch /\\*/] or Action regexMatch /\\*/) ]",
        "remediation": "\n**From Portal**\n1. Go to 'Lambda' dashboard\n2. In the left menu, select 'Functions'\n3. Select the relevant Lambda Function\n4. Under 'Configurations', go to 'Permissions'\n5. Under 'Resource-based policy statements', select the relevant statement\n6. Edit the statement according to the principle of least privilege\n\n**From TF**\nTo edit a resource-based policy, edit the 'action' attribute within 'aws_lambda_permission' block:\n```\nresource \"aws_lambda_permission\" \"lambda_permission_example\" {\n..\naction = ACTION\n..\n}\n```\n\n**From Command Line**\nTo remove a resource-based policy statement from a Lambda Function, run:\n```\naws lambda remove-permission --function-name FUNCTION-NAME --statement-id STATEMENT-ID\n```\nTo apply a resource-based policy statement to a Lambda Function, run:\n```\naws lambda add-permission --function-name FUNCTION-NAME--action ACTION --statement-id STATEMENT-ID --principal PRINCIPAL\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_permission\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/remove-permission.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/add-permission.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "/InnjB1Oz/x/ft0F3Xn3oQ",
        "ruleId": "D9.AWS.IAM.104",
        "category": ""
    },
    {
        "name": "Ensure that RDS database instance enforces SSL/TLS for all connections",
        "description": "Enforcing all connections to RDS database instance to use SSL/TLS provides additional layer of security by encrypting data in transit.",
        "severity": "High",
        "logic": "RDS where dbClusterName isEmpty() and not dbType like '%oracle%' should have parameterGroups contain [ parameters contain [ (parameterName='require_secure_transport' and parameterValue='1') or (parameterName='rds.force_ssl' and parameterValue='1') ] ]",
        "remediation": "\nNote: Oracle databases and databases that are configured under cluster are excluded from this check.\n\n**From Portal**\n1. In AWS management console, go to RDS\n2. In the left pane, choose 'Parameter groups' and select the parameter group associated with the RDS database instance\n3. For MySQL/MariaDB, search the 'require_secure_transport' parameter\n3. For Microsoft SQL Server/PostgreSQL, search the 'rds.force_ssl' parameter\n4. Set its value to '1'\n5. Save\n\n**From TF**\nFor MySQL/MariaDB, set the 'require_secure_transport' parameter within the 'aws_db_parameter_group' resource to '1':\n```\nresource \"aws_db_parameter_group\" \"db_parameter_group_example\" {\n..\nparameter {\nname  = \"require_secure_transport\"\nvalue = \"1\"\n}\n..\n}\n```\nFor Microsoft SQL Server/PostgreSQL, set the 'rds.force_ssl' parameter within the 'aws_db_parameter_group' resource to '1':\n```\nresource \"aws_db_parameter_group\" \"db_parameter_group_example\" {\n..\nparameter {\nname  = \"rds.force_ssl\"\nvalue = \"1\"\n}\n..\n}\n```\n\n**From Command Line**\nTo set the 'require_secure_transport' parameter for MySQL/MariaDB, use:\n```\naws rds modify-db-parameter-group --db-parameter-group-name DB-PARAMETER-GROUP-NAME --parameters \"ParameterName='require_secure_transport',ParameterValue=1,ApplyMethod=pending-reboot\"\n```\nTo set the 'rds.force_ssl' parameter for Microsoft SQL Server/PostgreSQL, use:\n```\naws rds modify-db-parameter-group --db-parameter-group-name DB-PARAMETER-GROUP-NAME --parameters \"ParameterName='rds.force_ssl',ParameterValue=1,ApplyMethod=pending-reboot\"\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithDBInstanceParamGroups.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_parameter_group\n3. https://docs.aws.amazon.com/cli/latest/reference/rds/modify-db-parameter-group.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "XuOyLsEtJvib4q6TCda1eA",
        "ruleId": "D9.AWS.CRY.69",
        "category": ""
    },
    {
        "name": "Ensure that Role names cannot be enumerable",
        "description": "Your Role name might be enumerable by an attacker. There are dictionaries of most common role names that exist in the wild, known as Enumerable Role Names. Attackers are able to easily check if this role exists in your account during a Reconnaissance Stage of an attack. It is recommended to change the role's name to better protect your account.",
        "severity": "High",
        "logic": "IamRole should not have name in($Enumerable_Role_Names)",
        "remediation": "\n**From Portal:**\nWe can not change the IAM role name once it is created. We have to delete the enumerable role and create new role. Set permission same as deleted role.\n1. Open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, choose roles.\n3. Identify and delete enumerable roles.\n4. Create new rule with unique name.\n\n**From Command Line:**\nRun following command to create a new IAM execution role, Use unique name for the role.\n```\naws iam create-role --role-name role_name --assume-role-policy-document file://example_policy.json\n```\n\nReferences:\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/roles-managingrole-editing-console.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/create-role.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "71WCUmmSdpLFoOIvv/l1Zg",
        "ruleId": "D9.AWS.IAM.60",
        "category": ""
    },
    {
        "name": "Ensure that S3 Bucket policy doesn't allow actions from all principals (Condition exists)",
        "description": "Misconfigured S3 buckets can leak private information to the entire internet or allow unauthorized data tampering / deletion. S3 bucket policy should ensure that principal of least privilege is being followed. A condition statement can be used to control the scope of the policy.",
        "severity": "High",
        "logic": "S3Bucket should not have policy.Statement with [Effect='Allow' and (Principal='*' or Principal.AWS='*') and Condition]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under Bucket policy, choose Edit. This opens the Edit bucket policy page.\n5. In the Policy box, edit the existing policy.\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nAdd a policy document with required permissions and appropriate condition as needed as follows:\n```\ndata \"aws_iam_policy_document\" \"example\" {\n...\nstatement {\neffect = \"Allow\"\n\nactions = [\nREQUIRED_ACTIONS\n]\nprincipals {\nREQUIRED_PRINCIPALS\n}\n\nresources = [\n\"S3_BUCKET_ARN\",\n]\n\ncondition {\ntest     = TEST\nvariable = CONTEXT_VARIABLE\n\nvalues = [\nVALUES\n]\n}\n}\n...\n}\n```\n\n**From Command Line**\nTo add a policy with required permissions and appropriate condition as needed, run:\n```\naws s3api put-bucket-policy --bucket BUCKET-NAME --policy file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-policy.html\n2. https://registry.terraform.io/providers/hashicorp/aws/3.3.0/docs/data-sources/iam_policy_document\n3. https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html\n4. https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "t9dqep7z1TkZDh5Tv3UpYw",
        "ruleId": "D9.AWS.IAM.96",
        "category": ""
    },
    {
        "name": "Ensure that S3 Bucket policy doesn't have excessive permissions (Allowing all actions)",
        "description": "Misconfigured S3 buckets can leak private information to the entire internet or allow unauthorized data tampering / deletion. S3 bucket policy should ensure that principal of least privilege is being followed. A condition statement can be used to control the scope of the policy.",
        "severity": "High",
        "logic": "S3Bucket should not have policy.Statement contain [Effect='Allow' and Action contain ['*'] and Condition isEmpty()]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under Bucket policy, choose Edit. This opens the Edit bucket policy page.\n5. In the Policy box, edit the existing policy.\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nAdd a policy document with required permissions and appropriate condition as needed as follows:\n```\ndata \"aws_iam_policy_document\" \"example\" {\n...\nstatement {\neffect = \"Allow\"\n\nactions = [\nREQUIRED_ACTIONS\n]\nprincipals {\nREQUIRED_PRINCIPALS\n}\n\nresources = [\n\"S3_BUCKET_ARN\",\n]\n\ncondition {\ntest     = TEST\nvariable = CONTEXT_VARIABLE\n\nvalues = [\nVALUES\n]\n}\n}\n...\n}\n```\n\n**From Command Line**\nTo add a policy with required permissions and appropriate condition as needed, run:\n```\naws s3api put-bucket-policy --bucket BUCKET-NAME --policy file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-policy.html\n2. https://registry.terraform.io/providers/hashicorp/aws/3.3.0/docs/data-sources/iam_policy_document\n3. https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html\n4. https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "N3d9DJjAobBejDLp76BGIg",
        "ruleId": "D9.AWS.IAM.101",
        "category": ""
    },
    {
        "name": "Ensure that S3 bucket ACLs don't allow 'READ_ACP' access for anonymous / AWS authenticated users",
        "description": "Granting 'READ_ACP' ACL permission within your S3 Bucket allows users to read the bucket ACL. To protect your S3 Bucket's data from unauthorized access, make sure to avoid granting ACL permissions to anonymous / AWS authenticated users.",
        "severity": "High",
        "logic": "S3Bucket should not have acl.grants contain [ (uri = 'http://acs.amazonaws.com/groups/global/AuthenticatedUsers' or uri = 'http://acs.amazonaws.com/groups/global/AllUsers') and premission = 'READ_ACP']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket that you want to create a bucket policy for or whose bucket policy you want to edit.\n3. Choose Permissions.\n4. Under ACL, choose Edit and modify the ACL configuration for the S3 bucket.\n5. On the Edit ACL page, Under Objects uncheck the relevant permission box.\nCheck the box which say \"I understand the effects of these changes on my objects and buckets\".\n6. Choose Save changes, which returns you to the Bucket Permissions page.\n\n**From TF**\nRemove the relevant ACL policy block:\n```\nresource \"aws_s3_bucket_acl\" \"example_s3_bucket_acl\" {\n..\naccess_control_policy {\ngrant {\ngrantee {\nuri  = ACL-URI\ntype = \"Group\"\n}\npermission = \"READ_ACP\"\n..\n}\n```\n\n**From Command Line**\nTo deny the ACLs permissions for everyone, run:\n```\naws s3api put-bucket-acl --bucket BUCKET-NAME --acl private\n```\n\n**References**\n1. https://aws.amazon.com/premiumsupport/knowledge-center/s3-public-access-acl/\n2. https://awscli.amazonaws.com/v2/documentation/api/2.0.34/reference/s3api/put-bucket-acl.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_acl\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "MWpdgDMTFZ4rn6tDuUKW/g",
        "ruleId": "D9.AWS.IAM.35",
        "category": ""
    },
    {
        "name": "Ensure that SQS policy won't allow all actions from all principals",
        "description": "SQS might contain sensitive information. Determine the specific principals the their required actions, and then craft IAM policy with the required permissions.",
        "severity": "High",
        "logic": "Sqs should not have policy.Statement contain [Effect='Allow' and ((Principal='*' or Principal.AWS='*') and Action contain ['%SQS:*%']) and Condition ]",
        "remediation": "\n**From console**\n1. Open the Amazon SQS console at https://console.aws.amazon.com/sqs/.\n2. In the navigation pane, choose Queues.\n3. Choose a queue and choose Edit.\n4. Scroll to the Access policy section.\n5. Edit the access policy statements in the input box, or You can use AWS policy generator tool: https://awspolicygen.s3.amazonaws.com/policygen.html.\n6. In the policy When Effect is 'Allow', Make sure you DO NOT mention Action = 'sqs:*', Principal = '*' and add a condition in the policy statement.\n7. When you finish configuring the access policy, choose Save.\n\n**From CLI**\n1. Create a json file with policy statement where, When Effect is 'Allow', Make sure you DO NOT mention Action = 'sqs:*', Principal = '*' and add a condition in the policy statement.\n2. Use below CLI Command to update the policy.\n```\naws sqs set-queue-attributes --queue-url <Queue url> --attributes <file:update_attributes.json>\n```\n\n**From CFT**\n1. When Effect is 'Allow', Make sure you DO NOT mention Action = 'sqs:*', Principal = '*' and add a condition in your policy document.\nSee below sample template.\n\nResource: AWS::SQS::QueuePolicy\n\n```\nResources:\nSampleSQSPolicy:\nType: AWS::SQS::QueuePolicy\nProperties:\nQueues:\n- 'https://sqs:us-east-2.amazonaws.com/444455556666/myqueue'\nPolicyDocument:\nStatement:\nAction: [ 'SQS:SendMessage' , 'SQS:ReceiveMessage' ]\nEffect: Allow\nPrincipal:\nAWS:\n- '111122223333'\nCondition:\nArnEquals:\n'aws:SourceArn': '${aws_sns_topic.example.arn}'\n```\n\n**From TF**\n1. When Effect is 'Allow', Make sure you DO NOT mention Action = 'sqs:*', Principal = '*' and add a condition in your policy document.\nSee below sample template.\n```\nresource \"aws_sqs_queue_policy\" \"test\" {\nqueue_url = \"https://sqs:us-east-2.amazonaws.com/444455556666/queue2\"\n\npolicy = <<POLICY\n{\n\"Version\": \"2012-10-17\",\n\"Id\": \"sqspolicy\",\n\"Statement\": [\n{\n\"Sid\": \"First\",\n\"Effect\": \"Allow\",\n\"Principal\": \"AWS\":\"111122223333\",\n\"Action\": \"sqs:SendMessage\",\n\"Resource\": \"arn:aws:sqs:us-east-2:444455556666:queue2\",\n\"Condition\": {\n\"ArnEquals\": {\n\"aws:SourceArn\": \"${aws_sns_topic.example.arn}\"\n}\n}\n}\n]\n}\nPOLICY\n}\n```\n**References**\n1. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-authentication-and-access-control.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/set-queue-attributes.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-sqs-policy.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue_policy",
        "complianceTag": "Identity and Access Management",
        "logicHash": "OQ0zb2gxxOSM/RnSpj7X7Q",
        "ruleId": "D9.AWS.IAM.83",
        "category": ""
    },
    {
        "name": "Ensure that SageMaker Notebook does not have direct internet access",
        "description": "When your AWS SageMaker notebook instances are publicly accessible, any machine outside the VPC can establish a connection to these instances, increasing the attack surface and the opportunity for malicious activity. It is recommended that the Amazon SageMaker notebook instances are not publicly accessible.",
        "severity": "High",
        "logic": "SageMakerNotebook should have directInternetAccess = 'Disabled'",
        "remediation": "\n**From Portal:**\nThere is no possibility to disable Direct Internet Access to your existing notebook instances. To ensure that your AWS SageMaker notebook instances do not have direct internet access, you need to re-create these. If you configure your SageMaker instance without a VPC, then by default direct internet access is enabled on your instance. You should configure your instance with a VPC and change the default setting to Disable - Access the internet through a VPC.\n\nWhile creating a new SageMaker, ensure notebook instances do not have direct internet access.\n1. Open the SageMaker console\n2. Navigate to Notebook instances.\n3. Delete the instance that has direct internet access enabled. Choose the instance, choose Actions, then choose stop.\n4. After the instance is stopped, choose Actions, then choose delete.\n5. Choose Create notebook instance. Provide the configuration details.\n6. Expand the Network section. Then choose a VPC, subnet, and security group. Under Direct internet access, choose Disable - Access the internet through a VPC.\n7. Choose Create notebook instance.\n\n**From TF:**\nUse direct_internet_access parameter set as Disabled to disable internet access to notebook. If value is set to Disabled, the notebook instance will be able to access resources only in your VPC, and will not be able to connect to Amazon SageMaker training and endpoint services unless you configure a NAT Gateway in your VPC.\n```\nresource \"aws_sagemaker_notebook_instance\" \"example_name\" {\nname          = example_name\nrole_arn      = sagemaker_role_arn\ninstance_type = instance_type\nsecurity_groups = aws_security_group_sg_id\nsubnet_id = VPC_subnet_id\ndirect_internet_access = Disabled\ntags = {\nName = \"SageMaker\"\n}\n}\n```\n\n**From Command Line:**\nUse following command to create new notebook instance with direct internet access option set as disabled.\n```\naws sagemaker create-notebook-instance --region region_name --notebook-instance-name example_instance_name --instance-type type_of_instance --role-arn AmazonSageMaker_ExecutionRole_arn --kms-key-id kms_key_arn --subnet-id subnet_id --security-group-ids sg_ID --direct-internet-access Disabled\n```\n\nReferences:\n1. https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sagemaker_notebook_instance#direct_internet_access\n3. https://docs.aws.amazon.com/cli/latest/reference/sagemaker/create-notebook-instance.html ",
        "complianceTag": "Network Security",
        "logicHash": "PmfFZsrRx78QJ84y8RPUlw",
        "ruleId": "D9.AWS.NET.49",
        "category": ""
    },
    {
        "name": "Ensure that Static website hosting is disabled on your S3 bucket",
        "description": "Configuring a static website on a S3 bucket requires you to grant public read access to the bucket. To make your bucket publicly readable, you must disable block public access settings for the bucket and write a bucket policy that grants public read access.\nThere is a potential risk of exposure when you turn off block public access settings to make your bucket public, anyone on the internet can access your bucket. We recommend that you block all public access to your buckets.",
        "severity": "High",
        "logic": "S3Bucket should not have website.indexDocumentSuffix",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open Amazon S3 dashboard at https://console.aws.amazon.com/s3/.\n2. Choose the name of the bucket for which you want to disable static website feature.\n3. Choose Properties.\n4. Edit Static Website hosting and choose disable.\n5. Save changes.\n\n**From TF**\nWhile creating a S3 bucket keep ACL private.\n```\nresource \"aws_s3_bucket\" \"test\" {\nbucket = \"s3-website-test.hashicorp.com\"\nacl    = \"private\"\nversioning {\nenabled = true\n}\n- website {\n-   index_document = ...\n-   error_document = ...\n- }\n}\n```\n\n**From Command Line**\nTo disable Static website hosting on your S3 bucket, run:\n```\naws s3api delete-bucket-website --bucket BUCKET-NAME\n```\n\n**References**\n1. http://docs.aws.amazon.com/AmazonS3/latest/user-guide/static-website-hosting.html\n2. https://docs.aws.amazon.com/general/latest/gr/s3.html\n3. https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteEndpoints.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket",
        "complianceTag": "Network Security",
        "logicHash": "6Sz0qOGgAYV/JEyVDLTKEw",
        "ruleId": "D9.AWS.NET.20",
        "category": ""
    },
    {
        "name": "Ensure that VPC Endpoint policy does not provide excessive permissions",
        "description": "Services with sensitive information are connected to VPC Endpoint. Determine the specific actions needed by the endpoint, and then craft IAM policy with the required permissions. Disclaimer: Endpoint policies are not supported by all endpoint services. If a service does not support endpoint policies, the endpoint allows full access to the service. For more information, see View endpoint policy support link in reference section",
        "severity": "High",
        "logic": "VpcEndpoint should not have policy.Statement contain [Effect='Allow' and (Action  = '*'  or Action contain ['%s3:*%']  or Action contain ['%dynamodb:*%'] )]",
        "remediation": "\n**From Portal**\nDefault policy allows vpc resources full access to the services behind the endpoint. We should limit this policy and follow least privilege guidelines. Perform the following steps in order to set a new VPC Endpoint policy via AWS Console:\n\n1. Sign in to the Amazon VPC console at https://console.aws.amazon.com/vpc/\n2. Choose Endpoints from the left VPC navigation panel\n3. Choose relevant endpoint and click Actions\n4. Edit the policy and limit the principal and/or the actions and/or the resources in the statement.\n\nNote: You can use AWS policy generator tool: https://awspolicygen.s3.amazonaws.com/policygen.html\n\n**From Command Line**\n```\naws ec2 modify-vpc-endpoint --vpc-endpoint-id Endpoint_ID --policy-document Path_to_JSON_file_with_updated_policy\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-access.html\n2. https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.html#vpce-endpoint-policy-support\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify-vpc-endpoint.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "ogryvLF6o6aqiznE9OfNxw",
        "ruleId": "D9.AWS.IAM.59",
        "category": ""
    },
    {
        "name": "Ensure that all authorization Type in API Gateway are not set to None",
        "description": "when authorization Type is set to None any one with access to the APIGateway network can use it if the gateway is public anyone can use the API ",
        "severity": "High",
        "logic": "ApiGateway where not authorizers should not have resources contain-any [ methods contain-any [ authorizationType='NONE' ] ]",
        "remediation": "\n**From TF**\nSet a authorizer to your api Gateway\n```\nresource \"aws_api_gateway_method\" \"test\" {\nrest_api_id   = aws_api_gateway_rest_api.this.id\nresource_id   = aws_api_gateway_resource.this.id\n+ http_method   = \"...\"     # i.e \"GET\", \"PUT\", \"OPTIONS\": if http_method != \"OPTIONS\"\n+ authorization = \"...\"     #                                 authorization != \"NONE\"\n# OR\n+ http_method   = \"OPTIONS\"  # if http_method == \"OPTIONS\"\n+ authorization = \"NONE\"     # authorization = \"NONE\"\nauthorizer_id = aws_api_gateway_authorizer.this.id\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-to-api.html\n",
        "complianceTag": "Network Security",
        "logicHash": "/SAUQIHNlsF8mxpbr3ZYgw",
        "ruleId": "D9.AWS.NET.67",
        "category": ""
    },
    {
        "name": "Ensure that all requestValidatorId in API Gateway are not null",
        "description": "before you send the API request to your server to be process it is recommended to validate the inputs to avoid several types of attacks",
        "severity": "High",
        "logic": "ApiGateway should not have resources contain-any [ methods contain-any [ requestValidatorId isEmpty() ] ]",
        "remediation": "\n**From Portal:**\nUse following steps to enable a request validator on a method.\n1. Sign in to the API Gateway console.\n2. Choose the relevant API.\n3. Select the method which has no validation.\n5. Click 'Method Request'.\n6. Choose the pencil icon of Request Validator under Settings.\n7. Choose validation option from the Request Validator drop-down list. Then choose the check mark icon to save your choice.\n\nReferences:\n1. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-validation-set-up.html\n2. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-request-validation.html ",
        "complianceTag": "Network Security",
        "logicHash": "ITOaTlw8auOsAeIewQr9OQ",
        "ruleId": "D9.AWS.NET.68",
        "category": ""
    },
    {
        "name": "Ensure that an API Key is required on a Method Request",
        "description": "API keys are string tokens that you provide to client application developers to grant access to your APIs. You can use API keys together with usage plans or Lambda authorizers to control access to your APIs. API Gateway can generate API keys on your behalf, or you can import them from a CSV file.",
        "severity": "High",
        "logic": "ApiGateway should have resources contain-all [ (methods contain-all [ apiKeyRequired=true ]) or (methods isEmpty()) ] or  authorizers isEmpty() = false",
        "remediation": "\n**From Portal**\nFollow the below steps to configure an API method to require an API key\n1. Sign in to the AWS Management Console and open the API Gateway console at https://console.aws.amazon.com/apigateway/.\n2. Choose a REST API.\n3. In the API Gateway main navigation pane, choose Resources.\n4. Under Resources, create a new method or choose an existing one.\n5. Choose Method Request.\n6. Under the Settings section, choose true for API Key Required.\n7. Select the checkmark icon to save the settings.\n8. Deploy or redeploy the API for the requirement to take effect.\n\nNote: If the API Key Required option is set to false and you don't execute the previous steps, any API key that's associated with an API stage isn't used for the method.\n\n**From TF**\n```\nresource \"aws_api_gateway_method\" \"test\" {\nrest_api_id       = aws_api_gateway_rest_api.testapi.id\nresource_id       = aws_api_gateway_resource.testapi.id\nhttp_method       = \"GET\" # HTTP methods of DELETE, GET, HEAD, OPTIONS, PATCH, POST, and PUT.\nauthorization     = \"NONE\"\n+ api_key_required  = true\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-setup-api-key-with-console.html\n2. https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-create-api.html\n3. https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-deploy-api.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_method ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "RdX/Q3csWb7pgN8GvHuPNw",
        "ruleId": "D9.AWS.CRY.37",
        "category": ""
    },
    {
        "name": "Ensure that custom IAM Role doesn't have an overly permissive scope (Contains a wildcard)",
        "description": "To reduce the risk of a misuse or abuse due an overly privileged IAM Role, minimize the scope your IAM Role is allowed to perform actions on, according to the principal of least privilege.",
        "severity": "High",
        "logic": "IamRole where not path regexMatch /service-role/ should not have combinedPolicies contain [ (id regexMatch /^((?!arn:aws:iam::aws:policy).)*$/ and relationType != 'AssumeRole') and policyDocument.Statement contain [ Effect='Allow' and (Resource contain ['*']) and Action contain [$ regexMatch /^(?!sts|ssm|cloudwatch|ec2messages|ssmmessages|logs|route53).*$/] ] ]",
        "remediation": "\nNote: The provided rule covers managed IAM Roles only: AWS service-roles and AWS service-role policies are excluded. In addition, this rule ignores any policy document block with one or more actions from the following action groups: sts, ssm, cloudwatch, ec2messages, ssmmessages, logs, route53.\n\n**From Portal**\n1. Sign in to the AWS Management Console and open the AWS IAM console at https://console.aws.amazon.com/iamv2/\n2. From the left pane, under 'Access management' select 'Roles'\n3. Identify and select the relevant IAM Role\n4. Edit its 'Permissions policies' according to the principal of least privilege\n\n**From TF**\nTo edit an IAM Role inline policy, update the policy document referred in the 'policy' argument:\n```\nresource \"aws_iam_role_policy\" \"iam_role_policy_example\" {\n..\npolicy = POLICY-DOCUMENT\n..\n}\n```\nTo edit an IAM Role attached policy, update the policy document correlated to the policy within 'policy_arn' argument:\n```\nresource \"aws_iam_role_policy_attachment\" \"iam_role_policy_attachment_example\" {\n..\nrole       = ROLE-NAME\npolicy_arn = POLICY-ARN\n..\n}\n```\nTo edit an IAM policy document, update the 'resource' argument within the 'statement' block:\n```\ndata \"aws_iam_policy_document\" \"iam_policy_document_example\" {\nstatement {\n..\nresource = [ RESOURCE-LIST ]\n..\n}\n}\n```\n\n**From Command Line**\nTo update an IAM Role inline policy, use:\n```\naws iam put-role-policy --role-name ROLE-NAME --POLICY-NAME --policy-document POLICY-DOCUMENT-JSON\n```\nTo update a managed policy, use:\n```\naws iam create-policy-version --policy-arn POLICY-ARN --policy-document POLICY-DOCUMENT-JSON --set-as-default\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/put-role-policy.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/create-policy-version.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "SEj5ZpH+Q8dAlnliuTO0Ig",
        "ruleId": "D9.AWS.IAM.108",
        "category": ""
    },
    {
        "name": "Ensure that encryption is enabled for AWS EBS Snapshot",
        "description": "Enable encryption on your EBS Snapshot, in order to protect your data\nand metadata from breaches or unauthorized access.",
        "severity": "High",
        "logic": "EbsSnapshot should have encrypted=true",
        "remediation": "\nNote: Since EBS Snapshot can not be changed, you can copy the snapshot and add the encryption, then you can delete the unencrypted Snapshot.\n\n**From Portal**\n1. Nevigate to EBS under the AWS EC2 service in the AWS Management Console.\n2. Select the source snapshot that you want to encrypt.\n2. Under the \"Actions\" menu, select \"Copy snapshot\".\n3. In the \"Copy Snapshot\" wizard, choose the destination region and availability zone.\n4. Under the \"Encryption\" section, select \"Enable encryption\" and choose the KMS key.\n5. Click \"Copy snapshot\" to start the copy process and create a new encrypted snapshot.\n\n\n\n**From TF**\n```\nresource \"aws_ebs_snapshot_copy\" \"example\" {\nsource_snapshot_id = SNAPSHOT_ID\nsource_region      = REGION\nencrypted          = true\nkms_key_id         = KMS_KEY_ARN\n}\n```\n\n**From Command Line**\n\n```\naws ec2 copy-snapshot --source-region <SOURCE_REGION> --source-snapshot-id <SOURCE_SNAPSHOT_ID> --encrypted --kms-key-id <KMS_KEY_ARN>\n```\n\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html#ebs-create-snapshot-console-encrypt\n2. https://docs.aws.amazon.com/cli/latest/reference/ec2/create-snapshot.html#options\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ebs_snapshot#create-snapshots-with-encryption-enabled\n\n\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "pDvTjB/wkFRtDUACaId6UA",
        "ruleId": "D9.AWS.CRY.76",
        "category": ""
    },
    {
        "name": "Ensure that encryption is enabled for AWS RDSDBCluster Storage",
        "description": "Enable encryption on your RDS DB Clusters, in order to protect your data\nand metadata from breaches or unauthorized access.",
        "severity": "High",
        "logic": "RDSDBCluster should have storageEncrypted=true",
        "remediation": "\nNote: Since RDS DB Cluster storage encryption can not be changed, you can create new RDS DB Cluster with Storge encrypted.\n\n**From Portal**\n1. Log in to the AWS Management Console and navigate to the Amazon RDS console.\n2. Click \"Create database\".\n3. Choose \"Amazon Aurora\" as the database engine.\n4. Select the edition and version that you want to use.\n5. In the \"Settings\" section, configure the DB cluster identifier, credentials, network settings, and other options as desired.\n6. In the \"Additional configuration\" section, select the VPC and subnets that you want to use.\n7. In the \"Encryption\" section, select \"Enable encryption\" and choose the KMS key that you want to use for encryption.\n8. Review the configuration and click \"Create database\" to create the encrypted RDS DB Cluster.\n\n\n**From TF**\n```\nresource \"aws_rds_cluster\" \"example\" {\nengine             = \"aurora-mysql\"\nengine_version     = \"<version>\"\ndb_cluster_identifier = \"<identifier>\"\nmaster_username    = \"<username>\"\nmaster_password    = \"<password>\"\nvpc_security_group_ids = [\"<security-group-ids>\"]\ndb_subnet_group_name   = \"<subnet-group>\"\nstorage_encrypted   = true\nkms_key_id          = \"<kms-key-id>\"\n}\n```\n\n**From Command Line**\n\n```\naws rds create-db-cluster --engine aurora --engine-version <version> --db-cluster-identifier <identifier> --master-username <username> --master-user-password <password> --vpc-security-group-ids <security-group-ids> --db-subnet-group-name <subnet-group> --storage-encrypted --kms-key-id <kms-key-id>\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.StorageEncryption\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/rds_cluster\n3. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.StorageEncryption\n4. https://docs.aws.amazon.com/cli/latest/reference/rds/create-db-cluster.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "wj48D1Rw5Bn7jBE+wXSmXg",
        "ruleId": "D9.AWS.CRY.70",
        "category": ""
    },
    {
        "name": "Ensure that encryption is enabled for EFS file systems",
        "description": "Enable encryption of your EFS file systems in order to protect your data and metadata from breaches or unauthorized access and fulfill compliance requirements for data-at-rest encryption within your organization.",
        "severity": "High",
        "logic": "EFS should have encrypted=true",
        "remediation": "\n**From Portal**\nYou can enable encryption of data at rest when creating an Amazon EFS file system. Following are the steps to encrypt a File System at Rest Using the AWS Console.\n1. Open the Amazon Elastic File System console at https://console.aws.amazon.com/efs/.\n2. Choose 'Create file system' to open the file system creation wizard.\n3. Check 'Enable encryption of data at rest' checkbox.\n4. Click on 'Customize encryption settings' and choose the KMS Key from dropdown list to enable encryption using your own KMS CMK key.\n\nNote: There is no functionality that allows you to encrypt existing EFS if the encryption wasn't enabled during the creation of Amazon EFS process. In order to encrypt an existing Amazon EFS, you need to create a new Amazon EFS and copy all the data from the existing Amazon EFS onto the new one with encryption enabled.\n\n**From TF**\n```\nresource \"aws_efs_file_system\" \"example\"{\ncreation_token = \"default-efs\"\n+ encrypted = true\n+ kms_key_id = aws_kms_key.default-kms.arn\n}\n```\n\n**From Command Line**\n```\naws efs create-file-system --creation-token VALUE --performance-mode VALUE --encrypted --kms-key-id KEY_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/efs/latest/ug/encryption-at-rest.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_file_system\n3. https://docs.aws.amazon.com/whitepapers/latest/efs-encrypted-file-systems/creating-an-encrypted-file-system-using-the-aws-cli.html\n4. https://docs.aws.amazon.com/cli/latest/reference/efs/create-file-system.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "wMS6295xhdbNpBO4lUmVnA",
        "ruleId": "D9.AWS.CRY.22",
        "category": ""
    },
    {
        "name": "Ensure that encryption of data at rest is enabled on Elasticsearch domains",
        "description": "The encryption of data at rest is a security feature that helps prevent unauthorized access to your data. When the feature is enabled, it encrypts sensitive information on your Elasticsearch domains and their storage systems such as Indices, Elasticsearch Logs, Swap files, automated snapshots and all other data in the application directory. The ElasticSearch at-rest encryption feature uses AWS KMS service to store and manage the encryption keys.",
        "severity": "High",
        "logic": "ElasticSearchDomain should have encryptionAtRestOptions.enabled=true",
        "remediation": "\n**From Portal**\nBy default,  data at rest encryption is not enabled for Amazon OpenSearch Service domains, and you can't enable encryption for existing domains. To enable the encryption feature, you must create another domain and migrate your data. Encryption of data at rest requires Elasticsearch 5.1 or later.\n\n1. Sign in to your AWS Console and select the Amazon OpenSearch Service.\n2. Select Create a new domain.\n3. Under Deployment type, go to 'Version' and select ElasticSearch version from dropdown list.\n4. Under 'Encryption' section, select the checkmark 'Enable encryption of data at rest'\n5. Continue configure your cluster for other settings and click on Create.\n\nNote: Follow 'References' section for detailed guidelines for creating a new domain.\n\n**From TF**\n```\nresource \"aws_elasticsearch_domain\" \"test\" {\ndomain_name           = \"example\"\nelasticsearch_version = \"1.5\"\n\n+ encrypt_at_rest {\n+     enabled = true\n+ }\n}\n```\n\n**From Command Line**\n```\naws es create-elasticsearch-domain --region us-east-1 --domain-name NEW_DOMAIN_NAME --elasticsearch-version VERSION_VALUE --elasticsearch-cluster-config InstanceType=EXAMPLE_INSTANCE_TYPE,InstanceCount=VALUE --ebs-options EBSEnabled=TRUE/FALSE,VolumeType=VALUE,VolumeSize=VALUE --access-policies file://domain_policy.json --vpc-options SubnetIds=SUBNET_ID,SecurityGroupIds=SG_ID --encryption-at-rest-options Enabled=TRUE,KmsKeyId=KMS_KEY\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomains\n2. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/encryption-at-rest.html\n3. https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elasticsearch_domain\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/es/create-elasticsearch-domain.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "EKPZAy6ytj9OX12SxSVMgg",
        "ruleId": "D9.AWS.CRY.45",
        "category": ""
    },
    {
        "name": "Ensure that encryption-at-rest is enabled for RDS Instances",
        "description": "Encrypt Amazon RDS instances and snapshots at rest, by enabling the encryption option for your Amazon RDS DB instance. Amazon RDS encrypted DB instances use the industry standard AES-256 encryption algorithm to encrypt your data on the server that hosts your Amazon RDS DB instances.",
        "severity": "High",
        "logic": "RDS should have isStorageEncrypted=true",
        "remediation": "\n**From Portal**\nTo create an encrypted RDS instance:\n1. Sign in to the AWS Management Console and open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the upper-right corner of the Amazon RDS console, choose the AWS Region in which you want to create the DB instance.\n3. In the navigation pane, choose Databases.\n4. Choose Create database.\n5. In Choose a database creation method, select Standard Create.\n6. Set the other options as per your requirement\n7. In Advanced Configuration section, make sure that Enable encryption option is selected\n8. Choose Create database\n\nTo encrypt existing unencrypted database, follow these steps:\n\n1. Encrypt an unencrypted snapshot that you take from an unencrypted read replica of the DB instance.\n2. Restore a new DB instance from the encrypted snapshot to deploy a new encrypted DB instance.\n\nNote: Depending on the type of the database ou are using, you might want to consider using a replication service to replicate the data.\n\n**From TF**\nadd storage_encrypted flag to terraform file to create encrypted database instance:\n```\nresource \"aws_db_instance\" \"db_instance_example\" {\n...\nstorage_encrypted = true\n...\n}\n```\n\n**From Command Line**\nTo create an encrypted database, run:\n```\naws rds create-db-instance --engine ENGINE  --db-instance-identifier DB_IDENTIFIER --allocated-storage SIZE  --db-instance-class DB_INSTANCE_CLASS --vpc-security-group-ids SECURITY_GROUP_ID --db-subnet-group SUBNET_GROUP --master-username USER --master-user-password PWD -backup-retention-period DAYS --storage-encrypted\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\n2. https://aws.amazon.com/premiumsupport/knowledge-center/rds-encrypt-instance-mysql-mariadb/\n3. https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#storage_encrypted",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "syE0D5MAxlxBTs736B4Aow",
        "ruleId": "D9.AWS.CRY.05",
        "category": ""
    },
    {
        "name": "Ensure that node-to-node encryption is enabled for Elasticsearch service",
        "description": "The node-to-node encryption capability provides an additional layer of security by implementing Transport Layer Security (TLS) for all communications between Elasticsearch instances in a cluster. It ensures that any data you send to your Amazon Elasticsearch Service domain over HTTPS remains encrypted in-flight while it is being distributed and replicated between the nodes.",
        "severity": "High",
        "logic": "ElasticSearchDomain should not have nodeToNodeEncryptionOptions.enabled=false",
        "remediation": "\n**From Portal**\nBy default,  node-to-node encryption is not enabled for Amazon OpenSearch Service domains, and you can't enable encryption for existing domains. To enable the encryption feature, you must create another domain and migrate your data. Node-to-node encryption requires Elasticsearch 6.0 or later.\n\n1. Sign in to your AWS Console and select the Amazon OpenSearch Service.\n2. Select Create a new domain.\n3. Under Deployment type, go to 'Version' and select ElasticSearch version from dropdown list.\n4. Under 'Encryption' section, select the checkmark 'Node-to-node encryption'\n5. Continue configure your cluster for other settings and click on Create.\n\n**From TF**\n```\nresource \"aws_elasticsearch_domain\" \"test\" {\ndomain_name           = \"example\"\nelasticsearch_version = \"1.5\"\n\n+ node_to_node_encryption {\n+   enabled = true\n+ }\n\ntags = {\nDomain = \"TestDomain\"\n}\n}\n```\n\n**From Command Line**\n```\naws es create-elasticsearch-domain --region REGION_NAME --domain-name NEW_DOMAIN_NAME --elasticsearch-version VERSION_VALUE --elasticsearch-cluster-config InstanceType=EXAMPLE_INSTANCE_TYPE,InstanceCount=VALUE --ebs-options EBSEnabled=TRUE/FALSE,VolumeType=VALUE,VolumeSize=VALUE --access-policies file://domain_policy.json --vpc-options SubnetIds=SUBNET_ID,SecurityGroupIds=SG_ID --encryption-at-rest-options Enabled=TRUE,KmsKeyId=KMS_KEY --node-to-node-encryption-options Enabled=true\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomains\n2. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/encryption-at-rest.html\n3. https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elasticsearch_domain\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/es/create-elasticsearch-domain.html\n6. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html#snapshot-based-migration\n7. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/ntn.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "x59IVmgPOsCxSy8sSEl8vw",
        "ruleId": "D9.AWS.CRY.46",
        "category": ""
    },
    {
        "name": "Ensure that public System Manager Documents include parameters",
        "description": "In case the SSM Document should be publicly exposed, then make sure to include parameters for any sensitive information like S3 bucket names, keys, users, passwords etc.",
        "severity": "High",
        "logic": "SystemManagerDocument where accountSharingInfoList contain [ accountId='all' ] should not have parameters isEmpty()",
        "remediation": "\n**From Portal**\nUse following steps to create a parameter\n1. Open the AWS Systems Manager console at https://console.aws.amazon.com/systems-manager/.\n2. In the navigation pane, choose Parameter Store or If the AWS Systems Manager home page opens first, choose the menu icon to open the navigation pane, and then choose Parameter Store.\n3. Choose Create parameter.\n4. In the Name box, enter a hierarchy and a name. For example, enter /Test/helloWorld.\n5. In the Description box, type a description that identifies this parameter as a test parameter.\n6. For Parameter tier choose either Standard or Advanced. For more information about advanced parameters, see Managing parameter tiers.\n7. For Type, choose String, StringList, or SecureString.\n8. In the Value box, type a value.\n9. Choose Create parameter.\n10. In the parameters list, choose the name of the parameter you just created. Verify the details on the Overview tab. If you created a SecureString parameter, choose Show to view the unencrypted value.\n\n**References**\n1. https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-create-console.html\n2. https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-doc-syntax.html\n3. https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html\n4. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html\n5. https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store ",
        "complianceTag": "Vulnerability and Threat Management",
        "logicHash": "XakYHsHax+8NTsqqmzot9g",
        "ruleId": "D9.AWS.VLN.05",
        "category": ""
    },
    {
        "name": "Ensure that root Volume Encryption is enabled for AWS Workspace",
        "description": "Enable encryption on your Workspace, in order to protect your data and\nmetadata from breaches or unauthorized access.",
        "severity": "High",
        "logic": "Workspace should have rootVolumeEncryptionEnabled=true",
        "remediation": "\n\n**From Portal**\n1. Open the AWS Management Console and navigate to the WorkSpaces service.\n2. Under WorkSpaces click on \"Create Workspaces\"\n3. Select a directory\n4. For Identify users, enter the Username, First Name. Last Name, and Email. Then choose Next.\n5. Select Bundle and fill the WorkSpaces configuration part\n6. Under \"Customization\" section, open the \"Encrypt root and user volume\" and select \"Encrypt root volume\"\n7. Review and click on \"Create WorkSpaces\"\n\n**From TF**\n```\nresource \"aws_workspaces_workspace\" \"example\" {\ndirectory_id = DIRECTORY_ID\nbundle_id    = BUNDLR_ID\nuser_name    = USER_NAME\n\nroot_volume_encryption_enabled = true\nuser_volume_encryption_enabled = true\nvolume_encryption_key          = \"alias/aws/workspaces\"\n\nworkspace_properties {\ncompute_type_name                         = \"VALUE\"\nuser_volume_size_gib                      = 10\nroot_volume_size_gib                      = 80\nrunning_mode                              = \"AUTO_STOP\"\nrunning_mode_auto_stop_timeout_in_minutes = 60\n}\n```\n\n**From Command Line**\n1. create a Json file with the requirment parameters.\n```\n{\n\"Workspaces\" : [\n{\n\"DirectoryId\" : DIRECTORY_ID,\n\"UserName\" : USER_NAME,\n\"BundleId\" : BUNDLE_ID,\n\"VolumeEncryptionKey\": ENCRYPTION_KEY,\n\"UserVolumeEncryptionEnabled\": true,\n\"RootVolumeEncryptionEnabled\": true\n}\n]\n}\n\n```\n2. Run the command:\n```\naws workspaces create-workspaces --cli-input-json PATH_TO_JSON_FILE\n```\n\n\n\n**References**\n1. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/workspaces_workspace\n2. https://docs.aws.amazon.com/cli/latest/reference/workspaces/create-workspaces.html\n3. https://docs.aws.amazon.com/workspaces/latest/adminguide/encrypt-workspaces.html#kms-permissions-key-users\n\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "I+JMEUIn3spIQxrAm2qHrw",
        "ruleId": "D9.AWS.CRY.74",
        "category": ""
    },
    {
        "name": "Ensure that sensitive parameters are encrypted",
        "description": "Sensitive parameters in AWS System Manager Parameter Store should be encrypted using the SecureString type.",
        "severity": "High",
        "logic": "SystemManagerParameter where name regexMatch /(pass|user|login|pwd|key|secret)/ should have parameterType='SecureString'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console.\n2. Navigate to SSM dashboard at https://console.aws.amazon.com/systems-manager/.\n3. In the navigation panel, under the Application Management section, choose Parameter Store.\n4. Choose the SSM parameter that you want to re-create then click on its name to open the resource details page.\n5. On the selected SSM parameter details page, copy the values set for the Name, Description and Value attributes in a secured location.\n6. Once the necessary information is copied, click the Delete button from the dashboard top-right menu to remove the selected parameter.\n7. Inside the Delete Parameter dialog box, click Delete to confirm the action.\n8. In the navigation panel, in the Application Management section, select Parameter Store and click Create parameter button from the dashboard top menu to initiate the setup process.\n9. Paste the values copied at step no. 5 in the Name, Description and Value boxes to utilize the same data as the source parameter.\n10. Set the parameter Type to SecureString, choose whether to use a KMS key from your current AWS account or from a different AWS account, then select the key to encrypt your parameter data from the KMS Key ID dropdown list.\n11. Click Create parameter to finish the setup process.\n\n**From TF**\n```\nresource \"aws_ssm_parameter\" \"example\" {\nname  = \"example\"\ntype  = \"SecureString\"\nvalue = \"bar\"\n}\n```\n\n**From Command Line**\n1. To encrypt the sensitive parameter, you should first delete the old one by running the following command:\n```\naws ssm delete-parameter ParamName\n```\n2. Then, create again the same parameter but this time encrypted:\n```\naws ssm put-parameter --name PARAMETER_NAME --value PARAMETER_VALUE --type SecureString\n```\n\n**References**\n1. https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-create-console.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ssm_parameter\n3. https://docs.aws.amazon.com/systems-manager/latest/userguide/param-create-cli.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ssm/delete-parameter.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ssm/put-parameter.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "ndi6Rtszc155UXFrMtE/eQ",
        "ruleId": "D9.AWS.CRY.53",
        "category": ""
    },
    {
        "name": "Ensure that the VPC Endpoint status is Available state",
        "description": "A VPC endpoint enables you to create a private connection between your VPC and another AWS service without requiring access over the Internet, through a NAT device, a VPN connection, or AWS Direct Connect. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network. The endpoint connection must be in the Available state. If the endpoint connection is in the Pending or Rejected state, any connection sent to the Network Load Balancer from the interface endpoint times out. ",
        "severity": "High",
        "logic": "VpcEndpoint should have state='Available'",
        "remediation": "\n**From Portal:**\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose Endpoints.\n3. Select the specific endpoint you want to verify.\n4. Under Details section, ensure the Status is 'Available'\n\n**From Command Line:**\nUse following command to verify the VPC endpoint state as available.\n```\naws ec2 describe-vpc-endpoints\n```\n\nReferences:\n1. https://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html\n2. https://aws.amazon.com/premiumsupport/knowledge-center/instance-vpc-troubleshoot/\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-vpc-endpoints.html ",
        "complianceTag": "Network Security",
        "logicHash": "almNPhEnstcXr3rjMG28FQ",
        "ruleId": "D9.AWS.NET.55",
        "category": ""
    },
    {
        "name": "Ensure that the Viewer Protocol policy is compliant to only use the HTTPS protocol",
        "description": "Ensure that for web distributions, CloudFront is configured to require that viewers use HTTPS to request your objects, so that connections are encrypted when CloudFront communicates with viewers. This enables data in transit encryption and the application viewers cannot be decrypted by malicious users in case they are able to intercept packets sent across the CDN distribution network.",
        "severity": "High",
        "logic": "CloudFront should have distributionConfig.cacheBehaviors.items contain [ viewerProtocolPolicy='https-only' or viewerProtocolPolicy='redirect-to-https']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the CloudFront console at https://console.aws.amazon.com/cloudfront/.\n2. In the top pane of the CloudFront console, choose the ID for the distribution that you want to update.\n3. On the Behaviors tab, choose the cache behavior that you want to update, and then choose Edit.\n4. Specify one of the following values for Viewer Protocol Policy:\na. Redirect HTTP to HTTPS or\nb. HTTPS Only\n5. Choose Yes, Edit.\n\n**From TF**\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\norigin {\n...\n}\ndefault_cache_behavior {\n...\n}\nrestrictions {\ngeo_restriction {\nrestriction_type = \"whitelist\"\nlocations        = [\"US\", \"CA\", \"GB\", \"DE\"]\n}\n}\n+   viewer_certificate {\n+   cloudfront_default_certificate = false\n+   minimum_protocol_version = \"TLSv1.2_2019\"\n+   viewer_protocol_policy = \"https-only\" # OR \"redirect-to-https\"\n+ }\n}\n```\n\n**From Command Line**\nTo add a policy to encrypt the data in transit , run:\n```\naws cloudfront update-distribution --id CLOUDFRONT_ID --distribution-config file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html\n2. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudfront-distribution-defaultcachebehavior.html",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "P3hO9W2B7fNtsWdXLpqWuw",
        "ruleId": "D9.AWS.CRY.42",
        "category": ""
    },
    {
        "name": "Ensure that user Volume Encryption is enabled for AWS Workspace",
        "description": "Enable encryption on your  Workspace, in order to protect your data and\nmetadata from breaches or unauthorized access.",
        "severity": "High",
        "logic": "Workspace should have userVolumeEncryptionEnabled=true",
        "remediation": "\nNote: Encryption of WorkSpaces is only supported during the creation and launch of a WorkSpace.\n\n**From Portal**\n1. Open the AWS Management Console and navigate to the WorkSpaces service.\n2. Under WorkSpaces click on \"Create Workspaces\"\n3. Select a directory\n4. For Identify users, enter the Username, First Name. Last Name, and Email. Then choose Next.\n5. Select Bundle and fill the WorkSpaces configuration part\n6. Under \"Customization\" section, open the \"Encrypt root and user volume\" and select \"Encrypt user volume\"\n7. Review and click on \"Create WorkSpaces\"\n\n**From TF**\n```\nresource \"aws_workspaces_workspace\" \"example\" {\ndirectory_id = DIRECTORY_ID\nbundle_id    = BUNDLR_ID\nuser_name    = USER_NAME\n\nroot_volume_encryption_enabled = true\nuser_volume_encryption_enabled = true\nvolume_encryption_key          = \"alias/aws/workspaces\"\n\nworkspace_properties {\ncompute_type_name                         = \"VALUE\"\nuser_volume_size_gib                      = 10\nroot_volume_size_gib                      = 80\nrunning_mode                              = \"AUTO_STOP\"\nrunning_mode_auto_stop_timeout_in_minutes = 60\n}\n```\n\n**From Command Line**\n1. create a Json file with the requirment parameters.\n```\n{\n\"Workspaces\" : [\n{\n\"DirectoryId\" : DIRECTORY_ID,\n\"UserName\" : USER_NAME,\n\"BundleId\" : BUNDLE_ID,\n\"VolumeEncryptionKey\": ENCRYPTION_KEY,\n\"UserVolumeEncryptionEnabled\": true,\n\"RootVolumeEncryptionEnabled\": true\n}\n]\n}\n\n```\n2. Run the command:\n```\naws workspaces create-workspaces --cli-input-json PATH_TO_JSON_FILE\n```\n\n\n**References**\n1. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/workspaces_workspace\n2. https://docs.aws.amazon.com/cli/latest/reference/workspaces/create-workspaces.html\n3. https://docs.aws.amazon.com/workspaces/latest/adminguide/encrypt-workspaces.html#kms-permissions-key-users\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "GDV6+aGLQTlPmepMavR38Q",
        "ruleId": "D9.AWS.CRY.73",
        "category": ""
    },
    {
        "name": "Ensure the S3 bucket used to store CloudTrail logs is not publicly accessible without a condition",
        "description": "CloudTrail logs a record of every API call made in your AWS account. These logs file are stored in an S3 bucket. It is recommended that the bucket policy or access control list (ACL) applied to the S3 bucket that CloudTrail logs to prevents public access",
        "severity": "High",
        "logic": "S3Bucket where policy.Statement contain [Principal.Service='cloudtrail.amazonaws.com'] should not have ( acl.grants contain [uri like 'http://acs.amazonaws.com/groups/global/%'] or policy.Statement with [Effect='Allow' and (Principal='*' or Principal.AWS='*') and Condition isEmpty()])",
        "remediation": "\n**From Portal**\nPerform the following to remove any public access that has been granted to the bucket via an ACL or S3 bucket policy:\n\n1. Go to Amazon S3 console at https://console.aws.amazon.com/s3/home\n2. Click on the bucket used to store CloudTrail logs and select Permissions tab.\n3. Ensure block public access is enabled for that bucket.\n4. Then go to Access Control list, it shows a list of grants, one row per grant, in the bucket ACL. Each row identifies the grantee and the permissions granted.\n5. Select the row that grants permission to Everyone or Any Authenticated User\n6. Uncheck all the permissions granted to Everyone or Any Authenticated User (click x to delete the row).\n7. Click Save to save the ACL.\n8. If the Edit bucket policy button is present, click it.\n9. Remove any Statement having an Effect set to Allow and a Principal set to '*' or {'AWS' : '*'}.\n\n**From TF**\nAdd a policy document with required permissions and appropriate condition as needed as follows:\n```\ndata \"aws_iam_policy_document\" \"example\" {\n...\nstatement {\neffect = \"Allow\"\n\nactions = [\nREQUIRED_ACTIONS\n]\nprincipals {\nREQUIRED_PRINCIPALS\n}\n\nresources = [\n\"S3_BUCKET_ARN\",\n]\n\ncondition {\ntest     = TEST\nvariable = CONTEXT_VARIABLE\n\nvalues = [\nVALUES\n]\n}\n}\n...\n}\n```\n\n**From Command Line**\nTo add a policy with required permissions and appropriate condition as needed, run:\n```\naws s3api put-bucket-policy --bucket BUCKET_NAME --policy file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-policy.html\n2. https://registry.terraform.io/providers/hashicorp/aws/3.3.0/docs/data-sources/iam_policy_document\n3. https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html\n4. https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html ",
        "complianceTag": "Logging",
        "logicHash": "m2lNrZM2KYLw7rrzcfIISw",
        "ruleId": "D9.AWS.LOG.08",
        "category": ""
    },
    {
        "name": "Ensure to update the Security Policy of the Network Load Balancer",
        "description": "Elastic Load Balancing uses a TLS negotiation configuration, known as a security policy, to negotiate TLS connections between a client and the load balancer. The ELBSecurityPolicy-2016-08 security policy is always used for backend connections. Network Load Balancers do not support custom security policies. When you create a TLS listener, you can select the security policy that meets your needs. When a new security policy is added, you can update your TLS listener to use the new security policy.",
        "severity": "High",
        "logic": "NetworkLoadBalancer should have listeners contain [securityPolicy in('ELBSecurityPolicy-2016-08', 'ELBSecurityPolicy-FS-2018-06', 'ELBSecurityPolicy-TLS13-1-2-Ext1-2021-06', 'ELBSecurityPolicy-TLS13-1-2-2021-06') ]",
        "remediation": "\n**From Portal**\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers\n3. Select the load balancer and go to 'Listeners'.\n4. Select the check box for the TLS listener and choose Actions and 'Edit listener'.\n5. Go to 'Security policy' under 'Secure listener settings'.\n6. Choose a recommended security policy from the dropdown list.\n6. Click on 'Save changes'.\n\n**From TF**\n```\nresource \"aws_lb_listener\" \"test\" {\nload_balancer_arn = aws_lb.test.arn\nport              = \"443\"\nprotocol          = \"[HTTPS, TLS]\"\n+ ssl_policy        = \"...\" #  Secure policies: \"ELBSecurityPolicy-2016-08\", \"ELBSecurityPolicy-FS-2018-06\", \"ELBSecurityPolicy-TLS13-1-2-Ext1-2021-06\", \"ELBSecurityPolicy-TLS13-1-2-2021-06\"\ncertificate_arn   = \"Certificate_ARN\"\ndefault_action {...}\n}\n```\n\n**From Command Line**\n```\naws elbv2 modify-listener --listener-arn ARN_VALUE --ssl-policy RECOMMENDED_POLICY_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-listeners.html\n2. https://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-tls-listener.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_listener\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elbv2/modify-listener.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "GhAxvj3zJs0HYNm6io0inQ",
        "ruleId": "D9.AWS.CRY.38",
        "category": ""
    },
    {
        "name": "Ensure undedicated AWS IAM managed policies do not have full action permissions",
        "description": "Ensuring undedicated AWS IAM managed policies do not have full action permissions, prevents potential overly permissive policy abuse.",
        "severity": "High",
        "logic": "IamPolicy where name regexMatch /AWS/ should not have document.Statement contain [ Effect='Allow' and Action='*' ]",
        "remediation": "\nNote: AWS managed policies cannot be deleted.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Policies'\n3. For each incompliant policy, make sure there are no IAM entities attached to it:\n4. Choose the incompliant policy\n5. Under 'Policy usage', detach any IAM entity attached to it\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified role., run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#aws-managed-policies\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-delete.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-user-policy.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-group-policy.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-role-policy.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "E3CkvzvhBv3SykpbD5/QcA",
        "ruleId": "D9.AWS.IAM.72",
        "category": ""
    },
    {
        "name": "Process for Security Group Management - Managing security groups",
        "description": "Security groups should be managed and enforced by CloudGuard. CloudGuard Security Group Full Protection facilitates a formal process for approving and testing all network connections and changes to the firewall and router configurations.",
        "severity": "High",
        "logic": "SecurityGroup should have isProtected = 'true'",
        "remediation": "\n**From Portal**\nIn CloudGuard, there are two modes to manage Amazon AWSClosed Security Groups:\na. Full Protection\nb. Read-Only\nFull Protection provides the CloudGuard administrator with full control of AWS security policy definition, access leases, and can interact with dynamic policy objects.\n\nIn Full Protection mode, you can manage an AWS Security Group only through CloudGuard. CloudGuard detects attempts to change a security group from the AWS environment (such as the AWS console), which starts Tamper Protection and can send an alert/notification. CloudGuard overrides the change that is made and reverts to the definition of the Security Group defined in CloudGuard. The alerts and notifications initiated from Tamper Protection occur when you start Full Protection for the necessary regions in your cloud account. CloudGuard locks down the configuration of the security groups in that region to make sure that the security group stays correctly configured.\n\nTo make a change in a Security Group that has Tamper Protection enabled, the change is made in CloudGuard. Use following steps to configure a Security Group that has Tamper Protection enabled.\n1. Navigate to the Security Groups page in the Network Security menu.\n2. Select the Security Group to be modified.\n3. Make the necessary changes to the Security Group (for example, add or change Inbound or Outbound services).\n4. Save the changes.\n\n**References**\n1. https://sc1.checkpoint.com/documents/CloudGuard_Dome9/Documentation/Network-Security/FullProtectionMode.htm ",
        "complianceTag": "Network Security",
        "logicHash": "c9BMQbDzlVzFwc6YHPymZg",
        "ruleId": "D9.AWS.NET.11",
        "category": ""
    },
    {
        "name": "RDS should not have been open to a large scope",
        "description": "RDS should not be open to a large scope. Firewall and router configurations should be used to restrict connections between untrusted networks and any system components in the cloud environment.",
        "severity": "High",
        "logic": "RDS should not have inboundRules with [scope numberOfHosts() > 256]",
        "remediation": "\n**From Portal:**\nUse following steps to verify connectivity settings for RD databases.\n1. Login to AWS console and Navigate to RDS.\n2. In the left navigation, select Databases.\n3. Select RDS instance that you want to edit.\n4. To limit the scope to the VPC, Go to Security group rules section and click on each active security group name to select it for editing.\n5. On the VPC Security Groups page, select the Inbound rules tab from the bottom panel and click the Edit button to edit the selected security group ingress rules.\n6. In the Edit inbound rules dialog box, identify any inbound rules which have set the Source to Anywhere (0.0.0.0/0) or more than 256 hosts and update them by using one of the following actions:\nTo grant access to a certain IP address:\na. Select Custom IP from the Source dropdown list.\nb. Enter the CIDR that you want to authorize in the Source field.\nc. Click the Save button to save the changes.\nTo grant access to an EC2 Security Group:\na. Select Custom IP from the Source dropdown list.\nb. Enter the EC2 security group ID that you want to authorize in the Source field.\nc. Click the Save button to save the changes.\n\n**From Command Line:**\n1. Run following command to revoke the VPC security group inbound rule with the public scope CIDR set to 0.0.0.0/0 that grants access to everyone.\n```\naws ec2 revoke-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --cidr 0.0.0.0/0\n```\n2. Run following command to authorize custom access based on IP/CIDR to the instances associated with the selected VPC security group (Instance access authorization based on IP/CIDR).\n```\naws ec2 authorize-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --cidr specific_CIDR_value\n```\n3. Run following command to authorize custom access based on existing EC2 security groups (Instance access authorization based on EC2 security group)\n```\naws ec2 authorize-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --source-group source_security_group_id\n```\n\nReferences:\n1. http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.html\n2. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.RDSSecurityGroups.html\n3. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.html\n4. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/modify-db-instance.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/authorize-security-group-ingress.html ",
        "complianceTag": "Network Security",
        "logicHash": "D76z4zr8u2OGUcavZ1dt3w",
        "ruleId": "D9.AWS.NET.18",
        "category": ""
    },
    {
        "name": "Remove Weak Ciphers for ELB ",
        "description": "Remove insecure ciphers for your ELB Predefined or Custom Security Policy, to reduce the risk of the SSL connection between the client and the load balancer being exploited.",
        "severity": "High",
        "logic": "ELB should not have elbListeners with [ policies contain [ attributes contain-any [$ in ('DHE-DSS-AES128-SHA','CAMELLIA128-SHA','EDH-RSA-DES-CBC3-SHA','DES-CBC3-SHA','ECDHE-RSA-RC4-SHA','RC4-SHA','ECDHE-ECDSA-RC4-SHA','DHE-DSS-AES256-GCM-SHA384','DHE-RSA-AES256-GCM-SHA384','DHE-RSA-AES256-SHA256','DHE-DSS-AES256-SHA256','DHE-RSA-AES256-SHA','DHE-DSS-AES256-SHA','DHE-RSA-CAMELLIA256-SHA','DHE-DSS-CAMELLIA256-SHA','CAMELLIA256-SHA','EDH-DSS-DES-CBC3-SHA','DHE-DSS-AES128-GCM-SHA256','DHE-RSA-AES128-GCM-SHA256','DHE-RSA-AES128-SHA256','DHE-DSS-AES128-SHA256','DHE-RSA-CAMELLIA128-SHA','DHE-DSS-CAMELLIA128-SHA','ADH-AES128-GCM-SHA256','ADH-AES128-SHA','ADH-AES128-SHA256','ADH-AES256-GCM-SHA384','ADH-AES256-SHA','ADH-AES256-SHA256','ADH-CAMELLIA128-SHA','ADH-CAMELLIA256-SHA','ADH-DES-CBC3-SHA','ADH-DES-CBC-SHA','ADH-RC4-MD5','ADH-SEED-SHA','DES-CBC-SHA','DHE-DSS-SEED-SHA','DHE-RSA-SEED-SHA','EDH-DSS-DES-CBC-SHA','EDH-RSA-DES-CBC-SHA','IDEA-CBC-SHA','RC4-MD5','SEED-SHA','DES-CBC3-MD5','DES-CBC-MD5','RC2-CBC-MD5','PSK-AES256-CBC-SHA','PSK-3DES-EDE-CBC-SHA','KRB5-DES-CBC3-SHA','KRB5-DES-CBC3-MD5','PSK-AES128-CBC-SHA','PSK-RC4-SHA','KRB5-RC4-SHA','KRB5-RC4-MD5','KRB5-DES-CBC-SHA','KRB5-DES-CBC-MD5','EXP-EDH-RSA-DES-CBC-SHA','EXP-EDH-DSS-DES-CBC-SHA','EXP-ADH-DES-CBC-SHA','EXP-DES-CBC-SHA','EXP-RC2-CBC-MD5','EXP-KRB5-RC2-CBC-SHA','EXP-KRB5-DES-CBC-SHA','EXP-KRB5-RC2-CBC-MD5','EXP-KRB5-DES-CBC-MD5','EXP-ADH-RC4-MD5','EXP-RC4-MD5','EXP-KRB5-RC4-SHA','EXP-KRB5-RC4-MD5') ] ] ]",
        "remediation": "\n**From Portal**\nStep 1 is to Navigate the Load Balancer section for each instance that failed the rule and then the Listener tab. Replace HTTP listeners with HTTPS listeners.\nStep 2 is to check the security policy. If an existing HTTPS Listener has a security policy based on TLS 1.0 (e.g., 2015), replace it with a policy based on TLS 1.1 or 1.2 (e.g., 2016 or 2017). This will replace weak ciphers with recommended, stronger ciphers. Alternatively, you can select a specific cipher.\n\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard.\n3. In the navigation panel, under Load balancing, click Load Balancers.\n4. Select your Elastic Load Balancer.\n5. Select the Listeners tab from the bottom panel. In the Cipher column of the HTTPS listener, click Change.\n6. In the Select a Cipher dialog box, select one of the following options configurations:\na. Predefined Security Policy: Select the latest predefined security policy from the list named ELBSecurityPolicy-2016-08 and click save.\nb. Uncheck any insecure or deprecated cipher from the SSL Ciphers section.\n\nFollow this link to see a list of all the insecure ciphers that require to be removed: http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-security-policy-table.html\n\n**From TF**\n```\nresource \"aws_load_balancer_policy\" \"test\" {\nload_balancer_name = aws_elb.wu-tang.name\npolicy_name        = \"wu-tang-ssl\"\npolicy_type_name   = \"SSLNegotiationPolicyType\"\n\npolicy_attribute {\n+   name  = \"Protocol-TLSv1.2\"\nvalue = \"true\"\n}\n}\n```\n\n**From Command Line**\n1. Run describe-load-balancer-policies command to find the predefined security policies provided by aws.\n```\naws elb describe-load-balancer-policies --query TYPE_QUERY --output table\n```\n2. Run create-load-balancer-policy command to create a predefined security policy using one of the SSL configurations listed in the first step. We recommend to use the latest predefined policy for your ELB.\n```\naws elb create-load-balancer-policy --load-balancer-name LOAD_BALANCER_NAME --policy-name POLICY_NAME --policy-type-name SSLNegotiationPolicyType --policy-attributes AttributeName=Reference-Security-Policy,AttributeValue=ELBSecurityPolicy-2016-08\n```\n3. Run create-load-balancer-policy command to create a custom ELB SSL security policy that contains secure ciphers.\n```\naws elb create-load-balancer-policy --load-balancer-name LOAD_BALANCER_NAME --policy-name POLICY_NAME --policy-type-name SSL_NEGOTIATION_POLICY_TYPE --policy-attributes AttributeName=Protocol-TLSv1.2,AttributeValue=true AttributeName=Protocol-TLSv1.1,AttributeValue=true AttributeName=ECDHE-RSA-AES128-SHA,AttributeValue=true AttributeName=Server-Defined-Cipher-Order,AttributeValue=true\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ssl-config-update.html\n2. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-ssl-security-policy.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/load_balancer_policy ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "pTkMQm433zo6YOcTjaxSuw",
        "ruleId": "D9.AWS.CRY.06",
        "category": ""
    },
    {
        "name": "S3 bucket CloudTrail logs ACL should not allow public access",
        "description": "CloudTrail logs a record of every API call made in your AWS account. These logs file are stored in an S3 bucket. It is recommended that access control list (ACL) applied to the S3 bucket that holds CloudTrail logs prevents public access",
        "severity": "High",
        "logic": "S3Bucket where policy.Statement contain [Principal.Service='cloudtrail.amazonaws.com'] should not have ( acl.grants contain [uri like 'http://acs.amazonaws.com/groups/global/%'] )",
        "remediation": "\n**From Portal**\n1. Navigate to S3.\n2. Click the target S3 bucket.\n3. Select the Permissions tab.\n4. Click Access Control List.\n5. In Public access, ensure no rows exist that have the Grantee set to Everyone or the Grantee set to Any Authenticated User.\n6. Click Save.\n7. Select the Bucket Policy tab.\n8. Ensure the policy does not contain a Statement having an Effect set to Allow and a Principal set to * or (AWS : *)\nNote: Principal set to * or (AWS : *) allows anonymous access.\n\n**From TF**\n```\nresource \"aws_s3_bucket\" \"example\" {\nacl = \"example1\"\nput other required fields here\n}\n```\nNote: Ensure that terraform resource does not contain acl field value as public-read or public-read-write.\n\n**From Command Line**\n1. Use below command to ensure the AllUsers principal privileges is not granted to that bucket:\n```\naws s3api get-bucket-acl --bucket S3_BUCKET_NAME --query 'Grants[?Grantee.URI== `http://acs.amazonaws.com/groups/global/AllUsers`]'\n```\n2. Ensure the AuthenticatedUsers principal privileges is not granted to that bucket:\n```\naws s3api get-bucket-acl --bucket S3_BUCKET_NAME --query 'Grants[?Grantee.URI== `http://acs.amazonaws.com/groups/global/Authenticated Users`]'\n```\n3. Use following command to get the S3 Bucket Policy:\n```\naws s3api get-bucket-policy --bucket S3_BUCKET_NAME\n```\n4. Ensure the policy does not contain a Statement having an Effect set to Allow and a Principal set to * or (AWS : *)\n\n**References**\n1. https://docs.aws.amazon.com/AmazonS3/latest/userguide/managing-acls.html\n2. https://docs.aws.amazon.com/cli/latest/reference/s3api/get-bucket-acl.html#description\n3. https://docs.aws.amazon.com/cli/latest/reference/cloudtrail/index.html#cli-aws-cloudtrail\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail ",
        "complianceTag": "Logging",
        "logicHash": "fIqOvlyp2C8izDrLQrFR8A",
        "ruleId": "D9.AWS.LOG.10",
        "category": ""
    },
    {
        "name": "SSL/TLS certificates expire in one week",
        "description": "Ensure that SSL/TLS certificates stored in AWS IAM are renewed one week before expiry.",
        "severity": "High",
        "logic": "IamServerCertificate should not have expiration before(7, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard\n3. Go to Load Balancing and click Load Balancers.\n4. Select the Elastic Load Balancer for which certificate is expiring in 7 days.\n5. Select the Listeners tab and click the Change link in the SSL Certificate column.\n6. In the Select Certificate dialog box, perform the following actions:\na. If you have already deployed a certificate with AWS Certificate Manager (ACM), select Choose an existing certificate from AWS Certificate Manager (ACM) and choose the new SSL certificate from the Certificate dropdown list.\nb. If you have already uploaded an SSL certificate to AWS IAM, select Choose an existing certificate from AWS Identity and Access Management (IAM) and choose the new SSL certificate from the Certificate dropdown list.\nc. If you have not yet uploaded an SSL/TLS certificate to AWS IAM, select Upload a new SSL certificate to AWS IAM to deploy the new SSL certificate by entering the required data provided by the SSL certificate provider.\n7. Click Save to apply the new SSL certificate and replace the one that is about to expire.\n\nNote: You can perform the same steps for all load balancer that needs SSL/TLS certificates renewal.\n\n**From Command Line**\nRun below Command to replace the SSL certificates that are about to expire with new certificates uploaded to IAM.\n```\naws iam upload-server-certificate --server-certificate-name EXAMPLE_CERTIFICATE --certificate-body file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\nRun below command to replace the ELB existing SSL certificate with the newly one uploaded to AWS IAM through upload command in previous step.\n```\naws elb set-load-balancer-listener-ssl-certificate --load-balancer-name EXAMPLE_NAME --load-balancer-port 443 --ssl-certificate-id EXAMPLE_CERTIFICATE_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://aws.amazon.com/certificate-manager/ ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "PBfBAiminty6v7OWjcXRmA",
        "ruleId": "D9.AWS.CRY.08",
        "category": ""
    },
    {
        "name": "Use KMS CMK customer-managed keys for Redshift clusters",
        "description": "Use customer-managed KMS keys instead of AWS-managed keys, to have granular control over encrypting and decrypting data.\nEncrypt Redshift clusters with a Customer-managed KMS key. This is a recommended best practice.",
        "severity": "High",
        "logic": "Redshift should have dataEncrypted and kmsKeyId",
        "remediation": "\n**From Portal**\nFollowing steps will enable KMS CMK for the desired redshift cluster:\n1. Login to the AWS Management Console.\n2. Select the appropriate AWS region.\n3. Navigate to KMS service at https://console.aws.amazon.com/kms/.\n4. Click on Customer managed keys in the left navigation panel\n5. Verify the name and key ID of the KMS default key generated for the Redshift service, key identified by the aws/redshift alias.\n6. Now, navigate to Redshift dashboard at https://console.aws.amazon.com/redshift/.\n7. In the navigation panel, under Redshift Dashboard, click Clusters.\n8. Choose the Redshift cluster that you want to modify encryption settings and go click on Properties tab.\n9. Verify the Encryption status (Disabled/enabled) under the Cluster Properties.\n10. Click on edit tab on the right side and go to edit encryption select the customer managed key created already and save it.\n\nNotes: You must enable encryption when you launch the Redshift cluster, before data is placed on it. Encryption on a cluster is immutable, and cannot be reversed.\n\n**From TF**\n```\nresource \"aws_redshift_cluster\" \"test\" {\n+ encrypted = true\n}\n```\n\n**From Command Line**\nTo turn on encryption for Redshift cluster\n```\naws redshift modify-cluster --cluster-ientifier PUT_VALUE --encrypted -- kms-key-id PUT_VALUE\n```\n\n**References**\n1. https://docs.aws.amazon.com/redshift/latest/mgmt/managing-clusters-console.html#create-cluster\n2. https://docs.aws.amazon.com/redshift/latest/mgmt/changing-cluster-encryption.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/redshift_cluster ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "oFMBQQvBdN07zi36Uebkbw",
        "ruleId": "D9.AWS.CRY.15",
        "category": ""
    },
    {
        "name": "Use encrypted connection between CloudFront and origin server ",
        "description": "Enforce HTTPS-only traffic between a CloudFront distribution and the origin. It is recommended to use HTTPS for secure communications between your CloudFront distribution and end users to guarantee encryption of traffic and prevent malicious actors from intercepting your traffic. This rule runs on all the origins except S3 Buckets ",
        "severity": "High",
        "logic": "CloudFront where not distributionConfig.origins.items with [ s3OriginConfig] should have distributionConfig.origins.items with [ customOriginConfig.originProtocolPolicy='https-only' ]or distributionConfig.defaultCacheBehavior.viewerProtocolPolicy='redirect-to-https' or distributionConfig.defaultCacheBehavior.viewerProtocolPolicy='https-only'",
        "remediation": "\n**From Portal**\nUse following steps to configure HTTPS between CloudFront and your custom origin\n1. Sign in to the AWS Management Console and open the CloudFront console.\n2. In the top pane of the CloudFront console, choose the ID for the distribution that you want to update.\n3. On the Origins tab, choose the origin that you want to update, and then choose Edit.\n4. Update the following settings:\nOrigin Protocol Policy - Change the Origin Protocol Policy for the applicable origins in your distribution:\na. HTTPS Only - CloudFront uses only HTTPS to communicate with your custom origin.\nb. Match Viewer - CloudFront communicates with your custom origin using HTTP or HTTPS, depending on the protocol of the viewer request. For example, if you choose Match Viewer for Origin Protocol Policy and the viewer uses HTTPS to request an object from CloudFront, CloudFront also uses HTTPS to forward the request to your origin.\n\nNote: Choose Match Viewer only if you specify Redirect HTTP to HTTPS or HTTPS Only for Viewer Protocol Policy. CloudFront caches the object only once even if viewers make requests using both HTTP and HTTPS protocols.\n5. Choose Yes, Edit.\n6. Confirm the following before you use the updated configuration in a production environment:\na. The path pattern in each cache behavior applies only to the requests that you want viewers to use HTTPS for.\nb. The cache behaviors are listed in the order that you want CloudFront to evaluate them in. For more information, see Path pattern.\nc. The cache behaviors are routing requests to the origins that you changed the Origin Protocol Policy for.\n\n**From TF**\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\ndomain_name = \"something.example.com\"\ncustom_origin_config = {\nhttp_port              = 80\nhttps_port             = 443\norigin_protocol_policy = \"https-only\"\norigin_ssl_protocols   = [\"TLSv1\", \"TLSv1.1\", \"TLSv1.2\"]\n}\n}\n```\n\n**From Command Line**\n1. Run following command to extract the configuration for selected Amazon CloudFront distribution.\n```\naws cloudfront get-distribution-config --id DISTRIBUTION_ID --query DISTRIBUTION_CONFIG\n```\n2. Run following command to describe the current version for selected Amazon CloudFront distribution\n```\naws cloudfront get-distribution-config --id DISTRIBUTION_ID --query DISTRIBUTION_CONFIG\n```\n3. Change the configuration document extracted from above command to enforce the HTTPS protocol and encrypt the traffic between the distribution server and the custom origin i.e OriginProtocolPolicy: https-only. Save the document with the modified configuration to a JSON file.\n4. Run following command using json file saved in step 3 to reconfigure the selected Amazon CloudFront distribution in order to enable HTTPS-only for the selected origin.\n```\naws cloudfront update-distribution --id DISTRIBUTION_ID --if-match PUT_VALUE --distribution-config JSON_FILE_PATH\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https.html\n2. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-custom-origin.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution\n4. https://docs.aws.amazon.com/cli/latest/reference/cloudfront/update-distribution.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "Z4Yr588JaL5nIVtBO8ZdBQ",
        "ruleId": "D9.AWS.CRY.17",
        "category": ""
    },
    {
        "name": "Use encrypted storage for instances that might host a database.",
        "description": "Ensure that storage is encrypted by KMS on instances that, based on their name, might host a database. Covered DBs include: couchbase, riak,redis, hbase, Oracle, SAP Hana, Postgres, cassandra, hadoop, Mongo, Neo4j and any server with DB, SQL, database or graph in name",
        "severity": "High",
        "logic": "Instance where(name like '%-db%' ) or (name like '%_db%' )  or (name like '%db-%' ) or (name like '%db_%' ) or (name like '%database%' ) or (name like '%sql%' ) or (name like '%couchbase%' ) or (name like '%riak%' )  or (name like '%redis%' )  or (name like '%hbase%' )  or (name like '%oracle%' )  or (name like '%hana%' ) or (name like '%postgres%' )  or (name like '%cassandra%' )   or (name like '%hadoop%' )  or (name like '%mongo%' )  or (name like '%graph%' )  or (name like '%Neo4j%' ) should have volumes with [kmsKeyId and encrypted='true']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the EC2 console at https://console.aws.amazon.com/ec2/.\n2. Create an EC2 instance with the where the names include - db, database, sql, couchbase, riak, redis, hbase, oracle, hana, postgres, cassandra, hadoop, mongo, graph, Neo4j\n3. Configure the filesystem on the instance(s) to be encrypted, using a key that is stored in a file on an S3 bucket (created for this purpose).\nThis involves creating an S3 bucket, with a permissions policy, creating & encrypting an encryption key and storing it in the bucket, and then configuring the instances to use the key to encrypt the filesystems, all from the AWS console.\n4. Choose Save changes.\n\n**From TF**\n```\nresource \"aws_ebs_volume\" \"negative\" {\n+ encrypted = true\n+ kms_key_id = \"KMS-KEY-ID\"\n}\n```\n\n**References**\n1. https://aws.amazon.com/blogs/security/how-to-protect-data-at-rest-with-amazon-ec2-instance-store-encryption",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "TMnisQW2lGU76DwIa/fuhQ",
        "ruleId": "D9.AWS.CRY.01",
        "category": ""
    },
    {
        "name": "Use secure ciphers in CloudFront distribution",
        "description": "Enforce the use of secure ciphers TLS v1.1 and TLS v1.2 in a CloudFront Distribution certificate configuration. This is a best security practice. This signature scans for any deviations from this practice and returns the results.",
        "severity": "High",
        "logic": "CloudFront should have ( ( distributionConfig.viewerCertificate.minimumProtocolVersion like 'TLSv1.1%') or ( distributionConfig.viewerCertificate.minimumProtocolVersion like 'TLSv1.2%') )",
        "remediation": "\n**From Portal**\nUse following steps to configure HTTPS between CloudFront and your custom origin\n1. Sign in to the AWS Management Console and open the CloudFront console.\n2. In the top pane of the CloudFront console, choose the ID for the distribution that you want to update.\n3. On the Origins tab, choose the origin that you want to update, and then choose Edit.\n4. Update the following settings:\nOrigin SSL Protocols - Choose the Minimum origin SSL protocol for the applicable origins in your distribution. The SSLv3 protocol is less secure, so we recommend that you choose SSLv3 only if your origin does not support TLSv1 or later. The TLSv1 handshake is both backwards and forwards compatible with SSLv3, but TLSv1.1 and TLSv1.2 are not. When you choose SSLv3, CloudFront only sends SSLv3 handshake requests.\n5. Click Save changes.\n\n**From TF**\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\nviewer_certificate {\ncloudfront_default_certificate = false\nminimum_protocol_version = \"TLSv1.2_2021\"\n}\n}\n```\n\n**From Command Line**\n1. Run following command to extract the configuration for selected Amazon CloudFront distribution.\n```\naws cloudfront get-distribution-config --id DISTRIBUTION_ID --query DISTRIBUTION_CONFIG\n```\n2. Run following command to describe the current version for selected Amazon CloudFront distribution\n```\naws cloudfront get-distribution-config --id DISTRIBUTION_ID --query DISTRIBUTION_CONFIG\n```\n3. Change the configuration document extracted from above command to change the security policy for selected CloudFront distribution. Use MinimumProtocolVersion as TLSv1.2_2021 and save the document to a JSON file.\n4. Run following command using json file saved in step 3 to upgrade the security group for Amazon CloudFront distribution\n\nNote --if-match parameter is used to check the current version of the configuration.\n```\naws cloudfront update-distribution --id DISTRIBUTION_ID --if-match PUT_VALUE --distribution-config JSON_FILE_PATH\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/secure-connections-supported-viewer-protocols-ciphers.html\n2. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-custom-origin.html#using-https-cloudfront-to-origin-certificate\n3. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html\n4. https://docs.aws.amazon.com/cli/latest/reference/cloudfront/update-distribution.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "QIq0voqXR9RvRksWPI3UEQ",
        "ruleId": "D9.AWS.CRY.16",
        "category": ""
    },
    {
        "name": "CloudFront distributions should encrypt traffic to custom origins",
        "description": "HTTPS (TLS) can be used to help prevent eavesdropping or manipulation of network traffic. Only encrypted connections over HTTPS (TLS) should be allowed.",
        "severity": "Medium",
        "logic": "CloudFront where distributionConfig.origins.items contain [ customOriginConfig ] should have distributionConfig.origins.items contain-none [ customOriginConfig.originProtocolPolicy='http-only' ] and distributionConfig.origins.items contain-none [ viewerProtocolPolicy='allow-all' and customOriginConfig.originProtocolPolicy='match-viewer' ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console.\n2. Navigate to Amazon CloudFront console at https://console.aws.amazon.com/cloudfront/v3/.\n3. In the left navigation panel, under CloudFront, choose Distributions.\n4. Click on the name of the CloudFront distribution that you want to reconfigure.\n5. Select the Origins tab to access the origins created for the selected distribution.\n6. Select the custom distribution origin that you want to reconfigure and choose Edit.\n7. On the Edit origin page, select HTTPS only under Protocol to enforce HTTPS and encrypt the traffic between the CloudFront distribution edge servers and the selected origin. Choose Save changes to apply the configuration changes.\n\n**From Command Line**\n1. Run following command to extract the configuration information from your Amazon CloudFront Distributions.\n```\naws cloudfront get-distribution-config --id Distribution_ID --query 'DistributionConfig'\n```\n2. Run following command to describe the current version of the configuration available for the selected distributions.\n```\naws cloudfront get-distribution-config --id Distribution_ID --query 'ETag'\n```\n3. Modify the configuration document returned at previous step to enforce the HTTPS protocol (OriginProtocolPolicy: https-only,) and encrypt the traffic between the distribution edge servers and the custom origin. Save the modified distribution configuration to a JSON file.\n4. Run following command using the json file modified at the previous step to reconfigure the selected Amazon CloudFront distribution in order to enable HTTPS-only for the specified origin.\n```\naws cloudfront update-distribution --id Distribution_ID --if-match ETag_header_value --distribution-config file://example.json --query 'Distribution.Status'\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudfront/get-distribution.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudfront/get-distribution-config.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudfront/update-distribution.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "xieIBm2srz4+EOyBvD/OxA",
        "ruleId": "D9.AWS.CRY.79",
        "category": ""
    },
    {
        "name": "CloudFront distributions should require encryption in transit",
        "description": "HTTPS (TLS) can be used to help prevent potential attackers from using person-in-the-middle or similar attacks to eavesdrop on or manipulate network traffic. Only encrypted connections over HTTPS (TLS) should be allowed. Encrypting data in transit can affect performance. You should test your application with this feature to understand the performance profile and the impact of TLS.",
        "severity": "Medium",
        "logic": "CloudFront should have distributionConfig.cacheBehaviors.items contain-none [ viewerProtocolPolicy='allow-all' ] and distributionConfig.defaultCacheBehavior.viewerProtocolPolicy!='allow-all'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console.\n2. Navigate to CloudFront dashboard at https://console.aws.amazon.com/cloudfront/.\n3. In the left navigation panel, click Distributions.\n4. On CloudFront Distribution page, under the main menu, select Web and Enabled from Viewing dropdown menus to list all active web distributions available within your AWS account.\n5. Select the web distribution that you want to reconfigure.\n6. Click the Distribution Settings button from the dashboard top menu to access the resource configuration page.\n7. Choose the Behaviors tab and select the distribution default behavior.\n8. Click the Edit button to access the behavior configuration settings.\n9. On the Edit Behavior page, under Default Cache Behavior Settings, perform one of the following actions to enforce encryption for your web content:\na. Set the Viewer Protocol Policy configuration attribute to Redirect HTTP to HTTPS so that any HTTP requests are automatically redirected to HTTPS requests. Click Yes, Edit to apply the changes.\nb. Set the Viewer Protocol Policy attribute to HTTPS Only so that your application viewers can only access your web content using HTTPS. Choosing this option will drop any HTTP traffic between edge servers and viewers. Click Yes, Edit to apply the configuration changes.\n\n**From Command Line**\nRun following command to update the configuration for the selected Amazon CloudFront CDN distribution in order to enforce encryption. The following command example updates the web distribution using a JSON configuration document named example-encryption.json\n```\naws cloudfront update-distribution --id Example_ID --distribution-config file://example-encryption.json --if-match ETag_header_value\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html\n2. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudfront/update-distribution.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "DusVW8YfHLfdfalyxywxSQ",
        "ruleId": "D9.AWS.CRY.78",
        "category": ""
    },
    {
        "name": "Connections to Amazon Redshift clusters should be encrypted in transit",
        "description": "TLS can be used to help prevent potential attackers from using person-in-the-middle or similar attacks to eavesdrop on or manipulate network traffic. Only encrypted connections over TLS should be allowed. Encrypting data in transit can affect performance. You should test your application with this feature to understand the performance profile and the impact of TLS.",
        "severity": "Medium",
        "logic": "Redshift should have parametersGroup contain [ parameters with [ parameterName='require_ssl' and parameterValue='true' ] ]",
        "remediation": "\n**From Portal**\nTo remediate this issue, update the parameter group to require encryption.\n1. Open the Amazon Redshift console at https://console.aws.amazon.com/redshift/.\n2. In the navigation menu, choose Config, then choose Workload management to display the Workload management page.\n3. Choose the parameter group that you want to modify.\n4. Choose Parameters.\n5. Choose Edit parameters, and then set require_ssl to True.\n6. Enter your changes and then choose Save.\n\n**From Command Line**\nRun following command to enable the require_ssl parameter for desired parameter group.\n```\naws redshift modify-cluster-parameter-group --parameter-group-name redshift_cluster_parameter_group_name --parameters ParameterName=require_ssl,ParameterValue=true\n```\n\n**References**\n1. https://docs.aws.amazon.com/redshift/latest/mgmt/connecting-ssl-support.html\n2. https://docs.aws.amazon.com/redshift/latest/mgmt/managing-clusters-console.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/redshift/modify-cluster-parameter-group.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "Ek+keMVH74cBlJVhDJYmJw",
        "ruleId": "D9.AWS.CRY.86",
        "category": ""
    },
    {
        "name": "DynamoDB Accelerator (DAX) clusters should be encrypted at rest",
        "description": "Encrypting data at rest reduces the risk of data stored on disk being accessed by a user not authenticated to AWS. The encryption adds another set of access controls to limit the ability of unauthorized users to access to the data. For example, API permissions are required to decrypt the data before it can be read.",
        "severity": "Medium",
        "logic": "DynamoDbTable should have sseDescription.status='ENABLED'",
        "remediation": "\n**From Portal**\nYou cannot enable or disable encryption at rest after a cluster is created. You must recreate the cluster in order to enable encryption at rest. Follow these steps to enable DAX encryption at rest on a table using the console.\n1. Sign in to the AWS Management Console and open the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n2. In the navigation pane on the left side of the console, under DAX, choose Clusters.\n3. Choose Create cluster.\n4. For Cluster name, enter a short name for your cluster. Choose the node type for all of the nodes in the cluster, and for the cluster size, use 3 nodes.\n5. In Encryption, make sure that Enable encryption is selected.\n6. After choosing the IAM role, subnet group, security groups, and cluster settings, choose Launch cluster.\nNote: To confirm that the cluster is encrypted, check the cluster details under the Clusters pane. Encryption should be ENABLED.\n\n**From Command Line**\n1. Run following command to create a new Amazon DAX cache cluster and enable Server-Side Encryption (SSE) during the launch process by setting the --sse-specification parameter to Enabled=true.\n```\naws dax create-cluster --cluster-name daxcluster --node-type dax.r4.large --replication-factor 3 --iam-role-arn role_ARN --sse-specification Enabled=true\n```\n2. Once the new DAX cluster has been created, change the cluster endpoint in your application to point to the new resource.\n3. Terminate the old unencrypted cluster. run following command to remove the required Clusters.\n```\naws dax delete-cluster --region region_name --cluster-name example_dax_cluster_name\n```\n**References**\n1. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAXEncryptionAtRest.html#dax.encryption.tutorial-console\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dax/create-cluster.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "9JCh+J5v19xQ2Ot3SuucgQ",
        "ruleId": "D9.AWS.CRY.85",
        "category": ""
    },
    {
        "name": "EksCluster should not have more than one security group",
        "description": "Having more than 1 security group is a bad practice and may create unexpected results ",
        "severity": "Medium",
        "logic": "EksCluster should not have resourcesVpcConfig.additionalSecurityGroups length()>1",
        "remediation": "\n**From Portal:**\n1. Sign in to the AWS console.\n2. Navigate to the EKS (Amazon Elastic Kubernetes) service.\n3. Select the cluster you want to verify.\n4. Go to Networking tab and ensure there is no Additional security groups associated to that cluster.\n5. Choose one security group or create a new security group that have all the correct rules.\n\nReferences:\n1. https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html ",
        "complianceTag": "Network Security",
        "logicHash": "0fwgLL4Tk3ctTbCXS9Fh3g",
        "ruleId": "D9.AWS.NET.70",
        "category": ""
    },
    {
        "name": "Enforce creation of ElasticSearch domains within your VPCs",
        "description": "Placing an Amazon ES domain within a VPC enables secure communication between Amazon ES and other services within the VPC without the need for an internet gateway, NAT device, or VPN connection. All traffic remains securely within the AWS Cloud. Because of their logical isolation, domains that reside within a VPC have an extra layer of security when compared to domains that use public endpoints.",
        "severity": "Medium",
        "logic": "ElasticSearchDomain should have vpc",
        "remediation": "\n**From Portal:**\nIn order to support VPCs, Amazon ES places an endpoint into one, two, or three subnets of your VPC. If you enable multiple Availability Zones for your domain, each subnet must be in a different Availability Zone in the same region. If you only use one Availability Zone, Amazon ES places an endpoint into only one subnet. If you launch a new domain within a VPC, you can't later switch it to use a public endpoint. The reverse is also true: If you create a domain with a public endpoint, you can't later place it within a VPC. Instead, you must create a new domain and migrate your data. To migrate your AWS Elasticsearch domains from public access to VPC access, you must unload the existing data from the domain to Amazon S3 then upload this data in a new ES cluster, launched within a Virtual Private Cloud.\n\nPerform the following steps to relaunch and configure your Elasticsearch cluster within an AWS VPC.\n1. Sign in to the AWS Management Console and Navigate to Elasticsearch dashboard.\n2. Click on the ES domain that you want to relaunch.\n3. On the selected ES domain description page, click the Configure cluster button from the dashboard top menu.\n4. Copy the selected cluster configuration information such as Instance count, Instance type, Dedicated master instance type, Dedicated master instance count, Storage Type, EBS volume size, etc.\n5. On the Set up access policy page, copy the access policy available in the Add or edit the access policy text box.\n6. Go back to the AWS ES service dashboard and click the Create new domain button from the dashboard top menu to launch a new Elasticsearch domain.\n7. On the Define domain page, perform the following actions:\na. Provide a unique name for the new ES domain in the Elasticsearch domain name box.\nb. Select the right version of the Elasticsearch engine from the Elasticsearch version dropdown list.\nc. Click Next to continue the setup process.\n8. On the Configure cluster page, set the new domain parameters using the configuration details copied previously and click Next to continue.\n9. Perform the following actions on the Set up access page of the new domain.\na. Inside Network configuration section, choose VPC access option to launch the domain within a VPC, then select the VPC identifier from the VPC dropdown list, an available subnet from the Subnet list and security groups.\nb. Under Access policy section, paste the access policy copied details into the Add or edit the access policy box or simply select a pre-configured policy from the Set the domain access policy to dropdown list and edit it to meet the needs of your ES domain.\nc. Click Next to continue the process.\n10. On the Review page, verify the domain configuration and its access policy.\n11. Click Confirm and create to launch the new AWS Elasticsearch domain within the specified VPC.\n12. Once the new AWS ES domain is created, upload the data from the source cluster to the new cluster.\n13. Now it is safe to remove the publicly accessible domain.\n14. Perform the following to delete the source domain.\na. Click on the name of the domain that you want to remove.\nb. On the selected domain description page, click Delete Elasticsearch domain to expand the section panel then click Delete domain button to start the removal process.\nc. Under Delete domain dialog box, check Delete the domain then click the Delete button to confirm the action.\n\n**From Command Line:**\n1. Run following command to relaunch the selected Amazon Elasticsearch domain into an AWS VPCs.\n```\naws es create-elasticsearch-domain --region region_name --domain-name Elasticsearch_domain_name --elasticsearch-version version_number --elasticsearch-cluster-config InstanceType=elasticsearch_instance_type,InstanceCount=value --ebs-options EBSEnabled=true,VolumeType=standard,VolumeSize=value --vpc-options SubnetIds=subnet_ID,SecurityGroupIds=sg_ID\n```\n2.Upload the existing data to the newly created cluster. You can remove the old publicly accessible Elasticsearch domain once all the data is uploaded. Use following command to delete the domain.\n```\naws es delete-elasticsearch-domain --region region_name --domain-name Elasticsearch_domain_name\n```\n\nReferences:\n1.  https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html#es-prerequisites-vpc-endpoints\n2. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html#es-creating-vpc\n3. https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html#es-migrating-public-to-vpc\n4. https://docs.aws.amazon.com/opensearch-service/latest/developerguide/gsgcreate-domain.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/es/create-elasticsearch-domain.html ",
        "complianceTag": "Network Security",
        "logicHash": "2+GATvHEA4UvHEgifO2WYQ",
        "ruleId": "D9.AWS.NET.53",
        "category": ""
    },
    {
        "name": "Ensure 'Auto accept shared attachments' is disabled, to avoid unknown cross account attachments to your Transit Gateway",
        "description": "Ensure you are always under the control of your environment. Always review cross-account attachment requests to your Transit gateway and approve them only if you trust the source.",
        "severity": "Medium",
        "logic": "TransitGateway should have options.autoAcceptSharedAttachments='disable'",
        "remediation": "\n**From Portal**\nPerform the following steps in order to set 'Auto accept shared attachments' to disable:\n1. Sign in to the Amazon VPC console at https://console.aws.amazon.com/vpc/\n2. Open Transit Gateways.\n3. Choose relevant gateway and click Actions\n4. Click Modify transit gateway.\n5. Uncheck 'Auto-accept shared attachments' under 'Configure cross-account sharing options' section.\n\n**From TF**\n```\nresource \"aws_ec2_transit_gateway\" \"primary_gateway\" {\n- auto_accept_shared_attachments = \"enable\"\n+ auto_accept_shared_attachments = \"disable\"\n}\n```\n\n**From Command Line**\n```\naws ec2 modify-transit-gateway --transit-gateway-id Transit_gateway_ID --options AutoAcceptSharedAttachments=disable\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/tgw/tgw-vpc-attachments.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify-transit-gateway.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_transit_gateway ",
        "complianceTag": "Monitoring",
        "logicHash": "COu5nzeo5DZgAYdTXpBl8w",
        "ruleId": "D9.AWS.MON.20",
        "category": ""
    },
    {
        "name": "Ensure Network firewall resides in a dedicated subnet",
        "description": "The network firewall protects the availability zone where it resides. It is the gate to your AZ, and therefore should be alone in a small and dedicated subnet. You should not place other applications in a subnet where a firewall resides, because the network firewall can't filter traffic coming into or going out from that subnet.",
        "severity": "Medium",
        "logic": "NetworkFirewall should have subnetMappings contain-all [getResource('Subnet', subnetId) contain [cidr numberOfHosts() <=15]]",
        "remediation": "\n**From Command Line**\nTo set Networks firewall in a new subnet, you should create a small subnet in the availability zone where you want the network firewall.\n\n1. Afterwards, you need to temporary disable subnet change protection with the following CLI command:\n```\naws network-firewall update-subnet-change-protection --firewall-arn FW_ARN --no-subnet-change-protection\n```\nNote: The flag --no-subnet-change-protection will set the subnet change protection to FALSE.\n\n2. Use below command to associate the network firewall with the new subnet:\n```\naws network-firewall associate-subnets --firewall-arn FW_ARN --subnet-mappings SubnetId= SUBNET_ID\n```\n3. Use below command to disassociate the previous subnet from the network firewall:\n```\naws network-firewall disassociate-subnets --firewall-arn FW_ARN --subnet-ids SUBNET_ID\n```\nNote: Dont forget to enable subnet change protection when you finish:\n```\naws network-firewall update-subnet-change-protection --firewall-arn FW_ARN --subnet-change-protection\n```\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/developerguide/firewall-vpc.html\n2. https://aws.amazon.com/blogs/networking-and-content-delivery/deployment-models-for-aws-network-firewall/\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/update-subnet-change-protection.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/associate-subnets.html\n",
        "complianceTag": "Network Security",
        "logicHash": "9zQSUhIm4V1RgF9kqSo10Q",
        "ruleId": "D9.AWS.NET.65",
        "category": ""
    },
    {
        "name": "Ensure a log metric filter and alarm exist for EC2 Large instance changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It helps to manage your heavy compute resources and avoid any unexpected charges",
        "severity": "Medium",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = RunInstances) && (($.requestParameters.instanceType = *.8xlarge) || ($.requestParameters.instanceType = *.4xlarge)) }')] length() > 0]",
        "remediation": "\n**From Portal:**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check.\n2. Create an SNS topic that the alarm will notify.\n3. Create an SNS subscription to the topic created in step 2.\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n\n**From Command Line:**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided which checks for EC2 instance changes. Use following command:\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name EC2_Large_Instance_Launch  --metric-transformations metricName=EC2LargeInstanceLaunch,metricNamespace=EC2_Large_Instance_Launch,metricValue=1 --filter-pattern '{ ($.eventName = RunInstances) && (($.requestParameters.instanceType = *.8xlarge) || ($.requestParameters.instanceType = *.4xlarge)) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n```\naws cloudwatch put-metric-alarm --alarm-name EC2_Large_Instance_Launch --metric-name EC2LargeInstanceLaunch --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'EC2_Large_Instance_Launch' --alarm-actions sns_topic_arn\n```\n\nReferences:\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n2. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n3. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/put-metric-alarm.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/put-metric-filter.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/create-topic.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/subscribe.html ",
        "complianceTag": "Monitoring",
        "logicHash": "QLhuMxe2+jYHvS4l7Be2gA",
        "ruleId": "D9.AWS.MON.27",
        "category": ""
    },
    {
        "name": "Ensure a log metric filter and alarm exist for EC2 instance changes",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Detecting EC2 instance configuration and status changes can help organizations stay up-to-date on the resource availability, gain insights into auto-scaling lifecycle, mitigate downtime, prevent data loss or avoid unexpected charges on your AWS bill.",
        "severity": "Medium",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{ ($.eventName = RunInstances) || ($.eventName = RebootInstances) || ($.eventName = StartInstances) || ($.eventName = StopInstances) || ($.eventName = TerminateInstances) }')] length() > 0]",
        "remediation": "\n**From Portal:**\nPerform the following steps to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern relevant for this check.\n2. Create an SNS topic that the alarm will notify.\n3. Create an SNS subscription to the topic created in step 2.\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2.\n\n**From Command Line:**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n\n1. Create a metric filter based on filter pattern provided which checks for EC2 instance changes. Use following command:\n```\naws logs put-metric-filter --log-group-name cloudtrail_log_group_name --filter-name EC2_Instance_Status_Changes --metric-transformations metricName=EC2InstancesChanges,metricNamespace=EC2_Instances_Changes,metricValue=1 --filter-pattern '{ ($.eventName = RunInstances) || ($.eventName = RebootInstances) || ($.eventName = StartInstances) || ($.eventName = StopInstances) || ($.eventName = TerminateInstances) }'\n```\nNote: You can choose your own metricName and metricNamespace strings. Using the same metricNamespace for all Foundations Benchmark metrics will group them together.\n\n2. Create an SNS topic that the alarm will notify\n```\naws sns create-topic --name sns_topic_name\n```\nNote: you can execute this command once and then re-use the same topic for all monitoring alarms.\n\n3. Create an SNS subscription to the topic created in step 2\n```\naws sns subscribe --topic-arn sns_topic_arn --protocol protocol_for_sns --notification-endpoint sns_subscription_endpoints\n```\nNote: you can execute this command once and then re-use the SNS subscription for all monitoring alarms.\n\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2\n```\naws cloudwatch put-metric-alarm --alarm-name `EC2_Instance_Status_Changes` --metric-name `EC2_Instance_Status_Changes`  --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace 'EC2_Instances_Changes' --alarm-actions sns_topic_arn\n```\n\nReferences:\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html\n2. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html\n3. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/put-metric-alarm.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/put-metric-filter.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/create-topic.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/subscribe.html ",
        "complianceTag": "Monitoring",
        "logicHash": "aqmrcczYRVUVH5QxOZw7aA",
        "ruleId": "D9.AWS.MON.26",
        "category": ""
    },
    {
        "name": "Ensure no Application Load Balancer allows incoming traffic from 0.0.0.0/0 to known TCP port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure Application Load Balancers are not exposed incoming traffic from 0.0.0.0/0 to known TCP ports",
        "severity": "Medium",
        "logic": "ApplicationLoadBalancer where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_TCP_Ports) and protocol in('TCP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1.  Create a new security group to replace the insecure security which is currently attached to the ALB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use set-security-groups command to replace the existing security group with new secure one.\n```\naws elbv2 set-security-groups --region REGION --load-balancer-arn ALB_ARN --security-groups SG_ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-update-security-groups.html\n2. https://docs.aws.amazon.com/cli/latest/reference/elbv2/set-security-groups.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html#cfn-elasticloadbalancingv2-loadbalancer-securitygroups\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb",
        "complianceTag": "Network Ports Security",
        "logicHash": "ndWLXYTM9YJ+I9j//8KMKQ",
        "ruleId": "D9.AWS.NET.82",
        "category": ""
    },
    {
        "name": "Ensure no Application Load Balancer allows incoming traffic from 0.0.0.0/0 to known UDP port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure Application Load Balancers are not exposed incoming traffic from 0.0.0.0/0 to known UDP ports.",
        "severity": "Medium",
        "logic": "ApplicationLoadBalancer where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_UDP_Ports) and protocol in('UDP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1.  Create a new security group to replace the insecure security which is currently attached to the ALB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use set-security-groups command to replace the existing security group with new secure one.\n```\naws elbv2 set-security-groups --region REGION --load-balancer-arn ALB_ARN --security-groups SG_ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-update-security-groups.html\n2. https://docs.aws.amazon.com/cli/latest/reference/elbv2/set-security-groups.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html#cfn-elasticloadbalancingv2-loadbalancer-securitygroups\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb",
        "complianceTag": "Network Ports Security",
        "logicHash": "ah7PgLifZYvA8UxBMKsvGg",
        "ruleId": "D9.AWS.NET.83",
        "category": ""
    },
    {
        "name": "Ensure no EC2 instance allows incoming traffic from 0.0.0.0/0 to known TCP port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure EC2 instances are not exposed incoming traffic from 0.0.0.0/0 to known TCP ports",
        "severity": "Medium",
        "logic": "Instance where isPublic=true and nics contain [ subnet.routeTable.associations length()>0 and subnet.routeTable.routes contain [ destinationCidrBlock='0.0.0.0/0' and gatewayId like 'igw-%' ] ] should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_TCP_Ports) and protocol in('TCP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console,  and Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/ .\n2. In the navigation pane, choose Instances.\n3. Select your instance and, in bottom half of the screen, choose the Security tab.\n4. Security groups lists the security groups that are associated with the instance. Inbound rules displays a list of the inbound rules that are in effect for the instance.\n5. Identify the security group with the scope 0.0.0.0/0 and a Known TCP port from the list in GSL.\n6. On the Edit inbound rules page, modify the traffic source that allow traffic from 0.0.0.0/0 to one of the port from the list.\n7. Select My IP from the Source dropdown list to allow inbound traffic only from your machine or  Select Custom from the Source dropdown list and enter appropriate range of IPs.\n8. Click Save to apply the changes.\n\n**From Command Line**\n1. Identify the security group associated with the instance.Remove the rule which has ingress is 0.0.0.0/0 to one of the from the GSL list.\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --protocol tcp --port PORT_NUMBER --cidr 0.0.0.0/0\n```\n2. Now add the inbound rules with different parameters, Modify the CIDR_BLOCK to appropriate range in order to restrict access from 0.0.0/0 to one of the port from the list.\n```\naws ec2 authorize-security-group-ingress --region REGION --group-name GROUP_NAME --protocol PROTOCOL --port PORT --cidr CIDR_BLOCK\n```\n**From CFT**\nUse the link to the Cloudformation resource from the references.\n\n**From TF**\nUse the link to the terraform resource from the references.\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html#\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance\n5. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html",
        "complianceTag": "Network Ports Security",
        "logicHash": "Hmoqq9DKfUcXhmtzbflM4A",
        "ruleId": "D9.AWS.NET.78",
        "category": ""
    },
    {
        "name": "Ensure no EC2 instance allows incoming traffic from 0.0.0.0/0 to known UDP port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure EC2 instances are not exposed incoming traffic from 0.0.0.0/0 to known UDP ports",
        "severity": "Medium",
        "logic": "Instance where isPublic=true and nics contain [ subnet.routeTable.associations length()>0 and subnet.routeTable.routes contain [ destinationCidrBlock='0.0.0.0/0' and gatewayId like 'igw-%' ] ] should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_UDP_Ports) and protocol in('UDP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console,  and Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/ .\n2. In the navigation pane, choose Instances.\n3. Select your instance and, in bottom half of the screen, choose the Security tab.\n4. Security groups lists the security groups that are associated with the instance. Inbound rules displays a list of the inbound rules that are in effect for the instance.\n5. Identify the security group with the scope 0.0.0.0/0 and a Known TCP port from the list in GSL.\n6. On the Edit inbound rules page, modify the traffic source that allow traffic from 0.0.0.0/0 to one of the port from the list.\n7. Select My IP from the Source dropdown list to allow inbound traffic only from your machine or  Select Custom from the Source dropdown list and enter appropriate range of IPs.\n8. Click Save to apply the changes.\n\n**From Command Line**\n1. Identify the security group associated with the instance.Remove the rule which has ingress is 0.0.0.0/0 to one of the from the GSL list.\n```\naws ec2 revoke-security-group-ingress --region REGION --group-name GROUP_NAME --protocol tcp --port PORT_NUMBER --cidr 0.0.0.0/0\n```\n2. Now add the inbound rules with different parameters, Modify the CIDR_BLOCK to appropriate range in order to restrict access from 0.0.0/0 to one of the port from the list.\n```\naws ec2 authorize-security-group-ingress --region REGION --group-name GROUP_NAME --protocol PROTOCOL --port PORT --cidr CIDR_BLOCK\n```\n**From CFT**\nUse the link to the Cloudformation resource from the references.\n\n**From TF**\nUse the link to the terraform resource from the references.\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/revoke-security-group-ingress.html#\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance\n5. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html",
        "complianceTag": "Network Ports Security",
        "logicHash": "ikvwbTj6G/PGTpQb+LXekg",
        "ruleId": "D9.AWS.NET.79",
        "category": ""
    },
    {
        "name": "Ensure no ELB allows incoming traffic from 0.0.0.0/0 to known TCP port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure ELBS are not exposed incoming traffic from 0.0.0.0/0 to known TCP ports.",
        "severity": "Medium",
        "logic": "ELB where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_TCP_Ports) and protocol in('TCP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1. Create a new security group to replace the insecure security which is currently attached to the ELB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use the following apply-security-groups-to-load-balancer command to associate a security group with a load balancer in a VPC. The specified security groups override the previously associated security groups.\n```\naws elb apply-security-groups-to-load-balancer --load-balancer-name my-loadbalancer --security-groups sg-ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elb/apply-security-groups-to-load-balancer.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elb",
        "complianceTag": "Network Ports Security",
        "logicHash": "vuNKgV19IlDzzLVS3QLH7Q",
        "ruleId": "D9.AWS.NET.86",
        "category": ""
    },
    {
        "name": "Ensure no ELB allows incoming traffic from 0.0.0.0/0 to known UDP port",
        "description": "In order to implement the principle of least privilege and reduce the possibility of a breach. Always make sure ELBS are not exposed incoming traffic from 0.0.0.0/0 to known UDP ports.",
        "severity": "Medium",
        "logic": "ELB where isPublic=true should not have nics contain [ securityGroups contain [ inboundRules contain [ scope='0.0.0.0/0' and port in($CloudGuard_Known_UDP_Ports) and protocol in('UDP', 'ALL') ] ] ]",
        "remediation": "\n**From Portal**\nA)\n1. Sign in to the AWS Management Console.Navigate to EC2 dashboard at https://console.aws.amazon.com/ec2/.\n2. In the NETWORK & SECURITY tab, choose Security Groups.\n3. Create a new Security group, add an appropriate scope other than 0.0.0.0/0 in the inbound rules.\nB)\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. On the navigation pane, under LOAD BALANCING, choose Load Balancers.\n3. Select the load balancer.\n4. On the Description tab, under Security, choose Edit security groups.\n5. To associate a security group with your load balancer, select it. To remove a security group from your load balancer, clear it.\n6. Choose Save.\n\n**From Command Line**\n1. Create a new security group to replace the insecure security which is currently attached to the ELB.\n```\naws ec2 create-security-group\t--region REGION --group-name SG_NAME --description \"SECURE SG\" --vpc-id VPC_ID\n```\n2. Add an inbound rule with appropriate scope/cidr range in order to limit the incoming traffic.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port PORT --cidr CIDR_BLOCK\n```\n3. Use the following apply-security-groups-to-load-balancer command to associate a security group with a load balancer in a VPC. The specified security groups override the previously associated security groups.\n```\naws elb apply-security-groups-to-load-balancer --load-balancer-name my-loadbalancer --security-groups sg-ID\n```\n**From CFT**\nUse the link from references to Cloudformation resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**From TF**\nUse the link from references to Terraform resource load balancer  and configure the security group with appropriate settings in order to limit the incoming traffic.\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elb/apply-security-groups-to-load-balancer.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elb",
        "complianceTag": "Network Ports Security",
        "logicHash": "/VWj2fD21enFRT3erNRY3A",
        "ruleId": "D9.AWS.NET.87",
        "category": ""
    },
    {
        "name": "Ensure security groups associated with EKS cluster do not have inbound rules with a scope of 0.0.0.0/0",
        "description": "Ensure that your Amazon EKS clusters' security groups allow inbound traffic only on TCP port 443 to protect against threats and meet compliance standards.",
        "severity": "Medium",
        "logic": "EksCluster should not have resourcesVpcConfig.clusterSecurityGroup contain [ inboundRules contain [ scope = '0.0.0.0/0'] ] or resourcesVpcConfig.additionalSecurityGroups contain [ inboundRules contain [ port != 443 and scope = '0.0.0.0/0'] ]",
        "remediation": "\n**From Portal**\n1. Login to AWS Console.\n2. Navigate to EKS Clusters.\n3. Select the EKS Cluster.\n4. Click on the Networking tab.\n5. Open each Security Group.\n6. Remove the inbound rule with a scope of '0.0.0.0/0'\n\n**From Command Line**\n1. Get the cluster security group:\n```\naws eks describe-cluster --name <cluster_name> --query cluster.resourcesVpcConfig.clusterSecurityGroup\n```\n2. Get the additional security groups:\n```\naws eks describe-cluster --name <cluster_name> --query cluster.resourcesVpcConfig.securityGroupIds\n```\n3. Get the security group inbound rules, for each security group id:\n```\naws ec2 describe-security-groups --group-ids <security_group_id> --query 'SecurityGroups[*].IpPermissions'\n```\n4. Remove the inbound rule with a scope of '0.0.0.0/0' from each security group:\n```\naws ec2 revoke-security-group-ingress --group-id <security_group_id> --protocol <protocol> --port <port> --cidr 0.0.0.0/0\n\n```\n\n**References**\n1. https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html\n",
        "complianceTag": "Network Security",
        "logicHash": "3cB1BuUoyTAbjYiZ8FASrg",
        "ruleId": "D9.AWS.NET.94",
        "category": ""
    },
    {
        "name": "Ensure that AWS Elastic Container Registry (ECR) repositories are not exposed to everyone, even with a condition.",
        "description": "Protect the Amazon ECR image repositories available within your AWS account from any unauthorized access. Amazon Elastic Container Registry uses resource-based policies to control access. These types of permission policies let you specify who has access to your ECR repositories and what actions they can perform on them. Allowing public access to your Amazon ECR image repositories through resource-based policies can lead to data leakage and/or data loss.",
        "severity": "Medium",
        "logic": "EcrRepository should not have policy.document.Statement contain [ Effect='Allow' and (Principal='*' or Principal.AWS='*') and Condition]",
        "remediation": "\n**From Portal**\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region that contains the repository to set a policy statement on.\n3. In the navigation pane, choose Repositories.\n4. On the Repositories page, choose the repository to set a policy statement on to view the contents of the repository.\n5. From the repository image list view, in the navigation pane, choose Permissions, Edit.\n6. Under Permission statements, select the policy statement that has Effect set to \"Allow\" and Principal set to \"*\", click on the Edit button to enter the edit mode.\n7. In the edit mode, explicitly grant permission to a specified entity (principal) when the effect is 'Allow'.\n8. Within Principal section, uncheck Everybody (*) checkbox and enter the AWS account ID or AWS service name in the Principal box, or select the IAM entity (user, group, role) allowed to access the selected ECR repository from All IAM entities table, based on your requirements.\n9. Save.\n\n**From TF**\nUse the resource \"aws_ecr_repository_policy\" to create policy. When the effect is 'Allow' Make sure that you don't have Principal='*' or 'AWS:*' in your policy document.\n```\nresource \"aws_ecr_repository_policy\" \"testpolicy\" {\nrepository = example-repository\n\npolicy =\n{\n...\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": [\n\"arn:aws:iam::account-id:user/user-1\",\n]\n}\n...\n}\n```\n\n**From Command Line**\nUse the following command to set repository policy. when the effect is 'Allow' Make sure that you don't have Principal='*' or 'AWS:*' in your policy policy.document.Statement\n```\naws ecr set-repository-policy --repository-name example-repository --policy-text file://my-policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/set-repository-policy.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/set-repository-policy.html#\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository_policy",
        "complianceTag": "Identity and Access Management",
        "logicHash": "yBmfWu5MOnNy0+BSDam4JQ",
        "ruleId": "D9.AWS.IAM.103",
        "category": ""
    },
    {
        "name": "Ensure that EC2 Metadata Service only allows IMDSv2",
        "description": "Using the Instance Metadata Service Version 2 (IMDSv2) provides additional protection against server-side request forgery (SSRF) attacks.",
        "severity": "Medium",
        "logic": "Instance where metadataOptions.httpEndpoint='enabled' should have metadataOptions.httpTokens='required'",
        "remediation": "\nNote: Modification of the metadata options is not yet available via AWS Console.\n\n**From TF**\nTo set the instance metadata 'http-tokens' to 'required', update the 'metadata_options' block:\n```\nresource \"aws_instance\" \"instance_example\" {\n..\nmetadata_options {\n..\nhttp_tokens = \"required\"\n..\n}\n..\n}\n```\n\n**From Command Line**\nTo set the instance metadata 'http-tokens' to 'required', run:\n```\naws ec2 modify-instance-metadata-options --instance-id INSTANCE-ID --http-tokens required\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance#metadata-options\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify-instance-metadata-options.html",
        "complianceTag": "Network Security",
        "logicHash": "DjbDyR7j/qruECNOoS9hfA",
        "ruleId": "D9.AWS.NET.90",
        "category": ""
    },
    {
        "name": "Ensure that NAT gateway is not associated in a private subnet",
        "description": "Don't define NAT gateway in the private subnet, to avoid the risk of exposing the private subnet to the internet",
        "severity": "Medium",
        "logic": "NatGateway where isPublic=true should have getResource('Subnet', subnetId) contain [routeTable.routes contain-any [gatewayId like '%igw%']]",
        "remediation": "\n**From Portal**\nNote: In order to do this, you need to change the route table or create a new NAT Gateway. Following are the steps:\n\n1. Sign in to the Amazon VPC console at https://console.aws.amazon.com/vpc/\n2. Choose NAT Gateways\n3. Before doing the step below, make sure that it is possible to temporary disable internet access of the instances associated with this Gateway.\n3. Find the Gateway that reside in a private subnet, and click delete.\n4. Create a new NAT gateway, associate it in a public subnet - subnet that routes to the internet through Internet Gateway. Choose the Elastic IP of the previous Gateway.\n\n**From Command Line**\n```\naws ec2 delete-nat-gateway --nat-gateway-id NAT_GATEWAY_ID\nthen\naws ec2 create-nat-gateway --subnet-id PUBLIC_SUBNET_ID --allocation-id PREVIOUS_ELASTIC_IP_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete-nat-gateway.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-nat-gateway.html ",
        "complianceTag": "Network Security",
        "logicHash": "dkySivNBREWtwVt9du9I2w",
        "ruleId": "D9.AWS.NET.60",
        "category": ""
    },
    {
        "name": "Ensure that SageMaker is placed in VPC",
        "description": "A SageMaker notebook instance is a Machine Learning (ML) compute instance running on Jupyter Notebook software. You can connect to your notebook instance from your VPC through an interface endpoint in your Virtual Private Cloud (VPC), instead of connecting over the internet. Ensure that your AWS SageMaker notebook instances placed in the VPC, to only access VPC resources for. AWS VPCs provides the controls to facilitate a formal process for approving and testing all network connections and changes to the firewall and router configurations.",
        "severity": "Medium",
        "logic": "SageMakerNotebook should have vpc",
        "remediation": "\n**From Portal:**\nThere is no possibility to move existing SageMaker notebook under VPC if they were not created inside VPC. To ensure that your AWS SageMaker notebook instances are running inside a VPC, you need to re-create the instance. Use following steps to create new notebook instance and deploy it under a VPC.\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\n2. Choose Notebook instances, and then choose Create notebook instance.\n3. On the Create notebook instance page, provide the following information (if a field is not mentioned, leave the default values).\na. For Notebook instance name, type a name for your notebook instance.\nb. For Notebook Instance type, choose ml.t2.medium. This is the least expensive instance type that notebook instances support, and it suffices for this exercise. If a ml.t2.medium instance type isn't available in your current AWS Region, choose ml.t3.medium.\nc. For Platform Identifier, choose a platform type to create the notebook instance on. This platform type dictates the Operating System and the JupyterLab version that your notebook instance is created with. For information about platform identifier type, see Amazon Linux 2 vs Amazon Linux notebook instances. For information about JupyterLab versions, see JupyterLab versioning.\nd. For IAM role, choose Create a new role, and then choose Create role. This IAM role automatically gets permissions to access any S3 bucket that has sagemaker in the name. It gets these permissions through the AmazonSageMakerFullAccess policy, which SageMaker attaches to the role.\ne. For VPC configuration under Network tab, Select the ID of the Virtual Private Cloud (VPC) where you want to deploy your new notebook instance from the VPC - optional dropdown list.\nf. Choose Create notebook instance.\n\n**From TF:**\nUse subnet_id field to place Sagemaker instance under VPC.\n```\nresource \"aws_sagemaker_notebook_instance\" \"example_name\" {\nname          = example_name\nrole_arn      = sagemaker_role_arn\ninstance_type = instance_type\nsecurity_groups = aws_security_group_sg_id\nsubnet_id = VPC_subnet_id\n\ntags = {\nName = \"SageMaker\"\n}\n}\n```\n\n**From Command Line:**\nUse following command to create SageMaker notebook instance using a VPC network. You need to enter the ID of the VPC subnet that you want to use for your instance and the ID of the security group required for access control.\n\nNote: If you specified SubnetId, SageMaker creates a network interface in your own VPC, which is inferred from the subnet ID that you provide in the input. When creating this network interface, SageMaker attaches the security group that you specified in the request to the network interface that it creates in your VPC. The security groups must be for the same VPC as specified in the subnet.\n\n```\naws sagemaker create-notebook-instance --region region_name --notebook-instance-name example_instance_name --instance-type type_of_instance --role-arn AmazonSageMaker_ExecutionRole_arn --kms-key-id kms_key_arn --subnet-id subnet_id --security-group-ids sg_ID\n```\n\nReferences:\n1. https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sagemaker_notebook_instance\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/create-notebook-instance.html ",
        "complianceTag": "Network Security",
        "logicHash": "3ZXdLsph2tZa7bMofIFszg",
        "ruleId": "D9.AWS.NET.48",
        "category": ""
    },
    {
        "name": "Ensure that at least one Load Balancer is attached to the service",
        "description": "Your Amazon ECS service should be configured to use Elastic Load Balancing to distribute traffic evenly across the tasks in your service.",
        "severity": "Medium",
        "logic": "EcsService should have loadBalancers length()>0",
        "remediation": "Load balancing settings can only be set on service creation. In order to verify the presence of a Load Balancer, please perform the following steps:\n**From Portal**\n1. Login to the AWS Management Console and open ECS at https://console.aws.amazon.com/ecs/home.\n2. Navigate to Cluster and choose the service\n3. In the detailed view of the cluster, select the service\n4. Ensure Load Balancer is present under the Target Group Name\n5. If there is no Load Balancer present in the Target Group Name then add a Load Balancer while creating a service.\n\n**From TF**\nTo attach Load Balancer, either specify 'elb_name' or 'target_group_arn'\n```\nresource \"aws_ecs_service\" \"lb_example\" {\nname = \"example\"\nload_balancer {\n+   elb_name = aws_elb.test.id\n+   container_name = \"mongo\"\n+   container_port = 8080\n}\n}\n```\nOR\n```\nresource \"aws_ecs_service\" \"lb_example\" {\nname = \"example\"\nload_balancer {\n+   target_group_arn = aws_lb_target_group.test.arn\n+   container_name = \"mongo\"\n+   container_port = 8080\n}\n}\n```\n\n\n**From Command Line**\nTo create a service with/behind load balancer , run:\n```\naws ecs create-service --cluster CLUSTER --service-name SERVICE_NAME --load-balancer LOAD_BALANCER --task-definition SAMPLE --desired-count 1\n\nOR\n\naws ecs create-service --cluster CLUSTER --service-name SERVICE --cli-input-json file://FILE.json\n```\nNOTE : file://FILE.json is the required configuration of the AWS cloudfront in json.\n\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-application-load-balancer.html\n2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-load-balancing.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecs_cluster\n4. https://docs.aws.amazon.com/cli/latest/reference/ecs/create-cluster.html\n5. https://docs.aws.amazon.com/cli/latest/reference/ecs/create-service.html",
        "complianceTag": "Network Security",
        "logicHash": "DbxIFICDYnwi+ajBFMPbiQ",
        "ruleId": "D9.AWS.NET.38",
        "category": ""
    },
    {
        "name": "Instances are Configured under Virtual Private Cloud",
        "description": "Instance should be configured in vpc. AWS VPCs provides the controls to facilitate a formal process for approving and testing all network connections and changes to the firewall and router configurations.",
        "severity": "Medium",
        "logic": "Instance should have vpc",
        "remediation": "\n**From Portal**\nStep 1: Identify EC2-Classic instances\n1. Choose Instances in the navigation pane.\n2. In the VPC ID column, the value for each EC2-Classic instance is blank or a - symbol. If the VPC ID column is not present, choose the gear icon and make the column visible.\n\nStep 2: Create an AMI\nAfter you've identified your EC2-Classic instance, you can create an AMI from it. Follow these links to create AMI: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-migrate.html or https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/Creating_EBSbacked_WinAMI.html\n\nStep 3: Launch an instance into your VPC\nAfter you've created an AMI, you can use the Amazon EC2 launch instance wizard to launch an instance into your VPC. The instance will have the same data and configurations as your existing EC2-Classic instance.\n\n1. Follow the procedure to launch an instance.\n2. Under Application and OS Images (Amazon Machine Image), choose My AMIs, ensure that Owned by me is selected, and select the AMI that you created. Alternatively, if you shared an AMI from another account, choose Shared with me, and select the AMI that you shared from your EC2-Classic account.\n3. Under Network settings, choose Edit (on the right), and do the following:\nFor VPC, select your VPC.\nFor Subnet, select the required subnet.\nFor Security group name, select the security group that you created for your VPC.\n4. Configure any other details that you require, such as the instance type and key pair. For information about the fields in the launch instance wizard, see Launch an instance using defined parameters.\n5. In the Summary panel, review your instance configuration, and then choose Launch instance.\n\n**From Command Line**\nUse the following describe-instances command to identify your EC2-Classic instances. The --query parameter displays only instances where the value for VpcId is null.\n```\naws ec2 describe-instances --query 'Reservations[*].Instances[?VpcId=='null']'\n```\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-migrate.html\n2. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/Creating_EBSbacked_WinAMI.html\n3. https://aws.amazon.com/premiumsupport/knowledge-center/ssm-migrate-ec2classic-vpc/\n4. https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-migrate-ec2-classic-to-vpc.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-instances.html ",
        "complianceTag": "Network Security",
        "logicHash": "Dhu3N8DGNtM+5hPKPZV4Cw",
        "ruleId": "D9.AWS.NET.12",
        "category": ""
    },
    {
        "name": "Make sure that ALB is protected by a WAF",
        "description": "Ensure that all your public AWS ALB are integrated with the Web Application Firewall (AWS WAF) service to protect against application-layer attacks",
        "severity": "Medium",
        "logic": "ApplicationLoadBalancer where dnsName unlike '%internal%' should have webACLId",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and open AWS WAF console https://console.aws.amazon.com/wafv2/homev2\n2. Create the Web ACLs or select an existing one\n3. Select the Associated AWS resources tab\n4. Click on Add AWS resources\n5. Under Resource Type, Select the resource type and then select the resource you want to associate with this web ACL.\nNote this rule requires the following permission: 'waf-regional:ListResourcesForWebACL'\n\n**From TF**\nUse the application load balancer as Load Balancer type:\n```\nresource \"aws_alb\" \"test\" {\ninternal = false\n+ load_balancer_type = \"application\"\nsecurity_groups    = [aws_security_group.lb_sg.id]\nsubnets  = [for subnet in aws_subnet.public : subnet.id]\n}\nenable_deletion_protection = true\n\naccess_logs {\nbucket  = aws_s3_bucket.lb_logs.bucket\nprefix  = \"test-lb\"\nenabled = true\n}\n```\n\n**From Command Line**\nTo create WAF ACL , run:\n```\naws waf create-web-acl --name NAME --metric-name METRIC-NAME --default-action Type=BLOCK --change-token TOKEN\n```\n\n**References**\n1. https://docs.aws.amazon.com/waf/latest/developerguide/getting-started.html\n2. https://docs.aws.amazon.com/config/latest/developerguide/alb-waf-enabled.html\n3. https://aws.amazon.com/blogs/aws/aws-web-application-firewall-waf-for-application-load-balancers/\n4. https://docs.aws.amazon.com/cli/latest/reference/waf/create-web-acl.html",
        "complianceTag": "Network Security",
        "logicHash": "7q931vDGZsZv8Bd11dmq7w",
        "ruleId": "D9.AWS.NET.35",
        "category": ""
    },
    {
        "name": "Process for Security Group Management - Detection of new Security Groups",
        "description": "CloudGuard Newly Detected Groups Behavior should be set to Full protection or lock to enforce Security Groups management process",
        "severity": "Medium",
        "logic": "Region should not have behavior='ReadOnly'",
        "remediation": "\n**From Portal**\nIn CloudGuard, there are two modes to manage Amazon AWS Security Groups:\na. Full Protection\nb. Read-Only\nFull Protection provides the CloudGuard administrator with full control of AWS security policy definition, access leases, and can interact with dynamic policy objects.\n\nIn Full Protection mode, you can manage an AWS Security Group only through CloudGuard. CloudGuard detects attempts to change a security group from the AWS environment (such as the AWS console), which starts Tamper Protection and can send an alert/notification. CloudGuard overrides the change that is made and reverts to the definition of the Security Group defined in CloudGuard. The alerts and notifications initiated from Tamper Protection occur when you start Full Protection for the necessary regions in your cloud account. CloudGuard locks down the configuration of the security groups in that region to make sure that the security group stays correctly configured.\n\nTo make a change in a Security Group that has Tamper Protection enabled, the change is made in CloudGuard. Use following steps to configure a Security Group that has Tamper Protection enabled.\n1. Navigate to the Security Groups page in the Network Security menu.\n2. Select the Security Group to be modified.\n3. Make the necessary changes to the Security Group (for example, add or change Inbound or Outbound services).\n4. Save the changes.\n\n**References**\n1. https://sc1.checkpoint.com/documents/CloudGuard_Dome9/Documentation/Network-Security/FullProtectionMode.htm ",
        "complianceTag": "Network Security",
        "logicHash": "KafKzONqrmwSkvVE1StCDQ",
        "ruleId": "D9.AWS.NET.22",
        "category": ""
    },
    {
        "name": "RDS cluster snapshots should be encrypted at rest",
        "description": "Encrypting data at rest reduces the risk that an unauthenticated user gets access to data that is stored on disk. Data in RDS snapshots should be encrypted at rest for an added layer of security.",
        "severity": "Medium",
        "logic": "RdsDbClusterSnapshot should have storageEncrypted=true",
        "remediation": "\n**From Portal**\nTo encrypt an unencrypted RDS snapshot\n1. Open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the navigation pane, choose Snapshots.\n3. Find the snapshot to encrypt under Manual or System.\n4. Select the check box next to the snapshot to encrypt.\n5. Choose Actions, then choose Copy Snapshot.\n6. Under New DB Snapshot Identifier, type a name for the new snapshot.\n7. Under Encryption, select Enable Encryption.\n8. Choose the KMS key to use to encrypt the snapshot.\n9. Choose Copy Snapshot.\n10. After the new snapshot is created, delete the original snapshot.\n11. For Backup Retention Period, choose a positive nonzero value. For example, 30 days.\n\n**From TF**\n```\nresource \"aws_db_cluster_snapshot\" \"example\" {\n...\n+ storage_encrypted = true\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/securityhub/latest/userguide/rds-controls.html#rds-4\n2. https://registry.terraform.io/providers/hashicorp/aws/4.2.0/docs/data-sources/db_cluster_snapshot ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "vxUqlHTBfYZyHJcfIwMRBw",
        "ruleId": "D9.AWS.CRY.80",
        "category": ""
    },
    {
        "name": "RDS database snapshots should be encrypted at rest",
        "description": "Encrypting data at rest reduces the risk that an unauthenticated user gets access to data that is stored on disk. Data in RDS snapshots should be encrypted at rest for an added layer of security.",
        "severity": "Medium",
        "logic": "RDSDBSnapshot should have encrypted=true",
        "remediation": "\n**From Portal**\nTo encrypt an unencrypted RDS snapshot\n1. Open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n2. In the navigation pane, choose Snapshots.\n3. Find the snapshot to encrypt under Manual or System.\n4. Select the check box next to the snapshot to encrypt.\n5. Choose Actions, then choose Copy Snapshot.\n6. Under New DB Snapshot Identifier, type a name for the new snapshot.\n7. Under Encryption, select Enable Encryption.\n8. Choose the KMS key to use to encrypt the snapshot.\n9. Choose Copy Snapshot.\n10. After the new snapshot is created, delete the original snapshot.\n11. For Backup Retention Period, choose a positive nonzero value. For example, 30 days.\n\n**From TF**\n```\nresource \"aws_db_snapshot\" \"example\" {\n...\n+ storage_encrypted = true\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/securityhub/latest/userguide/rds-controls.html#rds-4\n2. https://registry.terraform.io/providers/hashicorp/aws/4.8.0/docs/resources/db_snapshot ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "kvQnf3OU+G51iunT1IzVOQ",
        "ruleId": "D9.AWS.CRY.81",
        "category": ""
    },
    {
        "name": "Remove Unused Security Groups that are open to all",
        "description": "A security group should always have attached protected assets. Removing Unused Security Groups that are open to all, is the expected outcome of the firewall and router rule sets review.",
        "severity": "Medium",
        "logic": "SecurityGroup where networkAssetsStats contain-all [ count = 0 ] or networkInterfaces isEmpty() should not have inboundRules with [ scope='0.0.0.0/0' and portTo=0]",
        "remediation": "\n**From Portal:**\nUse following steps to delete the unused security group.\n1. Note down the unused Security Groups detected by the CloudGuard Report.\n2. Go to EC2 console and navigate to security groups.\n3. Select all the security groups and click on 'Actions'.\n4. Click on 'Delete security groups'.\n\nUse following steps to delete the identified inbound rules where the scope is set to 0.0.0.0/0 and port 0..\n1. Login to the AWS Management Console at https://console.aws.amazon.com/vpc/home\n2. In the left pane, click Security Groups\n3. For each security group, perform the following:\n4. Select the security group to update, choose Actions, and then choose Edit inbound rules to remove an inbound rule or Edit outbound rules to remove an outbound rule.\n5. Choose the Delete button to the right of the rule to delete.\n6. Choose Preview changes, Confirm.\n\n**From Command Line:**\nIdentify the security group open to all and run the following command to delete an EC2 security group created within EC2-Classic.\n```\naws ec2 delete-security-group --region region_name --group-name security_group_name\n```\n\nIdentify the security group open to all and run the following command to delete an EC2 security group created within EC2-VPC.\n```\naws ec2 delete-security-group --region region_name --group-id security_group_id\n```\n\nReferences:\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html#deleting-security-group-rule\n2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html#deleting-security-group\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete-security-group.html ",
        "complianceTag": "Network Security",
        "logicHash": "DeP6yd+sLxaWoAgbGP4HQw",
        "ruleId": "D9.AWS.NET.57",
        "category": ""
    },
    {
        "name": "Restrict outbound traffic to that which is necessary, and specifically deny all other traffic",
        "description": "Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that no security group allows unrestricted egress access",
        "severity": "Medium",
        "logic": "SecurityGroup should not have outboundRules with [ protocol='ALL' and scope='0.0.0.0/0' ]",
        "remediation": "Reduce the scope of the outbound rules to just the necessary scope, protocol, and ports.\n**From Portal**\n1. Login to the AWS Management Console and open Amazon VPC console https://console.aws.amazon.com/vpc/home\n2. In the navigation pane, choose Security Groups.\n3. For each security group, perform the following:\n4. Select the security group\n5. Click the Outbound Rules tab\n6. Identify the rules to be removed\n7. Edit the Outbound rule , change the source cidr range, port, protocol or Delete the rule.\n8. Click Save\n\n**From TF**\nAdd CIDR range, port, protocol to restrict egress access from all port, protocol and range.\n\n```\nresource \"aws_security_group\" \"positive2\" {\negress {\nfrom_port         = 3306\nto_port           = 3306\n- protocol          = \"ALL\"\n+ protocol          = \"tcp\"\n- cidr_blocks       = [\"0.0.0.0/0\"]  # != \"0.0.0.0/0\"\n+ cidr_blocks       = [\"10.0.2.0/0\"]\nsecurity_group_id = aws_security_group.default.id\n}\n}\n```\n\n**From Command Line**\nTo make sure security groups doesn't allow egress to 0.0.0.0/0 or to all port, run:\n```\naws ec2 revoke-security-group-egress --region REGION --group-name GROUP-NAME --protocol PROTOCOL --port PORT --cidr 0.0.0.0/0\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n3. https://docs.aws.amazon.com/cli/latest/reference/ec2/revoke-security-group-egress.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group",
        "complianceTag": "Network Security",
        "logicHash": "I+ZBV/U6P9pRm0rJMbPClA",
        "ruleId": "D9.AWS.NET.09",
        "category": ""
    },
    {
        "name": "ACM has a PENDING_VALIDATION Certificate",
        "description": "Check the ACM for certificates that have the status PENDING_VALIDATION",
        "severity": "Low",
        "logic": "AcmCertificate should not have status like 'PENDING_VALIDATION'",
        "remediation": "\n**From Portal**\nTo manually check your certificate:\n1. Open the AWS Certificate Manager console at https://console.aws.amazon.com/acm/home.\n2. Expand a certificate to view its details.\n3. Find the Renewal Status in the Details section. If you don't see the status, ACM hasn't started the managed renewal process for this certificate.\n\nManaged renewal process for this certificate:\nACM provides managed renewal for your Amazon-issued SSL/TLS certificates. This means that ACM will either renew your certificates automatically (if you are using DNS validation), or it will send you email notices when expiration is approaching. These services are provided for both public and private ACM certificates.\n\n**From Command Line**\n```\naws acm describe-certificate --certificate-arn arn:aws:acm:region:123456789012:certificate/97b4deb6-8983-4e39-918e-ef1378924e1e\n```\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/managed-renewal.html\n2. https://docs.aws.amazon.com/acm/latest/userguide/check-certificate-renewal-status.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "3ET5Dxyu5GbmDK8u9pulwg",
        "ruleId": "D9.AWS.CRY.55",
        "category": ""
    },
    {
        "name": "ALB secured listener certificate about to expire in one month",
        "description": "Ensure that SSL/TLS certificates stored in AWS IAM are renewed one month before expiry.",
        "severity": "Low",
        "logic": "ApplicationLoadBalancer should not have listeners contain [ certificates contain [ expiration before(30, 'days') ] ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard\n3. Go to Load Balancing and click Load Balancers.\n4. Select the Application Load Balancer for which certificate is expiring in one month.\n5. Navigate to the Load Balancer section, and then the Listeners tab. Select the listener and click on View/edit certificates tab, and then click Add Certificate. You can add or import ACM or IAM certificates from here.\n\n**From Command Line**\nRun below Command to replace the SSL certificates that are about to expire with new certificates uploaded to IAM.\n```\naws iam upload-server-certificate --server-certificate-name EXAMPLE_CERTIFICATE --certificate-body file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\nRun below command to replace the ELB existing SSL certificate with the newly one uploaded to AWS IAM through upload command in previous step.\n```\naws elb set-load-balancer-listener-ssl-certificate --load-balancer-name EXAMPLE_NAME --load-balancer-port 443 --ssl-certificate-id EXAMPLE_CERTIFICATE_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://aws.amazon.com/certificate-manager/\n3. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-certificates.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "/lOYpgMnl42VAvXKTLTF+Q",
        "ruleId": "D9.AWS.CRY.13",
        "category": ""
    },
    {
        "name": "AWS Kinesis streams are encrypted with customer managed CMK",
        "description": "Use KMS customer-managed keys to protect the Kinesis Streams and metadata. Using KMS customer-managed keys, you gain full control over who can use the keys to access AWS Kinesis data (including the system metadata). The AWS KMS service allows you to create, rotate, disable and audit CMK encryption keys.",
        "severity": "Low",
        "logic": "Kinesis should have encryptionKey.isCustomerManaged=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Console.\n2. Go to Amazon Kinesis Service.\n3. Select the reported Kinesis data stream and click on 'configuration'.\n4. Choose 'Encryption' tab under 'configuration'.\n5. Check 'Enable serve-side encryption' box and select 'Use customer managed CMK'.\n6. Click Save Changes.\n\n**From TF**\n```\nresource \"aws_kinesis_stream\" \"test\" {\nname             = \"terraform-kinesis-test\"\nshard_count      = \"VALUE\"\nretention_period = \"VALUE\"\n\nshard_level_metrics = [\n\"IncomingBytes\",\n\"OutgoingBytes\",\n]\n\ntags = {\nEnvironment = \"test\"\n}\n\n+ encryption_type = ... # i.e \"KMS\" but different from None\n\nkms_key_id = \"alias/aws/kinesis\"\n}\n```\n\n**From Command Line**\n```\naws kinesis start-stream-encryption --encryption-type KMS --key-id KMS_KEY_ID --stream-name EXAMPLE_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/streams/latest/dev/creating-using-sse-master-keys.html\n2. https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html\n3. https://docs.aws.amazon.com/streams/latest/dev/amazon-kinesis-streams.html\n4. https://registry.terraform.io/modules/rodrigodelmonte/kinesis-stream/aws/latest\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kinesis_stream ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "lV0iUNU5lSUL3YDk7MCeuw",
        "ruleId": "D9.AWS.CRY.21",
        "category": ""
    },
    {
        "name": "Credentials report was generated in the last 24 hours",
        "description": "Credentials report should have been generated in the last 24 hours to support the AWS tests executed against the report's result. This CloudGuard Prerequisite for CIS AWS Identity and Access Management checks.",
        "severity": "Low",
        "logic": "Iam should have credentialReportGeneratedTime after (-24, 'hours')",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, choose Credential report.\n3. Choose Download Report.\n\n**From Command Line**\nTo generate credential report , run:\n```\naws iam get-credential-report\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html\n2. https://docs.aws.amazon.com/cli/latest/reference/iam/get-credential-report.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "4AL7qKzBoE9iFUzgwwhREQ",
        "ruleId": "D9.AWS.IAM.111",
        "category": ""
    },
    {
        "name": "Determine if CloudFront CDN is in use",
        "description": "CloudFront provides scalable, distributed, and inexpensive Content Distribution Network (CDN) within AWS. The use of a CDN can provide a layer of security between your origin content and the destination. It can also serve a critical role in consistent delivery of content during a DDoS attack or unexpected volume increases. This buffer can help give you the time to scale out your infrastructure to meet the demand and/or identify the origin to mitigate the risk if an attack. Ensure that AWS CloudFront Content Delivery Network (CDN) service is used within your AWS account to secure and accelerate the delivery of your website",
        "severity": "Low",
        "logic": "CloudFront should have distributionConfig.origins and distributionConfig.enabled = 'true'",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and open CloudFront Distributions Dashboard at https://console.aws.amazon.com/cloudfront/v3/.\n2. In the left navigation panel, click Distributions.\n3. Click Create Distribution.\n4. Specify settings for the distribution.\n5. Click 'Save Changes'.\n\n**From TF**\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\norigin {\ndomain_name = aws_s3_bucket.b.bucket_regional_domain_name\norigin_id   = local.s3_origin_id\n\ns3_origin_config {\norigin_access_identity = \"origin-access-identity/cloudfront/ABCDEFG1234567\"\n}\n}\n\n+ enabled             = true\nis_ipv6_enabled     = true\ncomment             = \"Some comment\"\ndefault_root_object = \"index.html\"\n}\n```\n\n**From Command Line**\nTo create cloudfront distribution with specific configuration, run:\n```\naws cloudfront create-distribution --distribution-config file://FILE.json\n```\nNOTE :FILE.json contains configuration of cloudfront distribution.\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-creating-console.html\n2. https://docs.aws.amazon.com/cli/latest/reference/cloudfront/index.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution",
        "complianceTag": "Network Security",
        "logicHash": "uF4YP8nPRZMp7nj2jXbczQ",
        "ruleId": "D9.AWS.NET.26",
        "category": ""
    },
    {
        "name": "Do not setup access keys during initial user setup for all IAM users that have a console password",
        "description": "AWS console defaults to no check boxes selected when creating a new IAM user. When cerating the IAM User credentials you have to determine what type of access they require.\nProgrammatic access: The IAM user might need to make API calls, use the AWS CLI, or use the Tools for Windows PowerShell. In that case, create an access key (access key ID and a secret access key) for that user.\nAWS Management Console access: If the user needs to access the AWS Management Console, create a password for the user.\nRequiring the additional steps be taken by the user for programmatic access after their profile has been created will give a stronger indication of intent that access keys are\n[a] necessary for their work and [b] once the access key is established on an account that the keys may be in use somewhere in the organization.\nNote: Even if it is known the user will need access keys, require them to create the keys themselves or put in a support ticket to have them created as a separate step from user creation.",
        "severity": "Low",
        "logic": "IamUser where passwordEnabled = 'true' should not have createDate dateDifference(firstAccessKey.lastRotated, 'seconds') < 60",
        "remediation": "\n**From Portal**\nPerform the following to delete access keys that do not pass the audit:\n1. Login to the AWS Management Console: https://console.aws.amazon.com/iam/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Click on Security Credentials\n6. As an Administrator\n- Click on the X (Delete) for keys that were created at the same time as the user profile but have not been used.\n7. As an IAM User\n- Click on the X (Delete) for keys that were created at the same time as the user profile but have not been used.\n\n\n**From TF**\nTo delete an IAM user access key, delete the following resource:\n```\nresource \"aws_iam_access_key\" \"example_access_key\" {\n..\nuser   = \"USER-NAME\"\n..\n}\n```\n\n**From Command Line**\nTo delete an IAM user access key, run:\n```\naws iam delete-access-key --access-key-id ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/iam/delete-access-key.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "BBk5DPEXxU00Xi0gg5BbXA",
        "ruleId": "D9.AWS.IAM.79",
        "category": ""
    },
    {
        "name": "ELB is created with Access logs enabled",
        "description": "ELB logs provide insights and audit evidence for traffic patterns and originating sources. In the absence of these logs, it is very hard to complete incident response actions.",
        "severity": "Low",
        "logic": "ELB should have accessLog.enabled=true",
        "remediation": "\n**From Portal**\n1. Go to the Amazon EC2 console at https://console.aws.amazon.com/ec2/. In the navigation pane, choose Load Balancers.\n2. Select your load balancer.\n3. On the Description tab, choose Edit attributes.\n4. On the Edit load balancer attributes page, Choose Configure access logs.\n5. Check Enable for Access Logs.\n6. Provide a name for your S3 bucket and check Create this location for me or provide the name for a bucket which already exists.\n7. Click Save.\n\n**From TF**\n```\nresource \"aws_elb\" \"example1\" {\naccess_logs {\nbucket = \"example_bucket\"\n}\nother required fields here\n}\n\nresource \"aws_lb\" \"example2\" {\naccess_logs {\nbucket = \"example2_bucket\"\n}\nother required fields here\n}\n```\n\nNote: aws_alb is known as aws_lb. The functionality is identical. For classic load balancers, ensure that the aws_elb resource has an access_logs block configured with a bucket. For next generation load balancers, ensure that the aws_lb resource has an access_logs block configured with a bucket.\n\n**From Command Line**\nTo enable access logs for your load balancer:\n```\naws elb modify-load-balancer-attributes --load-balancer-name LOAD_BALANCER_NAME --load-balancer-attributes file://my-json-file.json\n```\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/enable-access-logging.html\n2. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elbv2/modify-load-balancer-attributes.html ",
        "complianceTag": "Logging",
        "logicHash": "YkOGxOEq6wQ61pilaX890A",
        "ruleId": "D9.AWS.LOG.13",
        "category": ""
    },
    {
        "name": "ELB secured listener certificate expires in one month",
        "description": "Ensure that SSL/TLS certificates stored in AWS IAM are renewed one month before expiry.",
        "severity": "Low",
        "logic": "ELB should not have elbListeners contain [ certificate.expiration before(30, 'days') ]",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard\n3. Go to Load Balancing and click Load Balancers.\n4. Select the Elastic Load Balancer for which certificate is expiring in one month.\n5. Navigate to the Load Balancer section, and then the Listeners tab. Select the listener and click on View/edit certificates tab, and then click Add Certificate. You can add or import ACM or IAM certificates from here.\n\n**From Command Line**\nRun below Command to replace the SSL certificates that are about to expire with new certificates uploaded to IAM.\n```\naws iam upload-server-certificate --server-certificate-name EXAMPLE_CERTIFICATE --certificate-body file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\nRun below command to replace the ELB existing SSL certificate with the newly one uploaded to AWS IAM through upload command in previous step.\n```\naws elb set-load-balancer-listener-ssl-certificate --load-balancer-name EXAMPLE_NAME --load-balancer-port 443 --ssl-certificate-id EXAMPLE_CERTIFICATE_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://aws.amazon.com/certificate-manager/\n3. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-certificates.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "rjAZKSkA1Pd94GXR2KAAPw",
        "ruleId": "D9.AWS.CRY.11",
        "category": ""
    },
    {
        "name": "Enable ALB Elastic Load Balancer v2 (ELBv2) access log",
        "description": "ELBv2 ALBs should have have access log enabled to capture detailed information about requests sent to your load balancer. Each log contains information such as the time the request was received, the client's IP address, latencies, request paths, and server responses. You can use these access logs to analyze traffic patterns and troubleshoot issues.",
        "severity": "Low",
        "logic": "ApplicationLoadBalancer should not have attributes contain [ key='access_logs.s3.enabled' and value='false' ]",
        "remediation": "\n**From Portal**\n1. Sign into the AWS console\n2. In the console, select the specific region\n3. Navigate to EC2 dashboard\n4. Click 'Load Balancers' (Left Panel)\n5. Select the reported ELB\n6. Click 'Actions' drop-down\n7. Click 'Edit attributes'\n8. In the 'Edit load balancer attributes' popup box, select 'Enable' for 'Access logs' and configure S3 location where you want to store ELB logs\n\n**From TF**\n```\nresource \"aws_lb\" \"test\" {\n...\nname = \"test_lb\"\n+ access_logs {\n+   bucket  = aws_s3_bucket\n+   prefix  = \"test-lb\"\n+   enabled = true\n+ }\n}\n```\n\n**From Command Line**\nTo enable access logs for your load balancer:\n```\naws elb modify-load-balancer-attributes --load-balancer-name LOAD_BALANCER_NAME --load-balancer-attributes file://my-json-file.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elbv2/modify-load-balancer-attributes.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb ",
        "complianceTag": "Logging",
        "logicHash": "TR3FjRP8zafc7Oe8rAI6UA",
        "ruleId": "D9.AWS.LOG.15",
        "category": ""
    },
    {
        "name": "Ensure ACM only has certificates with single domain names, and none with wildcard domain names",
        "description": "Checks for ACM Certificates with wildcard domain names instead of single domain names. ACM allows you to use wildcards (*) in the domain name, to protect several sites in the same domain. There is a risk with this type of certificate, since if the private key of a certificate is compromised, then all domain and subdomains that use the compromised certificate are potentially compromised. It is recommended to use single domain name certificates instead of wildcard certificates to reduce these associated risks.",
        "severity": "Low",
        "logic": "AcmCertificate should not have domainValidationOptions contain [ domainName like '%*%' ]",
        "remediation": "\n**From Portal**\nReplace the reported wildcard certificate with single domain name certificate for all the first-level subdomains resulted from the domain name of the website secured with the wildcard certificate and delete the reported wildcard domain certificate.\n\nTo create a new certificate with a single domain:\n1. Sign in on the AWS console\n2. In the console, select the specific region\n3. Navigate to Certificate Manager\n4. In 'Request a certificate' page,\n1. Enter the fully qualified domain name in the 'Fully qualified domain name' box. Ensure it does not contain a wildcard character i.e. *.\n2. Select the validation method.\n3. Select an 'Key algorithm' and click on 'Request'. The certificate status should change from 'Pending validation' to 'Issued'.\n4. Now access your application's web server configuration and replace the wildcard certificate with the newly issued single domain name certificate.\n\nTo delete a wildcard certificate:\n1. Sign in on the AWS console\n2. In the console, select the specific region\n3. Navigate to the Certificate Manager(ACM) service\n4. Select the certificate\n5. Under 'Actions' drop-down click 'Delete'\n6. On 'Delete certificate' popup windows, Click 'Delete'\n\n**From TF**\n```\nresource \"aws_acm_certificate\" \"cert\" {\ndomain_name       = \"example.com\"\nvalidation_method = \"DNS\"\n\ntags = {\nEnvironment = \"test\"\n}\n\nlifecycle {\ncreate_before_destroy = true\n}\n}\n```\n\n**From Command Line**\n1. Replace the wildcard certificate with single domain name. Run below command to request an certificate.\n```\naws acm request-certificate --domain-name example.com --key-algorithm ALGORITHM_TYPE --validation-method METHOD_OF_VALIDATION\n```\n2. AWS issues the certificate once the new ACM certificate is validated and its status changed to 'Issued'. Now access your application's web server configuration and replace the wildcard certificate with the newly issued single domain name certificate.\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html\n2. https://docs.aws.amazon.com/cli/latest/reference/acm/request-certificate.html\n3. https://docs.aws.amazon.com/acm/latest/userguide/gs.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/acm_certificate\n5. https://docs.aws.amazon.com/cli/latest/reference/acm/request-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "naSojZJQj6xXy5OU0G3JNg",
        "ruleId": "D9.AWS.CRY.27",
        "category": ""
    },
    {
        "name": "Ensure AWS CloudFront distribution with access logging is enabled",
        "description": "Ensure that your AWS Cloudfront distributions logging is enabled. CloudFront distribution logging is used to track all the requests for the content delivered through the Content Delivery Network (CDN) which is helpful during investigation activities and provide audit trail that is used for audit purposes.",
        "severity": "Low",
        "logic": "CloudFront should have distributionConfig.logging.enabled=true and distributionConfig.logging.bucket like '%.s3.amazonaws.com'",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and open CloudFront Distributions Dashboard at https://console.aws.amazon.com/cloudfront/v3/.\n2. Click the reported distribution.\n3. On 'General' tab, click 'Edit' button.\n4. On 'Edit Distribution' page, Set 'Logging' to 'On', select a 'Bucket for Logs' and 'Log Prefix' as desired.\n5. Click 'Save Changes'.\n\n**From TF**\nTo enable access logging in AWS CloudFront distribution set the 'logging_config' field :\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\norigin {\ndomain_name = aws_s3_bucket.b.bucket_regional_domain_name\norigin_id   = local.s3_origin_id\n\ns3_origin_config {\norigin_access_identity = \"origin-access-identity/cloudfront/ABCDEFG1234567\"\n}\n}\n\nenabled             = true\nis_ipv6_enabled     = true\ndefault_root_object = \"index.html\"\n\n+ logging_config {\n+   include_cookies = false\n+   bucket          = \"mylogs.s3.amazonaws.com\"\n+   prefix          = \"myprefix\"\n+ }\n}\n```\n\n**From Command Line**\nTo update the existing cloudfront , run:\n```\naws cloudfront update-distribution --id ID --distribution-config file://FILE.json --if-match E-TAG\n```\nNOTE : file://FILE.json is the required configuration of the AWS cloudfront in json.\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/logging.html\n2. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html\n3. https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-accesslogs-enabled.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudfront/get-distribution-config.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution  ",
        "complianceTag": "Network Security",
        "logicHash": "7qE3jaO8SmIAT6/n4sSOWg",
        "ruleId": "D9.AWS.NET.41",
        "category": ""
    },
    {
        "name": "Ensure AWS CloudFront web distribution with geo restriction is enabled",
        "description": "Geo Restriction has the ability to block IP addresses based on Geo IP by whitelist or blacklist a country in order to allow or restrict users in specific locations from accessing web application content. It is recommended to have geo restriction feature enabled, to restrict or allow users in specific locations accessing web application content. This configuration helps with prevention of DDos Attacks.",
        "severity": "Low",
        "logic": "CloudFront should not have distributionConfig.restrictions.geoRestriction.restrictionType='none'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console\n2. Select the region, from the region drop-down, in which the issue is generated\n3. Navigate to CloudFront Distributions Dashboard\n4. Select relevant Distribution\n5. On 'Geographic Restrictions' tab, click the 'Edit' button\n6. On 'Edit Geo-Restrictions' page, Set 'Enable Geo-Restriction' to 'Yes' and whitelist/blacklist countries as per your requirement.\n7. Click 'Yes, Edit'\n\n**From TF**\n\nAdd the geo_restriction field to enable AWS CloudFront web distribution with geo restriction\n\n```\nresource \"aws_cloudfront_distribution\" \"test\" {\norigin {\ndomain_name = aws_s3_bucket.b.bucket_regional_domain_name\norigin_id   = local.s3_origin_id\n\ns3_origin_config {\norigin_access_identity = \"origin-access-identity/cloudfront/ABCDEFG1234567\"\n}\n}\n\n+ restrictions {\n+   geo_restriction {\n+    restriction_type = \"whitelist\"\n+    locations        = [\"US\", \"CA\"]\n+ }\n\n}\n```\n\n**From Command Line**\nTo update the existing cloudfront , run:\n```\naws cloudfront update-distribution --id ID --distribution-config file://FILE.json --if-match E-TAG\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/georestrictions.html\n2. https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-geo-restriction/\n3. https://docs.aws.amazon.com/cli/latest/reference/cloudfront/update-distribution.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution",
        "complianceTag": "Network Security",
        "logicHash": "shbYj9pBkVUTw7rdUk4kaQ",
        "ruleId": "D9.AWS.NET.42",
        "category": ""
    },
    {
        "name": "Ensure AWS CloudFront web distributions use custom (and not default) SSL certificates",
        "description": "Custom SSL certificates give you full control over your CloudFront content. Custom certificates allow your users to access content by using alternate domain name. You can store custom certificates in AWS Certificate Manager (ACM) or in IAM. It recommended to use custom SSL Certificate to access CloudFront content to have more control over your data.",
        "severity": "Low",
        "logic": "CloudFront should not have distributionConfig.viewerCertificate.certificateSource like '%cloudfront%'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS console\n2. Select the region, from the region drop-down, in which the issue is generated\n3. Navigate to CloudFront Distributions Dashboard\n4. Click the reported distribution\n5. On the 'General' tab, click the 'Edit' button\n6. On 'Edit Distribution' page set 'SSL Certificate' to 'Custom SSL Certificate (example.com):', select a certificate or type your certificate ARN in the field and other parameters as per your requirement.\n7. Click 'Save changes'\n\n**From TF**\n```\nresource \"aws_cloudfront_distribution\" \"example1\" {\nviewer_certificate {\n...\nacm_certificate_arn = \"aws_acm_certificate_arn\"\n...\n}\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html#using-https-viewers-to-cloudfront-procedure\n2. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/HowToUpdateDistribution.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution ",
        "complianceTag": "Network Security",
        "logicHash": "0LEwIEw8FtKcM0O+Gd9Law",
        "ruleId": "D9.AWS.NET.43",
        "category": ""
    },
    {
        "name": "Ensure AWS Config is enabled in all regions",
        "description": "AWS Config is a web service that performs configuration management of supported AWS resources within your account and delivers log files to you. The recorded information includes the configuration item (AWS resource), relationships between configuration items (AWS resources), any configuration changes between resources. It is recommended to enable AWS Config be enabled in all regions.",
        "severity": "Low",
        "logic": "Region should have configurationRecorders with [allSupported=true]",
        "remediation": "\n**From Portal**\n1. Log in to the AWS Management Console at https://console.aws.amazon.com/.\n2. At the top right of the console select the region you want to focus on.\n3. Click Services.\n4. Click Config.\n5. Define which resources you want to record in the selected region. Include global resources (IAM resources).\n6. Select an S3 bucket in the same account, or in another managed AWS account.\n7. Create an SNS Topic from the same AWS account, or from another managed AWS account.\n\n**From Command Line**\n1. Ensure there is an appropriate S3 bucket, SNS topic, and IAM role per the AWS Config Service prerequisites.\n2. Run this command to set up the configuration recorder\n```\naws configservice subscribe --s3-bucket BUCKET_NAME --sns-topic SNS_TOPIC_NAME or ARN --iam-role IAM_ROLE_ARN\n```\n3. Run this command to start the configuration recorder:\n```\nstart-configuration-recorder --configuration-recorder-name RECORDER_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-prereq-config.html\n2. https://docs.aws.amazon.com/config/latest/developerguide/manual-setup.title.html\n3. https://docs.aws.amazon.com/config/latest/developerguide/gs-cli-prereq.html\n4. https://docs.aws.amazon.com/cli/latest/reference/configservice/subscribe.html\n5. https://docs.aws.amazon.com/cli/latest/reference/configservice/start-configuration-recorder.html\n6. https://workbench.cisecurity.org/benchmarks/679 ",
        "complianceTag": "Logging",
        "logicHash": "cP2oOkH89jFbY2JNWhyEdg",
        "ruleId": "D9.AWS.LOG.04",
        "category": ""
    },
    {
        "name": "Ensure AWS Elastic MapReduce (EMR) clusters capture detailed log data to Amazon S3",
        "description": "EMR cluster can be configured to periodically archive the log files stored on the master node to Amazon S3. This ensures that the log files are available after the cluster terminates, whether this is through normal shut down or due to an error. Amazon EMR archives the log files to Amazon S3 at 5 minute intervals.",
        "severity": "Low",
        "logic": "EmrCluster should have logUri",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console, and open the Amazon EMR console at https://console.aws.amazon.com/emr/.\n2. Under EMR on EC2 in the left navigation pane, choose Clusters, and then choose Create cluster.\n3. Under Cluster logs, select the Publish cluster-specific logs to Amazon S3 check box.\n4. In the Amazon S3 location field, type (or browse to) an Amazon S3 path to store your logs. If you type the name of a folder that doesn't exist in the bucket, Amazon S3 creates it.\nNote: When you set this value, Amazon EMR copies the log files from the EC2 instances in the cluster to Amazon S3. This prevents the log files from being lost when the cluster ends and the EC2 terminates the instances hosting the cluster. These logs are useful for troubleshooting purposes. For more information, see View log files.\n5. Optionally, select the Encrypt cluster-specific logs check box. Then, select an AWS KMS key from the list, enter a key ARN, or create a new key. This option is only available with Amazon EMR version 5.30.0 and later, excluding version 6.0.0. To use this option, add permission to AWS KMS for your EC2 instance profile and Amazon EMR role. For more information, see To encrypt log files stored in Amazon S3 with an AWS KMS customer managed key.\n6. Choose any other options that apply to your cluster.\n7. To launch your cluster, choose Create cluster.\n\n**From TF**\n```\nresource \"aws_emr_cluster\" \"example\" {\n+ log_uri = \"s3n://my-emr-logs/test/example\"\n}\n```\n\n**From Command Line**\n1. To archive log files to Amazon S3 using the AWS CLI, type the create-cluster command and specify the Amazon S3 log path using the --log-uri parameter. To log files to Amazon S3 type the following command and replace myKey with the name of your EC2 key pair.\n```\naws emr create-cluster --name CLUSTER_NAME --release-label EMR_RELEASE_VERSION--log-uri S3_LOCATION --applications Name=Hadoop Name=Hive Name=Pig --use-default-roles --ec2-attributes KeyName=myKey --instance-type EC2_INSTANCE_TYPE --instance-count VALUE\n```\n2. When you specify the instance count without using the --instance-groups parameter, a single primary node is launched, and the remaining instances are launched as core nodes. All nodes will use the instance type specified in the command.\n\nNote: If you have not previously created the default Amazon EMR service role and EC2 instance profile, enter aws emr create-default-roles to create them before typing the create-cluster subcommand.\n\n**References**\n1. https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-debugging.html\n2. https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/ensure-amazon-emr-logging-to-amazon-s3-is-enabled-at-launch.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/emr_cluster\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/emr/create-cluster.html ",
        "complianceTag": "Logging",
        "logicHash": "EPamyDH5iuItBSXrzk1lsA",
        "ruleId": "D9.AWS.LOG.17",
        "category": ""
    },
    {
        "name": "Ensure AWS IAM policies allow only the required privileges for each role",
        "description": "IAM policies are the means by which privileges are granted to users, groups, or roles. IAM Policies should follow the standard principle of least privilege - granting only the permissions required to perform a task. It is recommended to begin with a minimum set of permissions and grant additional permissions as necessary, instead of allowing full administrative privileges.",
        "severity": "Low",
        "logic": "IamPolicy where arn!='arn:aws:iam::aws:policy/AdministratorAccess' should not have document.Statement contain-any [ $ with [ Effect='Allow' and Action='*' ] ]",
        "remediation": "\n**From Portal:**\nPerform the following to detach the policy that has excessive administrative privileges:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, click Policies and then search for the policy name.\n3. Select the policy that needs to be deleted.\n4. In the policy action menu, select first Detach.\n5. Select all Users, Groups, Roles that have this policy attached.\n6. Click Detach Policy.\n7. In the policy action menu, select Detach.\n\n**From Command Line:**\n1. Lists all IAM users, groups, and roles that the specified managed policy is attached to, identify and note any excessive privileges.\n```\naws iam list-entities-for-policy --policy-arn policy_arn\n```\n2. Detach the policy from all IAM Users:\n```\naws iam detach-user-policy --user-name iam_user --policy-arn policy_arn\n```\n3. Detach the policy from all IAM Groups:\n```\naws iam detach-group-policy --group-name iam_group --policy-arn policy_arn\n```\n4. Detach the policy from all IAM Roles:\n```\naws iam detach-role-policy --role-name iam_role --policy-arn policy_arn\n```\n\nReferences:\n1. https://docs.amazonaws.cn/en_us/IAM/latest/UserGuide/best-practices.html#grant-least-privilege\n2. https://docs.amazonaws.cn/en_us/IAM/latest/UserGuide/access_policies.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-group-policy.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-role-policy.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-user-policy.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-entities-for-policy.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "wf92WiJ1hk+dgYcYSCcmxg",
        "ruleId": "D9.AWS.IAM.52",
        "category": ""
    },
    {
        "name": "Ensure AWS Kinesis Streams Keys are rotated",
        "description": "Rotate the keys of your Kinesis Streams in order to protect your data and metadata from breaches or unauthorized access, and fulfill compliance requirements for key management within your organization.",
        "severity": "Low",
        "logic": "Kinesis where encrypted should have encryptionKey.rotationStatus=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the AWS Key Management Service (AWS KMS) console.\n2. In the navigation pane, choose 'Customer managed keys'.\n3. Choose the 'alias or 'key ID' of a KMS key.\n4. Choose the 'Key rotation' tab.\n5. Select or clear the Automatically rotate this KMS key every year check box.\n6. Choose Save.\n\nNote: The Key rotation tab appears only on the detail page of symmetric encryption KMS keys with key material that AWS KMS generated (the Origin is AWS_KMS), including multi-Region symmetric encryption KMS keys. You cannot automatically rotate asymmetric KMS keys, HMAC KMS keys, KMS keys with imported key material, or KMS keys in custom key stores. However, you can rotate them manually. AWS managed keys are automatically rotated every 3 years.\n\n**From TF**\n```\nresource \"aws_kms_key\" \"key1\" {\n...\nis_enabled              = true\n+ enable_key_rotation    = true\n}\n```\n\n**From Command Line**\n```\naws kms enable-key-rotation --kms-key-id KMS_KEY_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html\n2. https://docs.aws.amazon.com/streams/latest/dev/what-is-sse.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kms_key ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "YocY05lUXA0RRP62S1O4Bg",
        "ruleId": "D9.AWS.CRY.20",
        "category": ""
    },
    {
        "name": "Ensure AWS NAT Gateways are being utilized instead of the default route",
        "description": "NAT Gateway is a scalable and resilient method for allowing outbound internet traffic from your private VPC subnets. It is recommended to use NAT gateways, and not the default route which permits all traffic, in Route Tables.",
        "severity": "Low",
        "logic": "RouteTable where routes contain [ state='active' ] should not have routes contain [ destinationCidrBlock='0.0.0.0/0' and natGatewayId isEmpty() ]",
        "remediation": "\n**From Portal:**\nTo create a NAT gateway:\n1. Sign into the AWS console\n2. In the console, select the specific region\n3. Navigate to VPC Dashboard\n4. In the navigation pane, select 'NAT Gateways'\n5. Click 'Create NAT Gateway', Specify the subnet in which to create the NAT gateway, and select the allocation ID of an Elastic IP address to associate with the NAT gateway. When you're done, click 'Create a NAT Gateway'. The NAT gateway displays in the console. After a few moments, its status changes to Available, after which it's ready for you to use.\n\nTo update Route Table:\nAfter you've created your NAT gateway, you must update your route tables for your private subnets to point internet traffic to the NAT gateway. We use the most specific route that matches the traffic to determine how to route the traffic.\n1. Sign into the AWS console\n2. In the console, select the region\n3. Navigate to VPC Dashboard\n4. In the navigation pane, select 'Route Tables'\n5. Select the reported route table associated with your private subnet\n6. Select 'Routes' and Click 'Edit routes'\n7. Replace the current route that points to the NAT instance with a route to the NAT gateway\n8. Click 'Save routes'.\n\n**From Command Line:**\nuse following command to delete destination Cidr Block 0.0.0.0/0 in the route table. Replace the current route that points to the NAT instance with a route to the NAT gateway.\n```\naws ec2 delete-route --region region_name --route-table-id rtb_ID --destination-cidr-block 0.0.0.0/0\n```\n\nReferences:\n1. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html\n2. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete-route.html ",
        "complianceTag": "Network Security",
        "logicHash": "b3KLQ0rtKIQ87+bpd5D5LA",
        "ruleId": "D9.AWS.NET.46",
        "category": ""
    },
    {
        "name": "Ensure AWS Security Hub is enabled",
        "description": "Security Hub collects security data from across AWS accounts, services, and supported third-party partner products and helps you analyze your security trends and identify the highest priority security issues. When you enable Security Hub, it begins to consume, aggregate, organize, and prioritize findings from AWS services that you have enabled, such as Amazon GuardDuty, Amazon Inspector, and Amazon Macie. You can also enable integrations with AWS partner security products.",
        "severity": "Low",
        "logic": "SecurityHub should have region length()>=1",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the AWS Security Hub console at https://console.aws.amazon.com/securityhub/.\n2. When you open the Security Hub console for the first time, choose Enable AWS Security Hub.\n3. On the welcome page, Security standards list the security standards that Security Hub supports.\n4. Choose Enable Security Hub.\n\nNOTE : It is recommended AWS Security Hub be enabled in all regions. AWS Security Hub requires AWS Config to be enabled.\n\n**From Command Line**\n1. To enable the default standards, include --enable-default-standards.\n```\naws securityhub enable-security-hub --enable-default-standards\n```\n2. To enable the security hub without the default standards, include --no-enable default-standards.\n```\naws securityhub enable-security-hub --no-enable-default-standards\n```\n\n**References**\n1. https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-getstarted.html\n2. https://docs.aws.amazon.com/securityhub/latest/userguide/securityhubenable.html#securityhub-enable-api\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/securityhub/enable-security-hub.htm",
        "complianceTag": "Vulnerability and Threat Management",
        "logicHash": "SkmRXB/mTGpqoYf2HzUXNQ",
        "ruleId": "D9.AWS.VLN.07",
        "category": ""
    },
    {
        "name": "Ensure Auto Scaling group being used with multiple Availability zones",
        "description": "You should define your ASG to user multiple Availability zones, In order to balance your instances across these zones.",
        "severity": "Low",
        "logic": "AutoScalingGroup should have vpcZoneIdentifier regexMatch /,/",
        "remediation": "\n**From Portal:**\n1. Open the Amazon EC2 console.\n2. From the sidebar, navigate to Auto Scaling and go to Auto Scaling Groups.\n3. Select the check box next to an existing group.\n4. On the Details tab, choose Network, Edit.\n5. In Subnets, choose the subnet corresponding to the Availability Zone.\n6. Choose Update.\n\n**From TF:**\n```\nresource \"aws_autoscaling_group\" \"example\" {\n- availability_zones = [\"us-east-1a\"]\n+ vpc_zone_identifier = [aws_subnet.example1.id, aws_subnet.example2.id]\n}\n```\n\n**From Command Line:**\nIn order to update the subnets of your ASG, use to following CLI command\n```\naws autoscaling update-auto-scaling-group --auto-scaling-group-name autoscaling_group_name --vpc-zone-identifier Subnets_IDs (comma-separated)\n```\nNote: Make sure that your ASG and ELB are sharing the same AZ. This will increase performance and will decrease the latency.\n\nReferences:\n1. https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html\n2. https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group\n4. https://docs.aws.amazon.com/cli/latest/reference/autoscaling/update-auto-scaling-group.html ",
        "complianceTag": "Network Security",
        "logicHash": "ETuqjbG7f3d0g2pGj0avXw",
        "ruleId": "D9.AWS.NET.61",
        "category": ""
    },
    {
        "name": "Ensure Auto Scaling group does not have suspended processes",
        "description": "You should not have any suspended processes in your Auto Scaling group. You would want to Suspend process if there is a problem in your ASG that you need to investigate. You should enable any suspended process as soon as the investigation ends.",
        "severity": "Low",
        "logic": "AutoScalingGroup should not have suspendedProcesses",
        "remediation": "\n**From Portal**\nUse following steps to resume a process.\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/, and choose Auto Scaling Groups from the navigation pane.\n2. Select the check box next to the Auto Scaling group. A split pane opens up in the bottom of the Auto Scaling groups page.\n3. On the Details tab, choose Advanced configurations, Edit.\n4. For Suspended processes, remove the suspended process.\n5. Choose Update.\n\n**From Command Line**\n1. In order to resume all processes, use following command.\n```\naws autoscaling resume-processes --auto-scaling-group-name ASG_Name\n```\n2. It is also possible to resume a specific process using the tag: --scaling-processes process_name, use following command.\n```\naws autoscaling resume-processes --auto-scaling-group-name my-asg --scaling-processes process_name\n```\n\n**References**\n1. https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/autoscaling/resume-processes.html ",
        "complianceTag": "Operational",
        "logicHash": "pi3gX96Wh4udgj5O8soRhg",
        "ruleId": "D9.AWS.OPE.20",
        "category": ""
    },
    {
        "name": "Ensure Auto Scaling group have scaling cooldown higher than a minute",
        "description": "Scaling cooldown prevents your ASG from executing scaling activity before other scaling activity ends. You should not set the cooldown to be less than one minute.",
        "severity": "Low",
        "logic": "AutoScalingGroup should have defaultCooldown>=60",
        "remediation": "\n**From Portal**\nYou can't set the default cooldown when you initially create an Auto Scaling group in the Amazon EC2 Auto Scaling console. By default, this cooldown period is set to 300 seconds (5 minutes). If needed, you can update this after the group is created.\nUse following steps to change the default cooldown period from AWS console\n1. After creating the Auto Scaling group, on the Details tab, choose Advanced configurations.\n2. Click Edit.\n3. For Default cooldown, choose the amount of time that you want based on your instance startup time or other application needs.\n\n**From TF**\n```\nresource \"aws_placement_group\" \"test\" {\n- default_cooldown = 300\n+ default_cooldown = 60\n}\n```\n\n**From Command Line**\nIn order to set scaling cooldown, use to following CLI command.\n```\naws autoscaling update-auto-scaling-group --auto-scaling-group-name ASG_Name --default-cooldown Number_Of_Seconds\n```\nNote: NumberOfSeconds should be >= 60\n\n**References**\n1. https://docs.aws.amazon.com/autoscaling/ec2/userguide/get-started-with-ec2-auto-scaling.html\n2. https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-scaling-cooldowns.html\n3. https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-launch-template.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group\n5. https://docs.aws.amazon.com/cli/latest/reference/autoscaling/update-auto-scaling-group.html ",
        "complianceTag": "Operational",
        "logicHash": "T757+Q0XQhErJjNMX0oCiQ",
        "ruleId": "D9.AWS.OPE.21",
        "category": ""
    },
    {
        "name": "Ensure CloudTrail is enabled in all regions",
        "description": "AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services (such as CloudFormation).",
        "severity": "Low",
        "logic": "Region should have hasCloudTrail=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console.\n2. Navigate to CloudTrail dashboard at https://console.aws.amazon.com/cloudtrail/.\n3. In the left navigation panel, select Trails.\n4. Under Name column, select the trail name that you need to update.\n5. Under the trail name, search for the Apply trail to all regions status and click the pencil icon next to the status current value.\n6. Select Yes to enable the feature and click Save.\n\n**From TF**\n```\nresource \"aws_cloudtrail\" \"example\" {\nname                          = \"management-events\"\ns3_bucket_name                = \"aws-cloudtrail-logs-853284604061-88d690f8\"\ninclude_global_service_events = false\nis_multi_region_trail = true\n}\n```\n\n**From Command Line**\n```\naws cloudtrail create-trail --name TRAIL_NAME --bucket-name S3_BUCKET_FOR_CLOUDTRAIL> --is-multi-region-trail\n```\n```\naws cloudtrail update-trail --name TRAIL_NAME --is-multi-region-trail\n```\n\n**References**\n1. CIS Amazon Web Services Foundations Benchmark v1.3.0: https://workbench.cisecurity.org/benchmarks/679\n2. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.html#cloudtrail-concepts-management-events\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudtrail/create-trail.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail#is_multi_region_trail ",
        "complianceTag": "Logging",
        "logicHash": "ul9oJ3aOMrWAPm4QSV5sLQ",
        "ruleId": "D9.AWS.LOG.07",
        "category": ""
    },
    {
        "name": "Ensure CloudTrail logs are encrypted at rest using KMS CMKs",
        "description": "AWS CloudTrail is a web service that records AWS API calls for an account and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data, and uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. It is recommended that CloudTrail be configured to use SSE-KMS.",
        "severity": "Low",
        "logic": "CloudTrail should have kmsKeyId",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and navigate to CloudTrail.\n2. In the left navigation, select Trails.\n3. Click on a Trail you want to update.\n4. Under General details, click Edit.\n5. Under log file SSE-KMS encryption, select Enabled.\n6. In Customer managed AWS KMS key, either use a new or existing key.\n7. Enter the AWS KMS alias and click Save changes.\n\n**From TF**\n```\nresource \"aws_cloudtrail\" \"test\" {\nname                          = \"example1\"\ns3_bucket_name                = \"example2\"\n+ kms_key_id                    = \"CMK_KEY_ID\"\n}\n```\nNote: kms_key_id field (includes the KMS key ARN) is used to encrypt the logs delivered by CloudTrail.\n\n**From Command Line**\n1. Use below put-key-policy command to provide the necessary permissions through updating the KMS key policy.\n```\naws kms put-key-policy --key-id KMS_KEY --policy CLOUDTRAIL_KMS_KEY_POLICY\n```\n2. Use below command to update the trail configuration with the KMS key ID.\n```\naws cloudtrail update-trail --name TRAIL_NAME --kms-id KMS_KEY\n```\n\n**References**\n1. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/encrypting-cloudtrail-log-files-with-aws-kms.html\n2. https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudtrail/update-trail.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kms/put-key-policy.html ",
        "complianceTag": "Logging",
        "logicHash": "8cYtD+S9PYgykF2D4ToCfw",
        "ruleId": "D9.AWS.LOG.06",
        "category": ""
    },
    {
        "name": "Ensure EKS Node Group IAM role do not have administrator privileges",
        "description": "Providing full administrative privileges instead of restricting to the minimum set of permissions that the user is required to do exposes the resources to potentially unwanted actions",
        "severity": "Low",
        "logic": "IamRole where combinedPolicies with [ policyDocument with [ Statement with [ Principal.Service ='eks.amazonaws.com' ] ] ] should not have document.Statement contain[ Effect='Allow' and Action='*' ]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Roles'\n3. For each incompliant Roles:\n4. Click on the incompliant Role name\n5. Under 'Permissions', select the policy that provides full access\n6. Click 'Remove'\n\n**From Command Line**\nTo remove the specified managed policy from a specified IAM Role, run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/cli/latest/reference/iam/detach-role-policy.html\n2. https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "VItPkYh09Y4y6BlhkwNewQ",
        "ruleId": "D9.AWS.IAM.97",
        "category": ""
    },
    {
        "name": "Ensure IAM Policy do not have Effect: 'Allow' with 'NotAction' Element",
        "description": "When using NotAction, you should keep in mind that actions specified in this element are the only actions in that are limited. This, in turn, means that all of the applicable actions or services that are not listed are allowed if you use the Allow effect.",
        "severity": "Low",
        "logic": "IamPolicy where attachmentCount >0 should not have document.Statement contain [ Effect='Allow' and NotAction ]",
        "remediation": "\nNote: AWS managed policies cannot be deleted.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Policies'\n3. For each incompliant policy, make sure there are no IAM entities attached to it:\n4. Choose the incompliant policy\n5. Under 'Policy usage', detach any IAM entity attached to it\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified role., run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#aws-managed-policies\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-delete.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-user-policy.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-group-policy.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/detach-role-policy.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "p2y3zNXEPDXCtXRaHKXx3g",
        "ruleId": "D9.AWS.IAM.90",
        "category": ""
    },
    {
        "name": "Ensure IAM User do not have administrator privileges",
        "description": "Providing full administrative privileges instead of restricting to the minimum set of permissions that the user is required to do exposes the resources to potentially unwanted actions",
        "severity": "Low",
        "logic": "IamUser should not have combinedPolicies with [ name like 'AdministratorAccess' ]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'User'\n3. Select the incompliant users\n4. Click on 'X' next to 'AdministratorAccess' group\n5. Click 'Remove from group'\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage_add-remove-users.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_access-management.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "7U2d0tYUzp8Ej3JGXvKG2g",
        "ruleId": "D9.AWS.IAM.89",
        "category": ""
    },
    {
        "name": "Ensure IAM group do not have administrator privileges",
        "description": "Providing full administrative privileges instead of restricting to the minimum set of permissions that the user is required to do exposes the resources to potentially unwanted actions",
        "severity": "Low",
        "logic": "IamGroup should not have managedPolicies with [ name like 'AdministratorAccess' ]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'User groups'\n3. For each incompliant group:\n4. Click on the incompliant group name\n5. Under 'Permissions', select the policy 'AdministratorAccess'\n6. Click 'Remove'\n\n**From Command Line**\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_access-management.html\n2. https://docs.aws.amazon.com/cli/latest/reference/iam/delete-group-policy.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "zWiSsRsPQad4NQBSJCWPzg",
        "ruleId": "D9.AWS.IAM.87",
        "category": ""
    },
    {
        "name": "Ensure IAM groups have at least one IAM User attached",
        "description": "It is recommended that all empty IAM groups will removed. Removing unnecessary IAM groups will reduce the window of opportunity of malicious actor to gain access to resources",
        "severity": "Low",
        "logic": "IamGroup should not have attachedUsers isEmpty()",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'User groups'\n3. Select all the empty groups\n4. Click 'Delete'\n\n**From Command Line**\nTo remove IAM group, run:\n```\naws iam delete-group --group-name GROUP_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_access-management.html\n2. https://docs.aws.amazon.com/cli/latest/reference/iam/delete-group-policy.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups_manage_delete.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "QvK3rRbPL7BK9NXKOJD7+Q",
        "ruleId": "D9.AWS.IAM.88",
        "category": ""
    },
    {
        "name": "Ensure IAM instance roles are used for AWS resource access from instances",
        "description": "Applications running on EC2 instances frequently access additional AWS services and must be granted permissions to make API calls. The recommended approach for granting EC2-based applications AWS permissions is with an IAM role for EC2 because this eliminates the need to distribute and rotate long-term credentials on EC2 instances. When creating IAM roles, associate least-privilege IAM policies that restrict access to the specific API calls the application requires.",
        "severity": "Low",
        "logic": "Instance should not have profileArn isEmpty()",
        "remediation": "\n**From Portal**\nSteps 1 is to create new rule\n1. Navigate to the AWS console IAM dashboard.\n2. In the navigation pane, select Roles, Create new role.\n3. Under 'Select the service that will use this role' select EC2, then 'Next:Permissions.'\n4. On the Attach permissions policies page, select an AWS managed policy that grants your instance access to the resources that they need, then 'Next:Tags.'\n5. Add tags (optional), the select 'Next:Review.'\n6. On the Create role and Review page, type a name for the role and Select Create role.\n\nNote: Following steps are used to attach or replace IAM role for Ec2 instances:\n1. Navigate to the AWS console EC2 dashboard.\n2. Select Running Instances.\n3. Select the instance you want to modify.\n4. Click on security tab and ensure instance role is added there. Attach/Replace IAM Role in case needed.\n5. On the Attach/Replace IAM Role page, under the IAM role pull down menu, select the role created in the IAM steps above.\n\n**References**\n1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "S0TfBf0MHqhnuZwrFsAZgQ",
        "ruleId": "D9.AWS.IAM.54",
        "category": ""
    },
    {
        "name": "Ensure IAM user, group, or role do not have access to create or update login profiles (passwords) for IAM users",
        "description": "To prevent privilege escalation, you should use service control policies (SCPs) to prevent users in your accounts, except for IAM administrators or delegated admins, from using administrative IAM actions.",
        "severity": "Low",
        "logic": "IamPolicy where attachmentCount >0 should not have document.Statement contain [ Effect='Allow' and (Action='iam:UpdateLoginProfile' or Action='iam:CreateLoginProfile') ]",
        "remediation": "\nNote: AWS managed policies cannot be deleted.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Policies'\n3. For each incompliant policy, make sure there are no IAM entities attached to it:\n4. Choose the incompliant policy\n5. Under 'Policy usage', detach any IAM entity attached to it\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified role., run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/wellarchitected/latest/financial-services-industry-lens/aws-identity-and-access-management-iam.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-attach-detach.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "4gNZ/HPrvjX7P1jLczMxDw",
        "ruleId": "D9.AWS.IAM.84",
        "category": ""
    },
    {
        "name": "Ensure IAM user, group, or role should have IAM access key permissions restricted",
        "description": "IAM users,groups and roles must explicitly be given permissions to administer credentials or IAM resources. You can do this by attaching an identity-based policy to the resources.",
        "severity": "Low",
        "logic": "IamPolicy where attachmentCount >0 should not have document.Statement contain [ Effect='Allow' and (Action='iam:DeleteAccessKey' or Action='iam:GetAccessKeyLastUsed' or Action='iam:UpdateAccessKey' or Action='iam:CreateAccessKey' or Action='iam:ListAccessKeys') ]",
        "remediation": "\nNote: AWS managed policies cannot be deleted.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Policies'\n3. For each incompliant policy, make sure there are no IAM entities attached to it:\n4. Choose the incompliant policy\n5. Under 'Policy usage', detach any IAM entity attached to it\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified role., run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/service-authorization/latest/reference/list_identityandaccessmanagement.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-attach-detach.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_permissions-required.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "2WzSaqGN2Sk/ae95nBV0cA",
        "ruleId": "D9.AWS.IAM.85",
        "category": ""
    },
    {
        "name": "Ensure IAM user, group, or role should have MFA permissions restricted",
        "description": "IAM users,groups and roles must explicitly be given permissions to deactivate and reset multi-factor authentication (MFA) for other IAM resources. You can do this by attaching an identity-based policy to the resources.",
        "severity": "Low",
        "logic": "IamPolicy where attachmentCount >0 should not have document.Statement contain [ Effect='Allow' and (Action='iam:DeactivateMFADevice' or Action='iam:EnableMFADevice' or Action='iam:ResyncMFADevicem' or Action='iam:DeleteVirtualMFADevice' or Action='iam:CreateVirtualMFADevice' or Action='iam:ListMFADevices' or Action='iam:ListVirtualMFADevices') ]",
        "remediation": "\nNote: AWS managed policies cannot be deleted.\n\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Policies'\n3. For each incompliant policy, make sure there are no IAM entities attached to it:\n4. Choose the incompliant policy\n5. Under 'Policy usage', detach any IAM entity attached to it\n\n**From Command Line**\nTo remove the specified managed policy from a specified user, run:\n```\naws iam detach-user-policy --user-name USER-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified IAM group, run:\n```\naws iam detach-group-policy --group-name GROUP-NAME --policy-arn POLICY-ARN\n```\nTo remove the specified managed policy from a specified role., run:\n```\naws iam detach-role-policy --role-name ROLE-NAME --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/service-authorization/latest/reference/list_identityandaccessmanagement.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-attach-detach.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "jC0O3rngSq4yUY3cMSUEKQ",
        "ruleId": "D9.AWS.IAM.86",
        "category": ""
    },
    {
        "name": "Ensure IAM users have either access key or console password enabled",
        "description": "Ensuring IAM users are using either access key or console password reduces the security risk of mismanaged access controls.",
        "severity": "Low",
        "logic": "IamUser should have passwordEnabled=false or (firstAccessKey.isActive=false and secondAccessKey.isActive=false)",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Users' and choose the relevant user\n3. Choose the 'Security credentials' tab\n4. If access keys are used, make sure 'Console password' is disabled under 'Sign-in credentials'\n5. If 'Console password' is used, make sure to disable any access keys under 'Access keys'\n\n**From TF**\nTo disable an IAM user access key, set 'status' to 'Inactive':\n```\nresource \"aws_iam_access_key\" \"example_access_key\" {\n..\nuser   = \"USER-NAME\"\nstatus = \"Inactive\"\n..\n}\n```\nTo delete an IAM user login profile (password), delete the following resource:\n```\nresource \"aws_iam_user_login_profile\" \"example_user_login_profile\" {\n..\n}\n```\n\n**From Command Line**\nTo list IAM access keys for a given user, run:\n```\naws iam list-access-keys --user-name USER-NAME\n```\nTo disable IAM user access key, run:\n```\naws iam update-access-key --user-name USER-NAME --access-key-id ACCESS_KEY_ID --status Inactive\n```\nTo determine whether an IAM user has a password, run:\n```\naws iam get-login-profile --user-name USER-NAME\n```\nTo delete an IAM user login profile (password), run:\n```\naws iam delete-login-profile --user-name USER-NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_admin-change-user.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-access-keys.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/update-access-key.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-login-profile.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-login-profile.html\n7. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_access_key#status\n8. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user_login_profile\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "K3RBVqyFsrRUpM0xAqYfmw",
        "ruleId": "D9.AWS.IAM.65",
        "category": ""
    },
    {
        "name": "Ensure Inspector Instances have continuous scanning active",
        "description": "AWS Inspector is a security assessment service, used to assess applications for vulnerabilities or deviations from best practices. It is recommended to run AWS Inspector scans regularly",
        "severity": "Low",
        "logic": "Inspector2Ec2Coverage should not have scanStatus.statusCode.value='INACTIVE'",
        "remediation": "\n**From Portal**\nIn order for Amazon Inspector to detect software vulnerabilities for an Amazon EC2 instance, the instance must be a managed instance in Amazon EC2 Systems Manager (SSM). An SSM managed instance has the SSM Agent installed and running, and has an attached AWS Identity and Access Management (IAM) instance profile that allows SSM to manage the instance. If you are already using SSM to manage your instances, no additional steps are needed for Amazon Inspector to begin scans.\nUse following steps to configure an Amazon EC2 instance for Amazon Inspector scanning.\n\n1. Configure SSM for an Amazon EC2 instance. If it is not already installed by your operating system vendor, install the SSM Agent. Follow reference section for more details.\n2. Use the AWS CLI to verify that the SSM Agent is running. Follow reference section for more information.\n3. Grant permission for SSM to manage your instance. You grant permission by creating an IAM instance profile and attaching it to your instance. If you do not already have an IAM instance profile role for SSM, create an IAM instance profile for Systems Manager. After you create the instance profile, you must attach it to your instance. Follow reference section for more information.\n4. Verify the scan status code value as ACTIVE for each instance.\n\n**From Command Line**\nUse following commands to check whether AWS Systems Manager Agent (SSM Agent) is running on each supported operating system.\n\n1. For operating systems: Amazon Linux, CentOS 6.x, Red Hat Enterprise Linux (RHEL) 6.x, Ubuntu Server 14.04 (all) and 16.04 (32-bit) run following command\n```\nsudo status amazon-ssm-agent\n```\n2. For operating systems: Amazon Linux 2, CentOS 7.x and CentOS 8.x, Debian Server 8, 9, and 10, Oracle Linux, Red Hat Enterprise Linux (RHEL) 7.x and 8.x, SUSE Linux Enterprise Server (SLES), Ubuntu Server 16.04 64-bit instances (deb package installation)\n```\nsudo systemctl status amazon-ssm-agent\n```\n3. For operating systems: macOS\n```\nCheck the agent log file at\u00a0/var/log/amazon/ssm/amazon-ssm-agent.log\n```\n4. For operating systems: Ubuntu Server 16.04, 18.04, and 20.04 LTS & and 20.10 STR 64-bit (Snap package installation)\n```\nsudo systemctl status snap.amazon-ssm-agent.amazon-ssm-agent.service\n```\n5. For operating systems: Windows Server\n```\nRun in PowerShell: Get-Service AmazonSSMAgent\n```\n\n**References**\n1. https://docs.aws.amazon.com/inspector/latest/user/scanning-ec2.html\n2. https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html\n3. https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent-status-and-restart.html\n4. https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html\n5. https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-launch-managed-instance.html\n6. https://docs.aws.amazon.com/inspector/latest/user/assessing-coverage.html\n7. https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html\n8. https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent-status-and-restart.html ",
        "complianceTag": "Vulnerability and Threat Management",
        "logicHash": "Hd4P8HTJRoot1CFyyk5gyg",
        "ruleId": "D9.AWS.VLN.06",
        "category": ""
    },
    {
        "name": "Ensure MFA Delete is enabled on S3 buckets",
        "description": "Enabling MFA delete for versioning is a good way to add extra protection to sensitive files stored in buckets.",
        "severity": "Low",
        "logic": "S3Bucket should have versioning.mfaDelete=true",
        "remediation": "\nYou can not perform Enable MFA Delete through AWS Management Console, this is required to use the AWS CLI or API. You can perform MFA Delete on S3 buckets using 'root' account only. Use following steps to enable MFA delete on an S3 bucket.\n\n**From TF**\n```\nresource \"aws_s3_bucket\" \"test\" {\nbucket = \"my-tf-test-bucket\"\nacl    = \"private\"\n\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n\n+ versioning {\nenabled = true\n+ mfa_delete = true\n+ }\n}\n```\n**From Command Line**\nUsing the AWS s3api CLI, enable MFA Delete for the S3 buckets that fail this rule, for example:\n```\naws s3api put-bucket-versioning --bucket BUCKET_NAME --versioning-configuration Status=Enabled,MFADelete=Enabled --mfa 'arn:aws:iam::aws_account_id:mfa/root-account-mfa-device pass code'\n```\n\n**References**\n1. https://aws.amazon.com/blogs/security/securing-access-to-aws-using-mfa-part-3\n2. https://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiFactorAuthenticationDelete.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "Z9qvJ/Ts7vLlYh5NMj7DRg",
        "ruleId": "D9.AWS.IAM.43",
        "category": ""
    },
    {
        "name": "Ensure NAT gateway has a name tag",
        "description": "In order to control your VPC environment, all the components should have a meaningful name.",
        "severity": "Low",
        "logic": "NatGateway should have tags contain [key like '%Name%']",
        "remediation": "\n**From Portal**\nPerform the following to set a Name tag to your NAT Gateway:\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. In the navigation pane, choose NAT Gateways.\n3. Select the NAT gateway that you want to tag and choose Actions. Then choose Manage tags.\n4. Choose Add new tag, and define a Key and Value for the tag. You can add up to 50 tags.\n5. Choose Save.\n\n**From TF**\n```\nresource \"aws_ec2_tag\" \"example\" {\nresource_id = \"NAT_gateway_id\"\nkey         = \"Name\"\nvalue       = \"tag_value\"\n}\n```\n\n**From Command Line**\nUse following command to tag a NAT Gateway:\n```\naws ec2 create-tags --resources NAT_gateway_ID --tags tag_name\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-tags.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_tag ",
        "complianceTag": "Operational",
        "logicHash": "4/sIJu0bn1fgEJTILHJ+Yg",
        "ruleId": "D9.AWS.OPE.13",
        "category": ""
    },
    {
        "name": "Ensure Network firewall alerts logging is enabled",
        "description": "Network firewall ALERT logs provide detailed information about any alert that was triggered because of network traffic that went through the stateful engine of your firewall. In order to investigate security incidents, you must enable alert logs of the network firewall.",
        "severity": "Low",
        "logic": "NetworkFirewall should have loggingConfiguration.logDestinationConfigs contain [logType='ALERT']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon VPC console.\n2. In the navigation pane, under Network Firewall, choose Firewalls.\n3. In the Firewalls page, choose the name of the firewall that you want to edit.\n4. Choose the tab Firewall details, then in the Logging section, choose Edit.\n5. Adjust the Log type selections as needed. You can configure logging for alert and flow logs.\nAlert: Sends logs for traffic that matches any stateful rule whose action is set to Alert or Drop. For more information about stateful rules and rule groups, see Rule groups in AWS Network Firewall.\nFlow: Sends logs for all network traffic that the stateless engine forwards to the stateful rules engine.\n6. For each selected log type, choose the destination type, then provide the information for the logging destination that you prepared following the guidance in Firewall logging destinations. In order to change the destination for an existing Log type, you must first turn off logging for the policy. Then, edit the policy and specify the new destination(s) for the Log type.\n8. Choose Save to save your changes and return to the firewall's detail page.\n\n**From TF**\n```\nresource \"aws_networkfirewall_logging_configuration\" \"example\" {\nlogging_configuration {\nlog_destination_config {\n-        log_type = \"FLOW\"\n+        log_type = \"ALERT\"\n}\n}\n}\n```\n\n**From Command Line**\nIn order to set Networks firewall alerts logging, use to following CLI command:\n```\naws network-firewall update-logging-configuration --firewall-arn FW_ARN --logging-configuration LogDestinationConfigs=[{LogType=ALERT,LogDestinationType=S3 or CloudWatchLogs or KinesisDataFirehose,LogDestination={key1=value1,key2=value2}}]\n```\nExample for sending logs to S3:\n```\naws network-firewall update-logging-configuration --firewall-arn FW_ARN --logging-configuration LogDestinationConfigs=[{LogType=ALERT,LogDestinationType=S3,LogDestination={bucketName=Bucket name,prefix=Optional. prefix path in the bucket}}]\n```\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/developerguide/firewall-logging.html\n2. https://docs.aws.amazon.com/network-firewall/latest/developerguide/firewall-update-logging-configuration.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/networkfirewall_logging_configuration\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/update-logging-configuration.html ",
        "complianceTag": "Logging",
        "logicHash": "S4tBSRuRT8BXhfeLcamDRw",
        "ruleId": "D9.AWS.LOG.21",
        "category": ""
    },
    {
        "name": "Ensure Network firewall flow logging is enabled",
        "description": "Network firewall FLOW logs provide detailed information about network traffic that went through the stateful engine of your firewall. In order to investigate security incidents, you must enable flow logs of the network firewall.",
        "severity": "Low",
        "logic": "NetworkFirewall should have loggingConfiguration.logDestinationConfigs contain [logType='FLOW']",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon VPC console.\n2. In the navigation pane, under Network Firewall, choose Firewalls.\n3. In the Firewalls page, choose the name of the firewall that you want to edit.\n4. Choose the tab Firewall details, then in the Logging section, choose Edit.\n5. Adjust the Log type selections as needed. You can configure logging for alert and flow logs.\nAlert: Sends logs for traffic that matches any stateful rule whose action is set to Alert or Drop. For more information about stateful rules and rule groups, see Rule groups in AWS Network Firewall.\nFlow: Sends logs for all network traffic that the stateless engine forwards to the stateful rules engine.\n6. For each selected log type, choose the destination type, then provide the information for the logging destination that you prepared following the guidance in Firewall logging destinations. In order to change the destination for an existing Log type, you must first turn off logging for the policy. Then, edit the policy and specify the new destination(s) for the Log type.\n8. Choose Save to save your changes and return to the firewall's detail page.\n\n**From TF**\n```\nresource \"aws_networkfirewall_logging_configuration\" \"example\" {\nlogging_configuration {\nlog_destination_config {\n-        log_type = \"ALERT\"\n+        log_type = \"FLOW\"\n}\n}\n}\n```\n\n**From Command Line**\nIn order to set Networks firewall flow logging, use to following CLI command:\n```\naws network-firewall update-logging-configuration --firewall-arn FW_ARN --logging-configuration LogDestinationConfigs=[{LogType=FLOW,LogDestinationType=S3 or CloudWatchLogs or KinesisDataFirehose,LogDestination={key1=value1,key2=value2}}]\n```\nExample for sending logs to S3:\n```\naws network-firewall update-logging-configuration --firewall-arn FW_ARN --logging-configuration LogDestinationConfigs=[{LogType=FLOW,LogDestinationType=S3,LogDestination={bucketName=Bucket name,prefix=Optional. prefix path in the bucket}}]\n```\n\n**References**\n1. https://docs.aws.amazon.com/network-firewall/latest/developerguide/firewall-logging.html\n2. https://docs.aws.amazon.com/network-firewall/latest/developerguide/firewall-update-logging-configuration.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/networkfirewall_logging_configuration\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/network-firewall/update-logging-configuration.html ",
        "complianceTag": "Logging",
        "logicHash": "vCZjL3cbuJm48xieYMaStQ",
        "ruleId": "D9.AWS.LOG.20",
        "category": ""
    },
    {
        "name": "Ensure OpenSearch should have IAM permissions restricted",
        "description": "It is recommended to not allow unrestricted access to OpenSearch, Access to information and application system functions shall be restricted in accordance with the access control policy.",
        "severity": "Low",
        "logic": "ElasticSearchDomain should not have accessPolicies.Statement contain [ Effect='Allow' and ( Principal.AWS='*' ) ]",
        "remediation": "\n**From Portal**\n1. Go to OpenSearch console : https://docs.aws.amazon.com/opensearch-service\n2. Click on 'Domains'\n3. Select the incompliant domain name\n4. Navigate to Security configuration and click on Edit\n5. Under 'Access policy' edit the JSON file with the permitted principles only.\n6. Click 'Save changes'\n\n\n**From Command Line**\nTo change the specified access policy from a specified domain, run:\n```\naws es update-elasticsearch-domain-config --domain-name DOMAIN_NAME --access-policies file://POLICY.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/opensearch-service/latest/developerguide/what-is.html\n2. https://docs.aws.amazon.com/opensearch-service/latest/developerguide/fgac.html\n3. https://docs.aws.amazon.com/cli/latest/reference/opensearch/update-domain-config.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "q8mwS8wJ1DL9TOrhrYaEuQ",
        "ruleId": "D9.AWS.IAM.91",
        "category": ""
    },
    {
        "name": "Ensure SNS topic have active subscriptions",
        "description": "All SNS topics should have active subscriptions. You should delete unused SNS topics.",
        "severity": "Low",
        "logic": "SnsTopic should not have subscriptions isEmpty()",
        "remediation": "\n**From Portal**\nPerform the following to verify and create a new subscription:\n1. Login to AWS Console\n2. Navigate to SNS Service.\n3. Select the desired topic you want to examine.\n4. Go to Subscription section and ensure subscription is added to this topic.\n5. If there is no active subscription created, Create a new one.\n6. Choose create subscription tab to create a new subscription.\n7. If you want to delete the topic, select the relevant topic and click delete.\n\n**From TF**\nUse below Terraform code to create a subscription.\n```\nresource \"aws_sns_topic_subscription\" \"user_updates_sqs_target\" {\ntopic_arn = \"sns_topic_arn\"\nprotocol  = \"protocol_type\"\nendpoint  = \"Endpoint_to_send_data\"\n}\n```\n\n**From Command Line**\nUse following command to create a new subscription:\n```\naws sns subscribe --topic-arn Topic_ARN --protocol PROTOCOL_NAME --notification-endpoint my-email@example.com\n```\nNote: You can follow reference section to see a full list of protocol.\n\nUse following command to delete a topic:\n```\naws sns delete-topic --topic-arn Topic_ARN\n```\n**References**\n1. https://docs.aws.amazon.com/sns/latest/dg/sns-create-subscribe-endpoint-to-topic.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/subscribe.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/delete-topic.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sns_topic_subscription ",
        "complianceTag": "Monitoring",
        "logicHash": "wQOBKh+RdZot6qRn5pyBkQ",
        "ruleId": "D9.AWS.MON.19",
        "category": ""
    },
    {
        "name": "Ensure SQS Dead-letter queue is not configured to send messages to the source queue",
        "description": "A queues dead-letter queue should not be itself. If the dead-letter queue of a queue is itself, it wouldn't be possible to distinguish between messages that were send to the source queue and the dead letter queue",
        "severity": "Low",
        "logic": "Sqs should not have redrivePolicy.deadLetterTargetArn=id",
        "remediation": "\n**From Portal**\nPerform the following to set a dead-letter queue for existing queue:\n1. Login to AWS Console\n2. Navigate to SQS Service\n3. Create new queue. This queue will be used as the dead-letter queue of the existing queue.\n4. Select the relevant existing queue and click Edit\n5. Look for \"Dead-letter queue - Optional\", in the drop down select the new queue ARN.\n\n**From Command Line**\n```\naws sqs set-queue-attributes --queue-url Queue_url --attributes file://update_attributes.json\n```\nsee below example Input file update_attributes.json, where the file should contain RedrivePolicy with deadLetterTargetArn different then the source queue.\n\n{\n\"DelaySeconds\": \"value\",\n\"MaximumMessageSize\": \"value\",\n\"MessageRetentionPeriod\": \"value\",\n\"ReceiveMessageWaitTimeSeconds\": \"value\",\n\"RedrivePolicy\": \"{\"deadLetterTargetArn\":\"arn:aws:sqs:us-east-1:80398EXAMPLE:MyDeadLetterQueue\",\"maxReceiveCount\":\"value\"}\",\n\"VisibilityTimeout\": \"value\"\n}\n\n**References**\n1. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-dead-letter-queue.html\n2. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/set-queue-attributes.html ",
        "complianceTag": "Operational",
        "logicHash": "twTJ1jXyz5E7H7ec+TH7Lw",
        "ruleId": "D9.AWS.OPE.19",
        "category": ""
    },
    {
        "name": "Ensure Transit gateway have a name tag",
        "description": "In order to control your VPC environment, all the components should have a meaningful name",
        "severity": "Low",
        "logic": "TransitGateway should have tags contain [key like '%Name%']",
        "remediation": "\n**From Portal**\nPerform the following to set a Name tag to your Transit Gateways:\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. On the navigation pane, choose Transit Gateways.\n3. Choose the transit gateway for which to add or edit tags.\n4. Choose the Tags tab in the lower part of the page.\n5. Choose Manage tags.\n6. Choose Add new tag.\n7. Enter a Key and Value for the tag.\n8. Choose Save.\n\n**From TF**\n```\nresource \"aws_ec2_tag\" \"example\" {\nresource_id = \"Transit_gateway_id\"\nkey         = \"Name\"\nvalue       = \"tag_value\"\n}\n```\n\n**From Command Line**\n```\naws ec2 create-tags --resources transit_gateway_ID --tags tag_name\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/tgw/what-is-transit-gateway.html\n2. https://docs.aws.amazon.com/vpc/latest/tgw/tgw-transit-gateways.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-tags.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_tag ",
        "complianceTag": "Operational",
        "logicHash": "s1bfT4mex1FVdykgsBdtxQ",
        "ruleId": "D9.AWS.OPE.14",
        "category": ""
    },
    {
        "name": "Ensure VPC Endpoint has a name tag",
        "description": "In order to control your VPC environment, all the components should have a meaningful name",
        "severity": "Low",
        "logic": "VpcEndpoint should have tags contain [key like '%Name%']",
        "remediation": "\n**From Portal**\nPerform the following to set a Name tag to your VPC Endpoint:\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\n2. On the navigation pane, choose VPC Endpoints.\n3. Choose the VPC Endpoint for which to add or edit tags.\n4. Choose the Tags tab in the lower part of the page.\n5. Choose Manage tags.\n6. Choose Add new tag.\n7. Enter a Key and Value for the tag.\n8. Choose Save.\n\n**From TF**\n```\nresource \"aws_ec2_tag\" \"example\" {\nresource_id = \"VPC_Endpoint_id\"\nkey         = \"Name\"\nvalue       = \"tag_value\"\n}\n```\n\n**From Command Line**\n```\naws ec2 create-tags --resources Endpoint_ID --tags tag_name\n```\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\n2. https://docs.aws.amazon.com/vpc/latest/privatelink/create-endpoint-service.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-tags.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_tag ",
        "complianceTag": "Operational",
        "logicHash": "1pGe2TCS54wzMU5mv4zD2A",
        "ruleId": "D9.AWS.OPE.16",
        "category": ""
    },
    {
        "name": "Ensure a log metric filter and alarm exists for AWS MFA Deletion for IAM users",
        "description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for MFA deactivated for IAM users.",
        "severity": "Low",
        "logic": "List<CloudTrail> should have items with [hasSNSSubscriber='true' and metricFilters with [filterPattern isFilterPatternEqual('{($.eventName=DeactivateMFADevice)}')]] length() > 0]",
        "remediation": "\n**From Portal**\nA. To create a metric filter using the CloudWatch console\n1. Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.\n2. In the navigation pane, choose Log groups.\n3. Choose the name of the log group.\n4. Choose Actions, Create metric filter.\n5. For Filter pattern, enter the filter pattern to use:\n{($.eventName=DeactivateMFADevice)}\n6. Choose Next, and then enter a name for the filter.\n7. Under Metric details, for Metric namespace, enter a name for the CloudWatch namespace where the metric will be published. If this namespace doesn't already exist, be sure that Create new is selected.\n8. For Metric name, enter a name for the new metric.\n9. For Metric value, if your metric filter is counting occurrences of the keywords in the filter, enter 1.\n10. Choose Create metric filter.\n\nB. Create an SNS topic that the alarm will notify here: https://ap-south-1.console.aws.amazon.com/sns\n\nC. Create an SNS subscription to the topic created in step B here: https://ap-south-1.console.aws.amazon.com/sns\n\nD. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step A and an SNS topic created in step B here: https://ap-south-1.console.aws.amazon.com/cloudwatch\n\n**From TF**\nTo create log metric filter for AWS MFA Deletion for IAM users:\n```\nresource \"aws_cloudwatch_log_metric_filter\" \"yada\" {\nname           = NAME\npattern        = RELEVANT-FILTER-PATTERN\nlog_group_name = LOG-GROUP-NAME\n...\n}\n```\n\n**From Command Line**\nPerform the following to setup the metric filter, alarm, SNS topic, and subscription:\n1. Create a metric filter based on filter pattern provided which checks for AWS MFA Deletion for IAM users and the LOG-GROUP-NAME\n```\naws logs put-metric-filter --log-group-name LOG-GROUP-NAME --filter-name FILTER-NAME --metric-transformations metricName=METRIC-NAME,metricNamespace=METRIC-NAMESPACE,metricValue=1 --filter-pattern '{($.eventName=DeactivateMFADevice)}'\n```\n2. Create an SNS topic that the alarm will notify:\n```\naws sns create-topic --name SNS-TOPIC-NAME\n```\n3. Create an SNS subscription to the topic created in step 2:\n```\naws sns subscribe --topic-arn SNS-TOPIC-ARN --protocol PROTOCOL --notification-endpoint SNS-ENDPOINT\n```\n4. Create an alarm that is associated with the CloudWatch Logs Metric Filter created in step 1 and an SNS topic created in step 2:\n```\naws cloudwatch put-metric-alarm --alarm-name ALARM-NAME --metric-name METRIC-NAME --statistic Sum --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --namespace METRIC-NAMESPACE --alarm-actions SNS-TOPIC-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateMetricFilterProcedure.html\n2. https://docs.aws.amazon.com/sns/latest/dg/sns-create-topic.html\n3. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ConsoleAlarms.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_log_metric_filter\n5. https://docs.aws.amazon.com/cli/latest/reference/logs/put-metric-filter.html",
        "complianceTag": "Monitoring",
        "logicHash": "hsL2IhySDmGU0H4kz78wig",
        "ruleId": "D9.AWS.MON.25",
        "category": ""
    },
    {
        "name": "Ensure all IAM policies are in use",
        "description": "It is recommended to keep just IAM policies that in used. Reducing access management complexity may in-turn reduce opportunity for a principal to inadvertently receive or retain excessive privileges.",
        "severity": "Low",
        "logic": "IamPolicy where not arn regexMatch /aws:policy/ should have attachmentCount>0",
        "remediation": "\n**From Portal**\nTo remove unused IAM policy:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the left navigation pane, click on Policies\n4. For each policy:\n5. Select the policy where : Type = 'Customer managed' and Attached entities ='0'\n6. Click on Action\n7. click on delete\n\n\n**From Command Line**\nTo remove the specified managed policy, run:\n```\naws iam delete-policy --policy-arn POLICY-ARN\n```\n\n**References**\n1. https://aws.amazon.com/blogs/security/remove-unnecessary-permissions-in-your-iam-policies-by-using-service-last-accessed-data/\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-delete.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "RCoNj6y1HpMrSOy1W1LafA",
        "ruleId": "D9.AWS.IAM.82",
        "category": ""
    },
    {
        "name": "Ensure appropriate subscribers to each SNS topic",
        "description": "AWS Simple Notification Service (SNS) is a web service that can publish messages from an application and immediately deliver them to subscribers or other applications. Subscribers are clients interested in receiving notifications from topics of interest; they can subscribe to a topic or be subscribed by the topic owner. When publishers have information or updates to notify their subscribers about, they can publish a message to the topic which immediately triggers Amazon SNS to deliver the message to all applicable subscribers. It is recommended that the list of subscribers to given topics be periodically reviewed for appropriateness",
        "severity": "Low",
        "logic": "CloudTrail where name regexMatch /(.*)/ should have hasSNSSubscriber=true",
        "remediation": "\n**From Portal**\nPerform the following steps to verify if there is any inappropriate SNS subscribers available within your AWS account:\n1. Sign in to the AWS Management Console.\n2. Navigate to SNS dashboard at https://console.aws.amazon.com/sns/v2/.\n3. In the left navigation panel, under SNS Dashboard, select Subscriptions.\n4. Choose the SNS subscription that you want to examine.\n5. Evaluate the topic Amazon Resource Name (ARN), available in the Topic ARN column and the endpoint assigned to the subscription, available within Endpoint column, to determine if the subscriber is appropriate and can access/receive the data published to the assigned topic.\n6. If the subscriber is evaluated as unwanted, the selected AWS SNS subscription is not appropriate and can be safely removed from your account.\n\nPerform the following steps to remove any inappropriate SNS subscribers:\n1. Navigate to SNS dashboard at https://console.aws.amazon.com/sns/v2/.\n2. In the navigation panel, under SNS Dashboard, click Subscriptions.\n3. Select the SNS topic subscription that you want to remove.\n4. Click the Delete button to remove the selected SNS subscription.\n\n**From Command Line**\nRun following command to remove the inappropriate AWS SNS subscription from your account.\n```\naws sns unsubscribe --region AWS_REGION --subscription-arn SUBSCRIPTION_ARN\n```\nNote: use the ARN of the inappropriate subscription that you want to delete.\n\n**References**\n1. https://docs.aws.amazon.com/sns/latest/dg/sns-delete-subscription-topic.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/unsubscribe.html ",
        "complianceTag": "Monitoring",
        "logicHash": "m2RkwMTB0HJXIw2/NIJ6+w",
        "ruleId": "D9.AWS.MON.15",
        "category": ""
    },
    {
        "name": "Ensure credentials unused for 45 days or greater are disabled (First access key)",
        "description": "AWS IAM users can access AWS resources using different types of credentials, such as passwords or access keys. It is recommended that all credentials that have been unused in 45 or greater days from their creation time be deactivated or removed. Disabling or removing unnecessary credentials will reduce the window of opportunity for credentials associated with a compromised or abandoned account to be used.",
        "severity": "Low",
        "logic": "IamUser where firstAccessKey.isActive=true and firstAccessKey.lastRotated before(-45, 'days') should not have firstAccessKey.lastUsedDate before(-45, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Click on Security Credentials\n6. Select the relevant access key and click on 'Make Inactive'\n\n**From Command Line**\nTo inactive an IAM User access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/update-access-key.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "ac/tF2LsJsKAVpEBrL4SaA",
        "ruleId": "D9.AWS.IAM.03",
        "category": ""
    },
    {
        "name": "Ensure credentials unused for 45 days or greater are disabled (Second access key)",
        "description": "AWS IAM users can access AWS resources using different types of credentials, such as passwords or access keys. It is recommended that all credentials that have been unused in 45 or greater days be deactivated or removed. Disabling or removing unnecessary credentials will reduce the window of opportunity for credentials associated with a compromised or abandoned account to be used.",
        "severity": "Low",
        "logic": "IamUser where secondAccessKey.isActive=true and secondAccessKey.lastRotated before(-45, 'days') should not have secondAccessKey.lastUsedDate before(-45, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Click on Security Credentials\n6. Select the relevant access key and click on 'Make Inactive'\n\n**From Command Line**\nTo inactive an IAM User access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/update-access-key.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "PViFF/D4cKMZ+0eJ+SClEw",
        "ruleId": "D9.AWS.IAM.05",
        "category": ""
    },
    {
        "name": "Ensure cross-account IAM Role uses MFA or external ID as a condition",
        "description": "Ensuring your cross-account IAM Roles use Multi-Factor Authentication (MFA) or external ID is recommended as a security best practice.",
        "severity": "Low",
        "logic": "IamRole where assumeRolePolicy.Statement contain [ Effect = 'Allow' and Action = 'sts:AssumeRole' and Principal regexMatch /arn:aws:iam/ and not ~getValue('accountNumber') in (Principal.AWS split(':')) ] should have assumeRolePolicy.Statement contain [ Effect = 'Allow' and Action = 'sts:AssumeRole' and ( Condition.Bool.aws:MultiFactorAuthPresent= true or Condition.StringEquals.sts:ExternalId ) ]",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Roles'\n3. For each incompliant IAM Role:\n4. Go to 'Trust relationships' and click 'Edit trust policy'\n5. Edit the trust policy\n6. Click 'Update policy'\n\n**From TF**\nTo update the trust policy, edit the 'assume_role_policy' argument:\n```\nresource \"aws_iam_role\" \"example_iam_role\" {\n..\nassume_role_policy = POLICY-DOCUMENT\n..\n}\n```\n\n**From Command Line**\nTo update the trust policy, run:\n```\nupdate-assume-role-policy --role-name ROLE-NAME --policy-document POLICY-DOCUMENT\n```\n\n**References**\n1. https://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_configure-api-require.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/update-assume-role-policy.html\n5. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role#assume_role_policy\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "I8DGdfuQKt+qjdw7F4m6cQ",
        "ruleId": "D9.AWS.IAM.99",
        "category": ""
    },
    {
        "name": "Ensure first access key is rotated every 30 days or less",
        "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.\nRotating access keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used. Access keys should be rotated to ensure that data cannot be accessed with an old key which might have been lost, cracked, or stolen.",
        "severity": "Low",
        "logic": "IamUser where firstAccessKey.isActive='true' should not have firstAccessKey.lastRotated before(-30, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Click 'Make inactive'\n8. Click 'Create access key' and save the new credentials.\n9. Make sure the Accesskey updated by trying to access your applications with the new accesskey.\n10. After you verified the new Accesskey is updated, go to the inactive Accesskey and click on Delete.\n\n**From Command Line**\n1. To create new access key, run:\n```\naws iam create-access-key --user-name USER_NAME\n```\n2. To inactive the old access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n3. To delete the old access key, run:\n```\naws iam delete-access-key\t--access-key ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_CLIAPI'\n3. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "dY3n+HzbIfaorrUWnCAosA",
        "ruleId": "D9.AWS.IAM.76",
        "category": ""
    },
    {
        "name": "Ensure first access key is rotated every 45 days or less",
        "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.\nRotating access keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used. Access keys should be rotated to ensure that data cannot be accessed with an old key which might have been lost, cracked, or stolen.",
        "severity": "Low",
        "logic": "IamUser where firstAccessKey.isActive='true' should not have firstAccessKey.lastRotated before(-45, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Click 'Make inactive'\n8. Click 'Create access key' and save the new credentials.\n9. Make sure the Accesskey updated by trying to access your applications with the new accesskey.\n10. After you verified the new Accesskey is updated, go to the inactive Accesskey and click on Delete.\n\n**From Command Line**\n1. To create new access key, run:\n```\naws iam create-access-key --user-name USER_NAME\n```\n2. To inactive the old access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n3. To delete the old access key, run:\n```\naws iam delete-access-key\t--access-key ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_CLIAPI'\n3. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "9xmCAURvO1ch8p4s0xaMvA",
        "ruleId": "D9.AWS.IAM.78",
        "category": ""
    },
    {
        "name": "Ensure inactive IAM access keys are deleted",
        "description": "Deleting inactive IAM access keys reduces the security risk of mismanaged access keys.",
        "severity": "Low",
        "logic": "IamUser should not have (firstAccessKey.isActive=false and firstAccessKey.lastRotated > 0) or (secondAccessKey.isActive=false and secondAccessKey.lastRotated > 0)",
        "remediation": "\n**From Portal**\n1. Go to 'IAM'\n2. In the menu, under 'Access management', choose 'Users' and choose the relevant user\n3. Choose the 'Security credentials' tab\n4. Under 'Access keys' find the access key with 'Inactive' status\n5. Delete the IAM access key\n\n**From TF**\nTo delete an IAM user access key, delete the following resource:\n```\nresource \"aws_iam_access_key\" \"example_access_key\" {\n..\nuser   = \"USER-NAME\"\n..\n}\n```\n\n**From Command Line**\nTo list IAM access keys for a given user, run:\n```\naws iam list-access-keys --user-name USER-NAME\n```\nTo delete an inactive IAM access key, run:\n```\naws iam delete-access-key --user-name USER-NAME --access-key-id ACCESS-KEY-ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-access-key.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-access-keys.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "0u3oUi4FqpBuby2JdwUEqQ",
        "ruleId": "D9.AWS.IAM.64",
        "category": ""
    },
    {
        "name": "Ensure inactive user for 30 days or greater are disabled",
        "description": "It is recommended that all AWS IAM users that have been inactive for 30 or greater days be Disabled or removed.\nDisabling or removing unnecessary IAM users will reduce the window of opportunity of malicious actor to gain access to resources",
        "severity": "Low",
        "logic": "IamUser where firstAccessKey.isActive=true or secondAccessKey.isActive=true or passwordEnabled=true should have firstAccessKey.lastUsedDate after('-30', 'days') or secondAccessKey.lastUsedDate after('-30', 'days') or passwordLastUsed after('-30', 'days')",
        "remediation": "\n**From Portal**\nPerform the following to deactivate Access Keys:\n1. Login to the AWS Management Console.\n2. Click Services.\n3. Click IAM.\n4. Click on Users.\n5. Click on Security Credentials.\n6. Select any access keys that are over 30 days old and that have been used and click on Make Inactive.\n7. Select any access keys that are over 30 days old and that have not been used and click the X to Delete.\n\nPerform the following to manage Unused Password (IAM user console access):\n1. Login to the AWS Management Console.\n2. Click Services.\n3. Click IAM.\n4. Click on Users.\n5. Click on Security Credentials.\n6. In section Sign-in credentials, Console password click Manage.\n7. Under Console Access select Disable.\n8. Click Apply.\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#remove-credentials\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_finding-unused.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_admin-change-user.html\n4. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n5. https://workbench.cisecurity.org/sections/615823/recommendations/1009530\n\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "u7sal1YVnS+u8M22w+Xcfw",
        "ruleId": "D9.AWS.IAM.80",
        "category": ""
    },
    {
        "name": "Ensure inactive user for 90 days or greater are disabled",
        "description": "It is recommended that all AWS IAM users that have been inactive for 90 or greater days be Disabled or removed.\nDisabling or removing unnecessary IAM users will reduce the window of opportunity of malicious actor to gain access to resources",
        "severity": "Low",
        "logic": "IamUser where firstAccessKey.isActive=true or secondAccessKey.isActive=true or passwordEnabled=true should have firstAccessKey.lastUsedDate after('-90', 'days') or secondAccessKey.lastUsedDate after('-90', 'days') or passwordLastUsed after('-90', 'days')",
        "remediation": "\n**From Portal**\nPerform the following to deactivate Access Keys:\n1. Login to the AWS Management Console.\n2. Click Services.\n3. Click IAM.\n4. Click on Users.\n5. Click on Security Credentials.\n6. Select any access keys that are over 90 days old and that have been used and click on Make Inactive.\n7. Select any access keys that are over 90 days old and that have not been used and click the X to Delete.\n\nPerform the following to manage Unused Password (IAM user console access):\n1. Login to the AWS Management Console.\n2. Click Services.\n3. Click IAM.\n4. Click on Users.\n5. Click on Security Credentials.\n6. In section Sign-in credentials, Console password click Manage.\n7. Under Console Access select Disable.\n8. Click Apply.\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#remove-credentials\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_finding-unused.html\n3. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_admin-change-user.html\n4. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n5. https://workbench.cisecurity.org/sections/615823/recommendations/1009530\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "ZvKXcZmddZtd1CMG4+sGWA",
        "ruleId": "D9.AWS.IAM.73",
        "category": ""
    },
    {
        "name": "Ensure invalid or failed certificates are removed from ACM",
        "description": "Checks the ACM for Invalid or Failed certificates. An Invalid certificate is one that has not been validated within 72 hours. A certificate fails for these reasons:\n- the certificate is requested for invalid public domains.\n- the certificate is requested for domains which are not allowed or missing contact information\n- typographical errors.\nThese certificates cannot be used, and  you will have to request new ones. It is recommended to delete Failed or Invalid certificates.",
        "severity": "Low",
        "logic": "AcmCertificate should not have status='FAILED' or status='VALIDATION_TIMED_OUT'",
        "remediation": "\n**From Portal**\nFollowing are the steps to delete unused certificates:\n1. Open the ACM console at https://console.aws.amazon.com/acm/.\n2. In the list of certificates, select the check box for an ACM certificate, then choose Delete.\n\nAlternatively, you can associate/use the unused certificate to the resource which requires the certificate.\n\n**From Command Line**\nUse the delete-certificate command to delete a certificate, as shown in the following command:\n```\naws acm delete-certificate --certificate-arn ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-delete.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/delete-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "ZaO8Azme9ecARNiZtKjNIQ",
        "ruleId": "D9.AWS.CRY.29",
        "category": ""
    },
    {
        "name": "Ensure multi-regions trail exists for each AWS CloudTrail",
        "description": "AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services (such as CloudFormation).",
        "severity": "Low",
        "logic": "CloudTrail should have isMultiRegionTrail=true",
        "remediation": "\n**From Portal**\n1. Log in to the AWS Management Console\n2. Navigate to CloudTrail.\n3. In the left navigation, click Trails. Select Create trail, enter a Trail name.\n4. In Apply trail to all regions, select Yes.\n5. In Management events, select All for Read/write events.\n6. In Create a new S3 bucket, select Yes.\n7. In the S3 bucket, enter a name and click Create.\n\n**From TF**\n```\nresource \"aws_cloudtrail\" \"test\" {\nname                          = \"example\"\ns3_bucket_name                = \"BUCKET_NAME\"\n+ is_multi_region_trail         = true\n}\n```\n\n**From Command Line**\nTo create a trail that applies to all Regions, use the --is-multi-region-trail option. By default, the create-trail command creates a trail that logs events only in the AWS Region where the trail was created.\n```\naws cloudtrail create-trail --name TRAIL_NAME --s3-bucket-name S3_BUCKET_NAME --is-multi-region-trail\n```\n\n**References**\n1. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail-by-using-the-console.html\n2. https://registry.terraform.io/providers/hashicorp/aws/3.38.0/docs/resources/cloudtrail\n3. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail-by-using-the-aws-cli-create-trail.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudtrail/update-trail.html ",
        "complianceTag": "Logging",
        "logicHash": "8iom4RjaRKl1FPQrqvEXhw",
        "ruleId": "D9.AWS.LOG.01",
        "category": ""
    },
    {
        "name": "Ensure policy attached to IAM identities requires SSL/TLS to manage IAM access keys",
        "description": "Requiring AWS Secure Transport for policies with IAM access keys permissions will add a security layer for these API calls.",
        "severity": "Low",
        "logic": "IamPolicy where document.Statement contain [Effect='Allow' and Action regexMatch /AccessKey/ ] and not ( roles isEmpty() and users isEmpty() and groups isEmpty()) should have document.Statement with [Effect='Allow' and Action regexMatch /AccessKey/ ] contain-all [Condition.Bool.aws:SecureTransport = 'true']",
        "remediation": "\nNote: Please notice this rule doesn't cover inline policies. It is recommended to use managed policies instead.\n\n**From Portal**\n1. Go to 'IAM' and choose 'Policies' under 'Access management' in the menu\n2. Identify policies with the missing 'aws:SecureTransport' condition\n3. Update the relevant policies with the missing Bool condition\n4. Alternatively, detach all IAM entities from the policies\n\n**The required SSL/TLS Bool condition (JSON)**\n```\n\"Condition\": {\n\"Bool\": {\n\"aws:SecureTransport\": \"true\"\n}\n}\n```\n\n**From TF**\nTo update an IAM policy, update the policy document JSON in the following entity:\n```\nresource \"aws_iam_policy\" \"policy_example\" {\n..\npolicy = jsonencode({POLICY-DOCUMENT-JSON})\n..\n}\n```\nAlternatively, update the related policy document entity:\n```\ndata \"aws_iam_policy_document\" \"policy_document_example\" {\n...\n}\n```\n\n**From Command Line**\nTo list all IAM policies, run:\n```\naws iam list-policies\n```\nTo get an IAM policy document, run:\n```\naws iam get-policy-version --policy-arn POLICY-ARN --version-id DEFAULT-VERSION-ID\n```\nTo create a new version of the specified managed policy, run:\n```\naws iam create-policy-version --policy-arn POLICY-ARN --policy-document POLICY-DOCUMENT-JSON --set-as-default\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-policies.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/get-policy-version.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/create-policy-version.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "+uct01M9iqQo9qav0UVy8g",
        "ruleId": "D9.AWS.IAM.67",
        "category": ""
    },
    {
        "name": "Ensure second access key is rotated every 30 days or less",
        "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.\nRotating access keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used. Access keys should be rotated to ensure that data cannot be accessed with an old key which might have been lost, cracked, or stolen.",
        "severity": "Low",
        "logic": "IamUser where secondAccessKey.isActive='true' should not have secondAccessKey.lastRotated before(-30, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Click 'Make inactive'\n8. Go to the inactive Accesskey and click on Delete.\n\n**From Command Line**\n\n1. To inactive the old access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n2. To delete the old access key, run:\n```\naws iam delete-access-key\t--access-key ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_CLIAPI'\n3. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "47HL9JJ8tdRSMhKW99QgmA",
        "ruleId": "D9.AWS.IAM.77",
        "category": ""
    },
    {
        "name": "Ensure second access key is rotated every 45 days or less",
        "description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.\nRotating access keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used. Access keys should be rotated to ensure that data cannot be accessed with an old key which might have been lost, cracked, or stolen.",
        "severity": "Low",
        "logic": "IamUser where secondAccessKey.isActive='true' should not have secondAccessKey.lastRotated before(-45, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console: https://console.aws.amazon.com/\n2. Click Services\n3. Click IAM\n4. Click on Users\n5. Select on the relevant user\n6. Click on Security Credentials\n7. Click 'Make inactive'\n8. Go to the inactive Accesskey and click on Delete.\n\n**From Command Line**\n\n1. To inactive the old access key, run:\n```\naws iam update-access-key --access-key-id ACCESS_KEY_ID --status Inactive --user-name USER_NAME\n```\n2. To delete the old access key, run:\n```\naws iam delete-access-key\t--access-key ACCESS_KEY_ID --user-name USER_NAME\n```\n\n**References**\n1. https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_CLIAPI'\n3. http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "L+NGtT2mhBf5UoaiRfd6MA",
        "ruleId": "D9.AWS.IAM.75",
        "category": ""
    },
    {
        "name": "Ensure that AWS DynamoDB is encrypted using customer-managed CMK",
        "description": "AWS DynamoDb should be encrypted using customer-managed CMK, instead of AWS-managed CMK. An AWS-managed CMK can only be used to protect resources within the specific AWS service for which it is created. It does not provide the level of granular control that a customer-managed CMK provides. For more control, a best practice is to use a customer-managed CMK in all supported AWS services and in your applications. A customer-managed CMK is created at your request and should be configured based upon your explicit use case.This is required in order to meet encryption regulatory requirements of Server-Side encryption for the sensitive data that may be stored in the DynamoDB",
        "severity": "Low",
        "logic": "DynamoDbTable should have encryptionType='KMS'",
        "remediation": "\n**From Portal**\n1. Sign in to AWS console.\n2. In the console, select the specific region.\n3. Navigate to DynamoDB dashboard.\n4. Select the reported table from the list of DynamoDB tables.\n5. Choose Additional Settings tab and go to Encryption section.\n6. Click on Manage Encryption tab.\n7. On Manage Encryption pop up window, select Stored in your account, and owned and managed by you to select customer managed CMK as the encryption type.\n8. Click on Save Changes.\n\n**From TF**\n```\nresource \"aws_dynamodb_table\" \"basic_dynamodb_table\" {\nserver_side_encryption {\n-  kms_key_arn = null\n+  kms_key_arn = KEY_ARN\n}\n}\n```\n\n**From Command Line**\nRun below command to update an encrypted table with a customer managed key for DynamoDB\n```\naws dynamodb update-table --table-name Music --sse-specification Enabled=true,SSEType=KMS,KMSMasterKeyId=KEY_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/encryption.tutorial.html\n2. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/dynamodb_table\n4. https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html\n5. https://d1.awsstatic.com/whitepapers/aws-kms-best-practices.pdf ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "txnTQeRG1vInmPQKhNOpwg",
        "ruleId": "D9.AWS.CRY.30",
        "category": ""
    },
    {
        "name": "Ensure that AWS EKS Cluster control plane logging is enabled",
        "description": "Amazon EKS control plane logging provides audit and diagnostic logs directly from the Amazon EKS control plane to CloudWatch Logs in your account. These logs make it easy for you to secure and run your clusters. You can select the exact log types you need, and logs are sent as log streams to a group for each Amazon EKS cluster in CloudWatch.",
        "severity": "Low",
        "logic": "EksCluster should have logging.clusterLogging with [ enabled=true ]",
        "remediation": "\n**From Portal**\n1. Log in to the AWS Management Console at https://console.aws.amazon.com/.\n2. Open the Amazon EKS console.\n3. To display your cluster information, select the cluster's name.\n4. Navigate to Logging and click Update.\n5. For each individual log stream, select if the log type should be Enabled.\n6. Click Update.\n\n**From TF**\n```\nresource \"aws_eks_cluster\" \"example\" {\nname_prefix= example_name\nrole_arn = aws_iam_role_arn\nvpc_config {\nendpoint_public_access = false\nsubnet_ids = var.subnet_ids\n}\n\ntags = {\npike=\"permissions\"\n}\nencryption_config {\nresources = [\"secrets\"]\n}\n+  enabled_cluster_log_types = [\"api\", \"audit\", \"authenticator\",\"controllerManager\",\"scheduler\"]\n}\n```\n\n**From Command Line**\nUse following command to enable control plane logs with the AWS CLI\n```\naws eks update-cluster-config --region REGION_NAME --name CLUSTER_NAME --logging CLUSTER_LOGGING_TYPE\n```\nNote: --logging parameter defines the type of logging enabled for that cluster. For more info, follow the **References**\nsection.\n\n**References**\n1. https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/eks/update-cluster-config.html ",
        "complianceTag": "Logging",
        "logicHash": "wx4ZVikpHtp0WklbPObNdg",
        "ruleId": "D9.AWS.LOG.18",
        "category": ""
    },
    {
        "name": "Ensure that AWS Elastic Load Balancers (ELB) have inbound rules in their security groups",
        "description": "ELB security groups should have at least one inbound rule. ELBs with no inbound permissions will deny all traffic incoming to the ELB.",
        "severity": "Low",
        "logic": "ELB should not have securityGroups with [ inboundRules isEmpty() ]",
        "remediation": "\n**From Portal:**\n1. Log in to the AWS console\n2. In the console, select the specific region\n3. Navigate to EC2 Dashboard\n4. Click 'Load Balancers', select the reported load balancer\n5. Select the Security tab from the bottom panel.\n6. Click on each associated security group ID under Security Group ID column to open the selected security group configuration page.\n7. Click the 'Inbound Rules'\n8. If there are no rules, click 'Edit rules' and create an inbound rule according to your ELB functional requirement.\n\n**From Command Line:**\nTo add a rule that allows Inbound traffic to a specific address range. Below example command adds a rule that grants access to the desired address range on TCP port 22.\n```\naws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port 22 --cidr IP_address_range\n```\n\nReferences:\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html\n2. https://aws.amazon.com/premiumsupport/knowledge-center/security-group-load-balancer/\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/authorize-security-group-ingress.html ",
        "complianceTag": "Network Security",
        "logicHash": "nGutgkPJDOC0ayXj1EurFQ",
        "ruleId": "D9.AWS.NET.50",
        "category": ""
    },
    {
        "name": "Ensure that AWS Elastic Load Balancers (ELB) have outbound rules in their security groups",
        "description": "ELB security groups should have at least one outbound rule. ELBs with no outbound permissions will deny all outgoing traffic from the ELB.",
        "severity": "Low",
        "logic": "ELB should not have securityGroups with [ outboundRules isEmpty() ]",
        "remediation": "\n**From Portal**\n1. Log in to the AWS console\n2. In the console, select the specific region\n3. Navigate to EC2 Dashboard\n4. Click 'Load Balancers', select the reported load balancer\n5. Select the Security tab from the bottom panel.\n6. Click on each associated security group ID under Security Group ID column to open the selected security group configuration page.\n7. Click the 'Outbound Rules'\n8. If there are no rules, click 'Edit rules', add an outbound rule according to your ELB functional requirements.\n\n**From Command Line**\n1. To add a rule that allows outbound traffic to a specific address range. Below example command adds a rule that grants access to the specified address ranges on TCP port 80.\n\nCommand (Linux):\n```\naws ec2 authorize-security-group-egress --group-id security_group_id --ip-permissions IpProtocol=tcp,FromPort=80,ToPort=80,IpRanges=[{CidrIp=10.0.0.0/16}]\n```\nCommand (Windows):\n```\naws ec2 authorize-security-group-egress --group-id security_group_id --ip-permissions IpProtocol=tcp,FromPort=80,ToPort=80,IpRanges=[{CidrIp=10.0.0.0/16}]\n```\n\n2. To add a rule that allows outbound traffic to a specific security group. Below example command adds a rule that grants access to the specified security group on TCP port 80.\nCommand (Linux):\n```\naws ec2 authorize-security-group-egress --group-id security_group_id --ip-permissions IpProtocol=tcp,FromPort=80,ToPort=80,UserIdGroupPairs='[{GroupId=sg-4b51a32f}]'\n```\nCommand (Windows):\n```\naws ec2 authorize-security-group-egress --group-id security_group_id --ip-permissions IpProtocol=tcp,FromPort=80,ToPort=80,UserIdGroupPairs=[{GroupId=sg-4b51a32f}]\n```\n\n**References**\n1. https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html\n2. https://aws.amazon.com/premiumsupport/knowledge-center/security-group-load-balancer/\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/authorize-security-group-egress.html ",
        "complianceTag": "Network Security",
        "logicHash": "bTqQFD7fbjr8EqIJsXVg0Q",
        "ruleId": "D9.AWS.NET.44",
        "category": ""
    },
    {
        "name": "Ensure that AWS SNS topic is encrypted using Customer Managed Keys instead of AWS-owned CMKs",
        "description": "AWS SNS topic should be encrypted using Customer Managed Keys instead of AWS-owned CMKs. This is required in order to meet encryption regulatory requirements of Server-Side encryption for sensitive data that may be stored in the topic.",
        "severity": "Low",
        "logic": "SnsTopic where cryptoKey.enabled=true should have cryptoKey.isCustomerManaged=true",
        "remediation": "\n**From Portal**\nPerform the following steps to setup at-rest encryption using customer managed key:\n1. Sign on to the  Amazon SNS console\n2. On the navigation panel, choose Topics.\n3. Click on the topic you want to enable encryption for.\n4. In the top-right corner, click Edit.\n5. Under Encryption, Enable encryption tab.\n6. Under Customer master Key (CMK), enter an existing customer managed key ARN.\n\n**From TF**\n```\nresource \"aws_sns_topic\" \"test\" {\nname              = \"example_name\"\n- kms_master_key_id = \"CUSTOMER_MANAGED_KEY\"\n+ kms_master_key_id = \"CUSTOMER_MANAGED_KEY\"\n}\n```\n\n**From Command Line**\n```\naws sns set-topic-attributes --topic-arn VALUE --attribute-name KMS_MASTER_KEY_ID --attribute-value CUSTOMER_MANAGED_KEY\n```\n\n**References**\n1. https://docs.aws.amazon.com/sns/latest/dg/sns-tutorial-enable-encryption-for-topic.html\n2. https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sns_topic\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sns/set-topic-attributes.html\n5. https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "wf5GpTVnUULexCHRIOTx/Q",
        "ruleId": "D9.AWS.CRY.51",
        "category": ""
    },
    {
        "name": "Ensure that AWS SQS is encrypted using Customer Managed keys instead of AWS-owned CMKs",
        "description": "AWS SQS should be encrypted using Customer Managed keys, instead of AWS-owned CMKs. This is required in order to meet encryption regulatory requirements of Server-Side encryption for sensitive data that may be stored in the SQS.",
        "severity": "Low",
        "logic": "Sqs where cryptoKey.enabled=true should have cryptoKey.isCustomerManaged=true",
        "remediation": "\n**From Portal**\nPerform the following to set at-rest encryption using Customer Managed key:\n1. Log in to the AWS Management Console.\n2. Open the Amazon SQS console.\n3. Open a Queue and click Edit at the top right corner.\n4. Expand Encryption and select Enabled.\n5. Enter a Customer managed key and click Save.\n\n**From TF**\n```\nresource \"aws_sqs_queue\" \"example\" {\nname                              = \"terraform-example-queue\"\n+ kms_master_key_id                 = \"Customer_Managed_Key\"\n+ kms_data_key_reuse_period_seconds = VALUE\n...\n}\n```\n\n**From Command Line**\n```\naws sqs set-queue-attributes --queue-url QUEUE_URL --attributes KmsMasterKeyId=Customer_Managed_Key\n```\n\n**References**\n1. https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html\n2. https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-sse-existing-queue.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/set-queue-attributes.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "/wQ9J8LPqTHFuO8DbYwOLA",
        "ruleId": "D9.AWS.CRY.52",
        "category": ""
    },
    {
        "name": "Ensure that AWS Secret Manager Secret rotation interval is smaller than 30 days",
        "description": "Secrets Manager enables you to replace hardcoded credentials in your code, including passwords, with an API call to Secrets Manager to retrieve the secret programmatically. This helps ensure the secret can't be compromised by someone examining your code, because the secret no longer exists in the code. Also, you can configure Secrets Manager to automatically rotate the secret for you according to a specified schedule. This enables you to replace long-term secrets with short-term ones, significantly reducing the risk of compromise.\nAWS Secrets Manager automatically triggers a rotation this number of days after the previous rotation. If you ever rotate the secret manually, the rotation interval resets and it is best practice to set the rotation every 30 days.",
        "severity": "Low",
        "logic": "SecretManager should have rotationRules.automaticallyAfterDays<=30",
        "remediation": "\n**From console**\nPerform the following actions in order to change a secret rotation rule:\n1. Sign in to the AWS Secrets Manager Dashboard - https://console.aws.amazon.com/secretsmanager/\n2. Choose the name of the secret to enable rotation.\n3. On the secret details page, in the Rotation configuration section, choose Edit rotation.\n4. On the Edit rotation configuration page, choose Enable automatic rotation.\n5. For Select rotation interval, choose 30 or less days.\n6. Choose a Lambda function from the list.\n7. Under Select which secret will be used to perform the rotation, choose Use a secret that I have previously stored in AWS Secrets Manager.\n8. In the list of secrets that appears, choose the name of your Secret\n9. Choose Save.\n\n**From Command Line**\n```\naws secretsmanager rotate-secret --secret-id SECRED-ID --rotation-rules AutomaticallyAfterDays=DAYS\n```\n\n**From CFT**\nIn your cloudformation template use 'AWS::SecretsManager::RotationSchedule::RotationRules' and set the property 'AutomaticallyAfterDays: Integer' an integer value of 30 or less.\nSee below example:\n\n```\nType: AWS::SecretsManager::RotationSchedule\nProperties:\n...\nRotationRules:\nAutomaticallyAfterDays: 30\n...\n```\n\n**From TF**\n```\nresource \"aws_secretsmanager_secret\" \"rotation-example\" {\nrotation_rules {\n-   automatically_after_days = 31\n+   automatically_after_days = 30\n}\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\n2. https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/secretsmanager/rotate-secret.html#\n4. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-secretsmanager-rotationschedule-rotationrules.html",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "aiXoEWj0S3iC761rVWGrRg",
        "ruleId": "D9.AWS.CRY.49",
        "category": ""
    },
    {
        "name": "Ensure that AWS Secret Manager Secret rotation is enabled",
        "description": "AWS Secret Manager is a service to store, retrieve and manage secrets throughout its lifecycle. This services can store, retrieve, rotate, encrypt and monitor the use of secrets. This service will remove the need for developers to on-goingly worry about manual periodic secret rotation in all their sensitive AWS environments. They would be able to simply point their application code to this service to use secrets in the secret manager and let AWS take care of rotation.",
        "severity": "Low",
        "logic": "SecretManager should have rotationEnabled=true",
        "remediation": "\n**From Portal**\n1. Sign in to AWS Management Console.\n2. Open the Secrets Manager console at https://console.aws.amazon.com/secretsmanager/\n3. On the Secrets page, choose your secret.\n4. On the Secret details page, in the Rotation configuration section, choose Edit rotation. In the Edit rotation configuration dialog box, do the following:\n5. In the Edit rotation configuration dialog box, do the following:\na. Turn on Automatic rotation..\nb. Under Rotation schedule, enter your schedule in UTC time zone in either the Schedule expression builder or as a Schedule expression.\nc. Under Rotation function, choose Create function. The Lambda console opens in a new window.\nd. Switch back to the Secrets Manager console to attach the new rotation function to your secret.\ne. For Lambda rotation function, choose the refresh button. Then in the list of functions, choose your new function.\nf. Choose Save.\n\n**From TF**\n```\nresource \"aws_secretsmanager_secret\" \"rotation-example\" {\nrotation_rules {\n-   rotation_enabled = false\n+   rotation_enabled = true\n}\n}\n```\nNote: using value as true under rotation_enabled arguement enables secret rotation.\n\n**From Command Line**\nPerform the following CLI command to set rotation for a secret:\n```\naws secretsmanager rotate-secret --secret-id value --rotation-lambda-arn value --rotation-rules AutomaticallyAfterDays=value\n```\nNote: Use the ARN of the Lambda rotation function for secrets that use a Lambda rotation function to rotate.\nAutomaticallyAfterDays parameter value describe the number of days between rotations of the secret.\n\n**References**\n1. https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html\n2. https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_turn-on-for-other.html\n3. https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_now.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/secretsmanager_secret#rotation_enabled\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/secretsmanager/rotate-secret.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "JGkvcDPezIrfKFiZGjXXHg",
        "ruleId": "D9.AWS.CRY.48",
        "category": ""
    },
    {
        "name": "Ensure that Amazon ECR image repositories are using lifecycle policies.",
        "description": "Amazon ECR lifecycle policies provide more control over the lifecycle management of images in a private repository. A lifecycle policy contains one or more rules, where each rule defines an action for Amazon ECR. This provides a way to automate the cleaning up of your container images by expiring images based on age or count. You should expect that after creating a lifecycle policy, the affected images are expired within 24 hours. When Amazon ECR performs an action based on a lifecycle policy, this is captured as an event in AWS CloudTrail.",
        "severity": "Low",
        "logic": "EcrRepository should not have lifecyclePolicy.document isEmpty()",
        "remediation": "\n**From Portal**\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region that contains the repository for which to create a lifecycle policy.\n3. In the navigation pane, choose Repositories.\n4. On the Repositories page, on the Private tab, select a repository to view the repository image list.\n5. On the repository image list view, in the left navigation pane, choose Lifecycle Policy.\n6. On the repository lifecycle policy page, choose Create rule.\n7 Enter the following details for your lifecycle policy rule.\na) For Rule priority, type a number for the rule priority.\nb) For Rule description, type a description for the lifecycle policy rule.\nc) For Image status, choose Tagged, Untagged, or Any.\nd) If you specified Tagged for Image status, then for Tag prefixes, you can optionally specify a list of image tags on which to take action with your lifecycle policy. If you specified Untagged, this field must be empty.\ne) For Match criteria, choose values for Since image pushed or Image count more than (if applicable).\n8. Choose Save.\n9. Create additional lifecycle policy rules by repeating steps 5-7.\n\n**From TF**\nUse the resource \"aws_ecr_lifecycle_policy\" to configure replication. check below example for untagged images.\n\n```\nresource \"aws_ecr_lifecycle_policy\" \"examplepolicy\" {\nrepository = example_repository\n\npolicy = <<EOF\n{\n\"rules\": [\n{\n\"rulePriority\": 1,\n\"description\": \"Expire images older than 14 days\",\n\"selection\": {\n\"tagStatus\": \"untagged\",\n\"countType\": \"sinceImagePushed\",\n\"countUnit\": \"days\",\n\"countNumber\": 14\n},\n\"action\": {\n\"type\": \"expire\"\n}\n}\n]\n}\nEOF\n}\n```\n\n**From Command Line**\n1. Create a local file named policy.json with the contents of the lifecycle policy. Check the link in reference for example policies.\n2. Create a lifecycle policy by specifying the repository name and reference the lifecycle policy JSON file you created.\n```\naws ecr put-lifecycle-policy --repository-name repository-name --lifecycle-policy-text file://policy.json\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/LifecyclePolicies.html\n2. https://docs.aws.amazon.com/AmazonECR/latest/userguide/lp_creation.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_replication_configuration",
        "complianceTag": "Operational",
        "logicHash": "FRnV9bQcVNoFvWnIr/tN8w",
        "ruleId": "D9.AWS.OPE.24",
        "category": ""
    },
    {
        "name": "Ensure that IamGroup does not have Inline policies",
        "description": "Ensure that all your IAM Groups are not using inline policies and instead using managed policies, for various reasons including reusability, central change management, versioning and rolling back and delegating permissions management. ",
        "severity": "Low",
        "logic": "IamGroup should not have inlinePolicies",
        "remediation": "\n**From Portal**\nUse following steps to delete inline policy.\n1. Sign in to the AWS Management Console and navigate to the IAM dashboard - https://console.aws.amazon.com/iam/.\n2.  From the left navigation panel choose Groups.\n3. Click on a group name from the list of groups.\n4. Once in the IAM group summary page, click on the permissions tab.\n5. To delete an inline policy in User groups, choose Delete.\n6. If you are deleting a single inline policy in User groups, type the name of the policy and choose Delete. If you are deleting multiple inline policies in User groups, type the number of policies you are deleting followed by inline policies and choose Delete. For example, if you are deleting three inline policies, type 3 inline policies.\n\n**From Command Line**\nUse following command to delete any inline policy:\n```\naws iam delete-group-policy --group-name user_group_name --policy-name policy_document_name\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-delete.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-group-policy.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "1WEjh8KkXCi/6aiMRtcDiA",
        "ruleId": "D9.AWS.CRY.41",
        "category": ""
    },
    {
        "name": "Ensure that Lambda Function's environment variables 'Encryption at Rest' feature uses Customer Master Keys (CMK)",
        "description": "Lambda Function's environment variables are encrypted by default using the AWS default keys. Use Customer Master Keys to add another layer of control to the encryption.",
        "severity": "Low",
        "logic": "Lambda where not environmentVariables isEmpty() should have kmsKeyArn",
        "remediation": "\n**From Portal**\n1. Go to 'Lambda' dashboard\n2. In the left menu, select 'Functions'\n3. Select the relevant Lambda Function\n4. Under 'Configurations', go to 'Environment variables' and press 'Edit'\n5. Under 'Encryption configuration', set 'AWS KMS key to encrypt at rest' to 'Use a customer master key'\n6. Configure your 'Customer master key' and save\n\n**From TF**\nTo update a Lambda Function with a key for environment variables encryption, add the 'kms_key_arn' to the 'aws_lambda_function block:\n```\nresource \"aws_lambda_function\" \"lambda_function_example\" {\n..\nkms_key_arn = KEY-ARN\n..\n}\n```\n\n**From Command Line**\nTo update a Lambda Function with a key for environment variables encryption, use:\n```\naws lambda update-function-configuration --function-name FUNCTION-NAME --kms-key-arn KEY-ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function#kms_key_arn\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/update-function-configuration.html\n",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "cv0gP9D1Ciuzcm8k1vq5Hw",
        "ruleId": "D9.AWS.CRY.68",
        "category": ""
    },
    {
        "name": "Ensure that Object-level logging for read events is enabled for S3 bucket",
        "description": "S3 object-level API operations such as GetObject, DeleteObject, and PutObject are called data events.Object-level logging is managed by Cloudtrail hence this rule will show results of cloudtrail entity.By default, CloudTrail trails don't log data events and so it is recommended to enable Object-level logging for S3 buckets.Enabling object-level logging will help you meet data compliance requirements within your organization, perform comprehensive security analysis, monitor specific patterns of user behavior in your AWS account or take immediate actions on any object-level API activity using Amazon CloudWatch Events.",
        "severity": "Low",
        "logic": "CloudTrail should have (eventSelectors contain [ dataResources contain [type like 'AWS::S3::Object' ] ]) and (eventSelectors contain [ readWriteType = 'ReadOnly' or readWriteType = 'All'])",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console and navigate to S3 dashboard at https://console.aws.amazon.com/s3/\n2. In the left navigation panel, click buckets and then click on the S3 Bucket Name that you want to examine.\n3. Click Properties tab to see in detail bucket configuration.\n4. Click on the Object-level logging setting, enter the CloudTrail name for the recording activity. You can choose an existing Cloudtrail or create a new one by navigating to the Cloudtrail console link https://console.aws.amazon.com/cloudtrail/\n5. Once the Cloudtrail is selected, check the Read event checkbox, so that object-level logging for Read events is enabled.\n6. Repeat steps 2 to 5 to enable object-level logging of read events for other S3 buckets.\n\n**From Command Line**\n1. To enable object-level data events logging for S3 buckets within your AWS account, run put-event-selectors command using the name of the trail that you want to reconfigure as identifier:\n```\naws cloudtrail put-event-selectors --region REGION_NAME --trail-name TRAIL_NAME --event-selectors '[{ \"ReadWriteType\": \"ReadOnly\", \"IncludeManagementEvents\":true, \"DataResources\": [{ \"Type\": \"AWS::S3::Object\", \"Values\": [\"arn:aws:s3:::S3-BUKCET-NAME/\"] }] }]'\n```\n2. The command output will be object-level event trail configuration.\n3. If you want to enable it for all buckets at once then change Values parameter to [\"arn:aws:s3\"] in command given above.\n4. Repeat step 1 for each s3 bucket to update object-level logging of read events.\n5. Change the AWS region by updating the --region command parameter and perform the process for other regions.\n\n**From CFT**\n1. Use the resource AWS::CloudTrail::Trail and in the template make sure to set below values to respective arguments.\nThe property ReadWriteType should set to either 'ReadOnly' or 'All'.\n```\nResources:\nTrail:\nType: AWS::CloudTrail::Trail\nProperties:\n...\nEventSelectors:\n- DataResources:\n- Type: AWS::S3::Object\nValues:\n- arn:aws:s3:::BUCKET/\nIncludeManagementEvents: true\nReadWriteType: ReadOnly\n...\n```\n\n**From TF**\n1. Use the resource 'aws_cloudtrail' and in the template make sure to set below values to respective arguments.\nThe property read_write_type  should set to either 'ReadOnly' or 'All'.\n```\nresource \"aws_cloudtrail\" \"example\" {\n...\nevent_selector {\nread_write_type           = \"ReadOnly\"\ninclude_management_events = true\n\ndata_resource {\ntype   = \"AWS::S3::Object\"\nvalues = [\"arn:aws:s3:::BUCKET/\"]\n}\n}\n...\n}\n```\n\n**References**\n1. https://workbench.cisecurity.org/sections/615824/recommendations/1009551\n2. https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-cloudtrail-logging-for-s3.html\n3. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudtrail-trail.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail",
        "complianceTag": "Logging",
        "logicHash": "WasIsZjDO/jU4AnO0jp5ag",
        "ruleId": "D9.AWS.LOG.24",
        "category": ""
    },
    {
        "name": "Ensure that Object-level logging for write events is enabled for S3 bucket",
        "description": "Object-level logging allows you to incorporate S3 object access to your central auditing and logging in CloudTrail. You do have the ability to control what buckets, prefixes, and objects will be audited, and what types of actions to audit, and it will incur additional CloudTrail charges.",
        "severity": "Low",
        "logic": "S3Bucket should have objectLevelLogging=true",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. In the Buckets list, choose the name of the bucket.\n3. Choose Properties.\n4. Under AWS CloudTrail data events, choose Configure in CloudTrail.\n5. You can create a new CloudTrail trail or reuse an existing trail and configure Amazon S3 data events to be logged in your trail.\n\n**From TF**\n```\nresource \"aws_cloudtrail\" \"example\" {\n...\nevent_selector {\nread_write_type           = \"All\"\ninclude_management_events = true\n\ndata_resource {\ntype = \"AWS::S3::Object\"\n\n# Make sure to append a trailing '/' to your ARN if you want\n# to monitor all objects in a bucket.\nvalues = [\"BUCKET-ARN/\"]\n}\n}\n...\n}\n```\n\n**From Command Line**\nTo enable object level logging for a s3 bucket, run:\n```\naws cloudtrail put-event-selectors --trail-name TRAIL-NAME --event-selectors '[{\"ReadWriteType\": \"All\",\"IncludeManagementEvents\": true,\"DataResources\": [{\"Type\":\"AWS::S3::Object\", \"Values\": [\"arn:aws:s3:::BUCKET-NAME/\"]}]}]'\n```\n**References**\n1. https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-cloudtrail-events.html\n2. https://docs.aws.amazon.com/AmazonS3/latest/dev/cloudtrail-logging.html\n3. https://docs.aws.amazon.com/cli/latest/reference/cloudtrail/put-event-selectors.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail",
        "complianceTag": "Logging",
        "logicHash": "LrsMz7IuU/WmnaENr9JfUw",
        "ruleId": "D9.AWS.LOG.19",
        "category": ""
    },
    {
        "name": "Ensure that RDS database instance doesn't use its default endpoint port",
        "description": "Avoid using RDS database instance's default port to add another layer of security to your database's endpoint. Default ports: 3306 (MySQL/MariaDB), 5432 (PostgreSQL), 1521 (Oracle), 1433 (Microsoft SQL Server).",
        "severity": "Low",
        "logic": "RDS should not have ( port=3306 and (dbType like '%mysql%' or dbType like '%mariadb%') ) or ( port=5432 and dbType like '%postgres%' ) or ( port=1521 and dbType like '%oracle%' ) or ( port=1433 and dbType like '%sqlserver%' )",
        "remediation": "\n**From Portal**\n1. Go to the AWS RDS console: https://console.aws.amazon.com/rds/\n2. In the left pane, choose 'Databases'\n3. Mark the incompliant 'DB identifier'\n4. Click 'Modify'\n5. Under 'Connectivity' expand 'Connectivity'\n6. Set 'Database port' to a non-default port\n7. Press 'Continue' and apply the modification\n\n**From Command Line**\nTo modify the database instance's port, use:\n```\naws rds modify-db-instance --db-instance-identifier DB-IDENTIFIER --db-port-number PORT --no-apply-immediately\n```\n\n**From TF**\nSet the 'port' argument within the 'aws_db_instance' resource block to a non-default port:\n```\nresource \"aws_db_instance\" \"db_instance_example\" {\n..\nport = PORT\n..\n}\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/neptune/modify-db-instance.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#port\n",
        "complianceTag": "Network Security",
        "logicHash": "5cLfztxLVWH5iwQ+AFZX5w",
        "ruleId": "D9.AWS.NET.92",
        "category": ""
    },
    {
        "name": "Ensure that all the expired SSL/TLS certificates are removed from ACM",
        "description": "Certificate Manager is the AWS service that lets you easily provision, manage, and deploy SSL/TLS certificates for use with other Amazon services such as Elastic Load Balancing and CloudFront.",
        "severity": "Low",
        "logic": "AcmCertificate should not have status = 'EXPIRED'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console.\n2. Navigate to AWS ACM dashboard at https://console.aws.amazon.com/acm/.\n3. Select the SSL/TLS certificate that you want to remove with the status as Expired\n4. Click on the expired certificate and review the certificate details (domain name and ID).\n5. Click Delete to confirm the action.\n6. Repeat step number 3 and 4 to remove other expired AWS ACM certificates available within the selected region.\n7. Change the AWS region from the navigation bar and repeat the process for other regions.\n\n**From Command Line**\nUse the delete-certificate command to delete an expired certificate, as shown in the following command:\n```\naws acm delete-certificate --certificate-arn ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-delete.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/delete-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "IJx/blk9yOS2l7DJkaGVxw",
        "ruleId": "D9.AWS.CRY.40",
        "category": ""
    },
    {
        "name": "Ensure that at least one instance is registered with an ECS Cluster",
        "description": "ECS cluster is based on EC2 instances that are registered with the clusters. Cluster without registered instances is idle and cannot execute any tasks.",
        "severity": "Low",
        "logic": "EcsCluster should not have containerInstances length() = 0",
        "remediation": "\n**From Portal**\nUse following steps to verify container instances are registered with ECS clusters.\n1. Login to the AWS Management Console and navigate to ECS service.\n2. On ECS dashboard, select cluster you want to check.\n3. Click on ECS Instances tab available on the main page of cluster details.\n4. Select the container instance you want to examine under ECS Instances.\n5. Verify there is at least one instance is registered with that ECS cluster.\n\nUse following steps to delete a cluster.\n1. Open the Amazon ECS console at https://console.aws.amazon.com/ecs/.\n2. From the navigation bar, select the Region to use.\n3. In the navigation pane, choose Clusters.\n4. On the Clusters page, select the cluster to delete.\n5. In the upper-right of the page, choose Delete Cluster. You see a confirmation prompt.\n6. In the confirmation box, enter delete me.\n\nUse following steps to register instances with the ECS Cluster.\n1. Open the new console at https://console.aws.amazon.com/ecs/v2.\n2. From the navigation bar, select the Region to use.\n3. In the navigation pane, choose Clusters.\n4. On the Clusters page, choose a cluster to register your external instance to.\n5. On the Cluster : name page, choose the Infrastructure tab.\n6. On the Register external instances page, complete the following steps.\na. For Activation key duration (in days), enter the number of days that the activation key remains active for. After the number of days you entered pass, the key no longer works when registering an external instance.\nb. For Number of instances, enter the number of external instances that you want to register to your cluster with the activation key.\nc. For Instance role, choose the IAM role to associate with your external instances. If a role wasn't already created, choose Create new role to have Amazon ECS create a role on your behalf. For more information about what IAM permissions are required for your external instances, see Required IAM permissions for external instances.\nd. Copy the registration command. This command should be run on each external instance you want to register to the cluster.\nNote: The bash portion of the script must be run as root. If the command isn't run as root, an error is returned.\ne. Choose Close.\n\n**From Command Line**\nUse following commands to register an existing external instance with a different Cluster.\na. Stop the Amazon ECS container agent.\n```\nStop-Service AmazonECS\n```\nb. Modify the ECS_CLUSTER parameter so that the cluster name matches the name of the cluster to register the external instance with.\n```\n[Environment]::SetEnvironmentVariable(ECS_CLUSTER, $ECSCluster, [System.EnvironmentVariableTarget]::Machine)\n```\nc. Remove the existing Amazon ECS agent data.\n```\nRemove-Item -Recurse -Force $env:ProgramData\"Amazon\"ECS\"data\"*\n```\nd. Start the Amazon ECS container agent.\n```\nStart-Service AmazonECS\n```\n\nUse following delete-cluster command to delete the specified empty cluster:\n```\naws ecs delete-cluster --cluster CLUSTER_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-anywhere-registration.html\n2. https://docs.aws.amazon.com/AmazonECS/latest/userguide/delete_cluster.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-cluster.html ",
        "complianceTag": "Network Security",
        "logicHash": "fIPhMQpd4S57/C+d/c2FjA",
        "ruleId": "D9.AWS.NET.34",
        "category": ""
    },
    {
        "name": "Ensure that the Cross-Region Replication feature is enabled for your Amazon ECR container images.",
        "description": "Enabling Cross-Region replication for your registry makes copies of the repositories in one or more destination Regions. Application will start up faster when images stored are in multi-region, since this reduces latency and downtime.Since images are multi regional it also helps in achieving compliance in specific regions, and it will serve in disaster recovery for your application.",
        "severity": "Low",
        "logic": "EcrRepository should not have replicationConfiguration.rules isEmpty()",
        "remediation": "\n**From Portal**\n1. Open the Amazon ECR console at https://console.aws.amazon.com/ecr/repositories.\n2. From the navigation bar, choose the Region to configure your registry replication settings for.\n3. In the navigation pane, choose Private registry.\n4. On the Private registry page, on the Replication section, choose Edit.\n5. On the Replication page, choose Add replication rule.\n6. On the Destination types page, choose enable cross-Region replication, then choose Next.\n7. Select one or more AWS regions as destination targets from the Destination regions drop-down list.\n8. On the Review and submit page, review the replication rule configuration and then choose Submit rule.\n\n**From TF**\nUse the resource \"aws_ecr_replication_configuration\" to configure replication.\n```\nresource \"aws_ecr_replication_configuration\" \"example\" {\nreplication_configuration {\nrule {\ndestination {\nregion      = \"us-east-1\"\nregistry_id = registry_Id\n}\n}\n}\n}\n```\n\n**From Command Line**\n1. Create a JSON file containing the replication rules to define for your registry.The JSON file would look like below ;\n```\n{\n\"rules\": [{\n\"destinations\": [{\n\"region\": \"destination_region\",\n\"registryId\": \"destination_accountId\"\n}],\n\"repositoryFilters\": [{\n\"filter\": \"repository_prefix_name\",\n\"filterType\": \"PREFIX_MATCH\"\n}]\n}]\n}\n```\n2. Create a replication configuration for your registry.\n```\naws ecr put-replication-configuration --replication-configuration file://replication-settings.json --region us-west-2\n```\n**References**\n1. https://docs.aws.amazon.com/AmazonECR/latest/userguide/replication.html\n2. https://docs.aws.amazon.com/AmazonECR/latest/userguide/registry-settings-configure.html\n3. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_replication_configuration",
        "complianceTag": "Operational",
        "logicHash": "U6g7a/Is72U1CDgevtuWjQ",
        "ruleId": "D9.AWS.OPE.23",
        "category": ""
    },
    {
        "name": "Ensure that the configuration recorder is set to 'on' and set S3 Bucket and SNS topic as your delivery channel",
        "description": "AWS Config uses the configuration recorder to detect changes in your resource configurations and capture these changes as configuration items. You must create a configuration recorder before AWS Config can track your resource configurations. As AWS Config continually records the changes that occur to your AWS resources, it sends notifications and updated configuration states through the delivery channel. You can manage the delivery channel to control where AWS Config sends configuration updates. You can have only one delivery channel per region per AWS account, and the delivery channel is required to use AWS Config.",
        "severity": "Low",
        "logic": "ConfigSetting should have recordingIsOn=true and deliveryChannel.s3BucketName and deliveryChannel.snsTopicARN",
        "remediation": "\n**From Portal**\nUse following steps to set configuration recorder on. You can follow reference section for more details.\n1. Create the Amazon S3 bucket.\n2. Create the SNS topic.\n3. Create the KMS Key.\n4. Create the delivery channel.\n\nUse below steps to start configuration recorder:\n1. Open the AWS Config console.\n2. In the navigation pane, choose Settings.\n3. In Recording is off, choose Turn on, and then choose Continue.\n\n**From Command Line**\nStep 1: Use following command to create a delivery channel:\na. Using a text editor, copy and paste the following example template, and then save it as a JSON file. You can change the deliveryFrequency value to match your use case. If you choose not to activate encryption, omit the s3KmsKeyArn value from the JSON file.\n\nNote: If you receive errors when running AWS Command Line Interface (AWS CLI) commands, make sure that you are using the most recent AWS CLI version.\n\n{\n\"name\": \"default\",\n\"s3BucketName\": \"targetBucketName\",\n\"s3KeyPrefix\": \"Optionalprefix\",\n\"snsTopicARN\": \"arn:aws:sns:region:account_ID:targetTopicName\",\n\"s3KmsKeyArn\": \"arn:aws:kms:region:account_ID:KmsKey\",\n\"configSnapshotDeliveryProperties\": {\n\"deliveryFrequency\": \"Twelve_Hours\"\n}\n}\n\nNote: The s3KeyPrefix must be provided if the S3 bucket policy restricts PutObject to a certain prefix, rather than the default.\n\nb. Run the following AWS CLI command:\n```\naws configservice put-delivery-channel --delivery-channel file://deliveryChannel.json\n```\nc. Run the following AWS CLI command to confirm that the Delivery Channel created:\n```\naws configservice describe-delivery-channels\n```\n\nStep 2. Use below command to Start the configuration recorder.\n```\naws configservice start-configuration-recorder --configuration-recorder-name configRecorderName\n```\n\n**References**\n1. https://docs.aws.amazon.com/config/latest/developerguide/stop-start-recorder.html\n2. https://docs.aws.amazon.com/config/latest/developerguide/manage-delivery-channel.html\n3. https://aws.amazon.com/premiumsupport/knowledge-center/recreate-config-delivery-channel ",
        "complianceTag": "Monitoring",
        "logicHash": "losW8EKIhPvbFQ2m+oONvQ",
        "ruleId": "D9.AWS.MON.16",
        "category": ""
    },
    {
        "name": "Ensure that your AWS CloudTrail logging bucket has MFA delete enabled",
        "description": "CloudTrail defaults to S3 server-side encryption (SSE) to encrypt log files. It is recommended, in addition, that the S3 buckets for CloudTrail, be configured with MFA Delete. This will prevent deletion of CloudTrail logs without your explicit authorization. It is also recommended to use a bucket policy that places restrictions on which of your identity access management (IAM) users are allowed to delete S3 objects.",
        "severity": "Low",
        "logic": "S3Bucket where policy.Statement contain [Principal.Service='cloudtrail.amazonaws.com'] should not have versioning.mfaDelete=false",
        "remediation": "\nYou cannot enable MFA Delete using the AWS Management Console. You must use the AWS Command Line Interface (AWS CLI) or the API.\n\n**From Command Line**\nRun the below command to enable MFA delete on an S3 bucket. You must use your root account to enable MFA Delete on S3 buckets\n```\naws s3api put-bucket-versioning --profile MY_PROFILE --bucket S3_BUCKET_NAME --versioning-configuration Status=Enabled,MFADelete=Enabled --mfa SERIAL_EXAMPLE\n```\n--mfa (string): You can use here the concatenation of the authentication device serial number, a space, and the value that is displayed on your authentication device.\n\n**References**\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiFactorAuthenticationDelete.html\nhttps://aws.amazon.com/blogs/security/securing-access-to-aws-using-mfa-part-3/\nhttps://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-bucket-versioning.html ",
        "complianceTag": "Logging",
        "logicHash": "mh8ksZlCoIN31QpdTpWUbQ",
        "ruleId": "D9.AWS.LOG.16",
        "category": ""
    },
    {
        "name": "Ensure that your Amazon EFS file systems are encrypted using KMS CMK customer-managed keys",
        "description": "When you define and use your own KMS CMK customer-managed keys to protect the EFS file systems data and metadata, you gain full control over who can use these keys to access the data (including the system metadata). The AWS KMS service allows you to create, rotate, disable and audit CMK encryption keys for your file systems.",
        "severity": "Low",
        "logic": "EFS should have encryptionKey.isCustomerManaged=true",
        "remediation": "\n**From Portal**\nYou can enable encryption of data at rest when creating an Amazon EFS file system. Following are the steps to encrypt a File System at Rest Using the AWS Console.\n1. Open the Amazon Elastic File System console at https://console.aws.amazon.com/efs/.\n2. Choose 'Create file system' to open the file system creation wizard.\n3. Check 'Enable encryption of data at rest' checkbox.\n4. Click on 'Customize encryption settings' and choose the customer-managed KMS Key from dropdown list to enable encryption using your own KMS CMK key.\n\nNote: There is no functionality that allows you to encrypt existing EFS if the encryption wasn't enabled during the creation of Amazon EFS process. In order to encrypt an existing Amazon EFS, you need to create a new Amazon EFS and copy all the data from the existing Amazon EFS onto the new one with encryption enabled.\n\n**From TF**\n```\nresource \"aws_efs_file_system\" \"example\"{\ncreation_token = \"default-efs\"\n+ encrypted = true\n+ kms_key_id = aws_kms_key.default-kms.arn\n}\n```\n\n**From Command Line**\n```\naws efs create-file-system --creation-token VALUE --performance-mode VALUE --encrypted --kms-key-id KEY_ID\n```\nNote: --encrypted parameter will encrypt using default master key and --kms-key-id parameter will encrypt the snapshot with a customer-managed Customer CMK.\n\n**References**\n1. https://docs.aws.amazon.com/efs/latest/ug/encryption-at-rest.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_file_system\n3. https://docs.aws.amazon.com/whitepapers/latest/efs-encrypted-file-systems/creating-an-encrypted-file-system-using-the-aws-cli.html\n4. https://docs.aws.amazon.com/cli/latest/reference/efs/create-file-system.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "HIuKN8K5uP7zwxAHwvEXTg",
        "ruleId": "D9.AWS.CRY.23",
        "category": ""
    },
    {
        "name": "Ensure that your Amazon Lambda functions do not share the same AWS IAM execution role",
        "description": "It is recommended to have one IAM role per each Lambda function in order to follow the Principle of Least Privilege. This way you can ensure that your Lambda functions will have the minimum privileges needed to perform the required tasks.",
        "severity": "Low",
        "logic": "List<Lambda> should not have items groupBy [executionRoleArn] contain [values length() > 1]",
        "remediation": "\n**From Portal:**\n1. Navigate to Lambda dashboard at https://console.aws.amazon.com/lambda/.\n2. In the navigation panel, go to AWS Lambda section and select Functions.\n3. Choose the relevant Lambda function, and click on it to access its configuration page.\n4. Select the Configuration tab and click Permission option.\n5. In the Execution role section, choose Edit to change the role that defines the permissions for the selected Functions.\n6. On the Edit basic settings configuration page, perform one of the following operations.\na. To associate the function with an existing IAM role, choose 'Use an existing role' from the 'Execution role', and select the required role from the 'Existing role' dropdown list. The chosen IAM role can't be associated with another Lambda function and must follow the Principle of Least Privilege. Choose 'Save' to apply the configuration changes.\nb. To apply a new execution role to your Lambda function, choose 'Create a new role from AWS policy templates' to create a new execution role for the selected Amazon Lambda function. Provide a unique name for the new role in the 'Role name' box and select one or more policy templates from the 'Policy templates' dropdown list. Based on your function's access requirements, select the necessary permission sets from the 'Policy templates - optional' dropdown list. Choose 'Save' to apply the changes.\n\n**From Command Line**\n1. Create the trust relationship policy required for the execution role. Save the following policy document to a JSON file named cc-execution-role-trust-policy.json.\nNote: This trust policy allows Amazon Lambda to use the role's permissions by giving the service principal 'lambda.amazonaws.com' permission to call the AWS Security Token Service 'AssumeRole' action. To create the required trust policy for the new IAM role. Example below trust-policy.json\n\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"Service\": \"lambda.amazonaws.com\"\n},\n\"Action\": \"sts:AssumeRole\"\n}\n]\n}\n\n2. Run following command to create a new IAM execution role using the trust relationship policy:\n```\naws iam create-role --role-name new_lambda_execution_role_name --assume-role-policy-document file://example_policy.json.json\n```\n3. Run following command to attach an AWS-managed policy to the newly created execution role.\nNote: In below example the 'AWSLambdaSQSQueueExecutionRole' managed policy provides permission to read a message from an Amazon SQS queue.\n```\naws iam attach-role-policy --role-name new_lambda_execution_role_name --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaSQSQueueExecutionRole\n```\n4. Run following command using the name of the Amazon Lambda function that you want to reconfigure as the identifier parameter, to replace the shared execution role with the new IAM role created and configured in the previous steps.\nNote: Put new Lambda execution role ARN for --role command syntax\n```\naws lambda update-function-configuration --region region_name --function-name function_name --role arn:aws:iam::123456789012:role/new_lambda_execution_role_name\n```\n\nReferences:\n1. https://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html\n2. https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html\n3. https://docs.aws.amazon.com/lambda/latest/dg/lambda-permissions.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/create-role.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/attach-role-policy.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/update-function-configuration.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "poKnMoqBz65dSK0/uKeG0A",
        "ruleId": "D9.AWS.IAM.45",
        "category": ""
    },
    {
        "name": "Ensure the AWS Certificate Manager (ACM) has no unused certificates ",
        "description": "Checks the ACM for unused certificates. It is recommended to delete unused certificates, or associate them (use them).",
        "severity": "Low",
        "logic": "AcmCertificate should have inUseBy with ['%arn%']",
        "remediation": "\n**From Portal**\nFollowing are the steps to delete unused certificates:\n1. Open the ACM console at https://console.aws.amazon.com/acm/.\n2. In the list of certificates, select the check box for an ACM certificate, then choose Delete.\n\nAlternatively, you can associate/use the unused certificate to the resource which requires the certificate.\n\n**From Command Line**\nUse the delete-certificate command to delete a certificate, as shown in the following command:\n```\naws acm delete-certificate --certificate-arn ARN\n```\n\n**References**\n1. https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-delete.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/acm/delete-certificate.html ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "kVG8ZBiVFeSf+KWiwkpRXw",
        "ruleId": "D9.AWS.CRY.28",
        "category": ""
    },
    {
        "name": "Ensure there are no inline policies attached to the ECS service",
        "description": "Ensure there are no inline policies attached to the service. Inline policies are policies that are embedded directly into a single user, group, or role. It is recommend to use managed policies instead of inline policies. Managed policies provide reusability, central change management, versioning and more capabilities.",
        "severity": "Low",
        "logic": "EcsService should not have role.inlinePolicies",
        "remediation": "\n**From Portal**\nFor Each ECS Service with inline policies perform the following steps:\n1. In the IAM console, select Users from the navigation pane\n2. Select Permissions\n3. Remove any policies attached directly to the user (these are inline policies), and replace them with equivalent managed policies (in the Policies page) that are assigned to users, groups or roles.\n\n**From Command Line**\n1. Fetch the IAM group inline policies, run following get-group-policy command:\n```\naws iam get-group- --group-name PUT_GROUP_NAME --policy-name PUT_POLICY_NAME\n```\n2. Above command will give inline policy document requested. Create a JSON file and paste the data to the Policy Document object into the JSON file then save it.\n\n3. Detach the existing policies for the selected IAM group. Use following command to delete any inline policies\nNote: inline policies deleted automatically when we detach it, so make sure to save these policies before detaching.\n```\naws iam delete-group-policy --group-name PUT_GROUP_NAME --policy-name PUT_POLICY_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "aeW4uZDz3l+HqMQKXsPYkw",
        "ruleId": "D9.AWS.IAM.47",
        "category": ""
    },
    {
        "name": "Ensure to define VPC associations and propagations yourself to keep track of all routes and connections to and from your Transit gateway",
        "description": "In order to control your VPC environment and Transit gateway, prefer setting the associations and propagations for your transit gateway manually. Note: Default AWS configuration of transit gateway is set to automatically define associations and propagations.",
        "severity": "Low",
        "logic": "TransitGateway should have options.defaultRouteTableAssociation='disable' and options.defaultRouteTablePropagation='disable'",
        "remediation": "\n**From Portal:**\nPerform the following steps in order to set 'Default route table association' and 'Default route table propagation' to disable:\n1. Sign in to the Amazon VPC console at https://console.aws.amazon.com/vpc/\n2. Choose Transit Gateways\n3. Choose relevant gateway and click Actions -> Modify.\n4. Uncheck 'Default route table association' and 'Default route table propagation'.\n5. Update route table with the necessary routes.\n\n**From TF:**\n```\nresource \"aws_ec2_transit_gateway\" \"example\" {\n- default_route_table_association = \"enable\"\n- default_route_table_propagation = \"enable\"\n+ default_route_table_association = \"disable\"\n+ default_route_table_propagation = \"disable\"\n}\n```\n\n**From Command Line:**\n```\naws ec2 modify-transit-gateway --transit-gateway-id Transit_gateway_ID --options DefaultRouteTableAssociation=disable,DefaultRouteTablePropagation=disable\n```\n\nReferences:\n1. https://docs.aws.amazon.com/vpc/latest/tgw/tgw-getting-started.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_transit_gateway\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify-transit-gateway.html ",
        "complianceTag": "Network Security",
        "logicHash": "DOdfJtr6Y/GClt0Izo3MhA",
        "ruleId": "D9.AWS.NET.59",
        "category": ""
    },
    {
        "name": "Ensure whether IAM users are members of at least one IAM group",
        "description": "It is recommended to make sure that user belongs to at least one group, it will helps to control the permissions",
        "severity": "Low",
        "logic": "IamUser should have attachedGroups length()>0 or name regexMatch /^<root_account>$/",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the left navigation pane, click on Users\n4. For each User without group:\n5. Click on the User name\n6. Go to Groups\n7. click on Add user to groups\n8. Select relevant group\n9. Click on 'Add to Groups'\n\n**From TF**\nTo add user to a group, add following:\n```\nresource \"aws_iam_group_membership\" \"add_user_to_group_example\" {\n...\nusers = [\nUSER-1-NAME,\nUSER-2-NAME,\n]\ngroup = GROUP-NAME\n...\n}\n```\n\n**From Command Line**\nTo add iam user to group, run:\n```\naws iam add-user-to-group --user-name USER_NAME --group-name GROUP_NAME\n```\n\n**References**\n1. https://docs.aws.amazon.com/config/latest/developerguide/iam-user-group-membership-check.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_manage.html\n",
        "complianceTag": "Identity and Access Management",
        "logicHash": "wCFXtPgxDoMw4LwIsb0Q9Q",
        "ruleId": "D9.AWS.IAM.81",
        "category": ""
    },
    {
        "name": "Ensures that AWS RDS databases are encrypted using Customer Managed Keys",
        "description": "Validate that RDS databases are encrypted with customer managed keys and not default KMS keys. It is recommended to use customer managed keys to encrypt the data on your RDS databases and control the keys for sensitive data.",
        "severity": "Low",
        "logic": "RDS where isStorageEncrypted=true should have encryptionKey.isCustomerManaged=true",
        "remediation": "\n**From Portal**\nRDS encryption is configured during database creation, so you need to create a new database and migrate your existing data to your new RDS instance with encrypted Customer Managed keys.\n\nTo create a new RDS database with encryption using a customer managed key:\n1. Log in to the AWS console.\n2. Select the region for which the issue was generated.\n3. Navigate to the Amazon RDS Dashboard.\n4. Select 'Create database'.\n5. On the 'Select engine' page, select 'Engine options' and 'Next'.\n6. On the 'Select use case' page, select 'Use case' of database and 'Next'.\n7. On the 'Specify DB details' page, specify the database details you need and click 'Next'.\nNote: Amazon RDS encryption has some limitation on region and type instances. For Availability of Amazon RDS Encryption refer to: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Availability\n8. On the 'Configure advanced settings' page, Under 'Encryption', select 'Enable encryption' and select the customer managed key [i.e. Other than (default)aws/rds] from 'Master key' dropdown list].\n9. Select 'Create database'.\n\nTo delete the RDS database that uses the default KMS keys, which triggered the issue:\n1. Log in to the AWS console\n2. Select the region for which the issue was generated.\n3. Navigate to the Amazon RDS Dashboard.\n4. Click Instances, and select the reported RDS database.\n5. Select the 'Instance actions' drop-down and click 'Delete'.\n6. In the 'Delete' dialog, select the 'Create final snapshot?' checkbox, if you want a backup. Provide a name for the final snapshot, confirm deletion and select 'Delete'.\n\n**From TF**\n```\nresource \"aws_db_instance\" \"example\" {\n...\nname                 = \"example\"\n+ storage_encrypted    = true\nkms-key-id         = \"CustomerManagedKeyARN\"\n}\n```\n\n**From Command Line**\nUse following command to create a new RDS database with encryption using a customer managed key:\n```\naws rds create-db-instance --db-instance-identifier INSTANCE_NAME --db-instance-class INSTANCE_CLASS --engine ENGINE_TYPE --master-username USERNAME --master-user-password PASSWORD --storage-encrypted --kms-key-id CUSTOMER_MANAGED_KEY_ID --allocated-storage VALUE\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\n2. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateDBInstance.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-instance.html\n4. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "Gh4oTNnWy6OC/Ccpnk9svA",
        "ruleId": "D9.AWS.CRY.33",
        "category": ""
    },
    {
        "name": "Prefer using IAM roles for tasks rather than using IAM roles for an instance",
        "description": "Instead of creating and distributing your AWS credentials to the containers or using the EC2 instance role, you can associate an IAM role with an ECS task definition or RunTask API operation. Doing the first will result in all the privileges required by any task in the cluster being added to a single IAM role, potentially letting tasks use privileges that were not required.",
        "severity": "Low",
        "logic": "EcsCluster where services contain [taskDefinition] should have services contain [taskDefinition.taskRoleArn]",
        "remediation": "\n**From Portal**\nFollow the steps below for each finding:\n1. Open the new console at https://console.aws.amazon.com/ecs/v2.\n2. From the navigation bar, choose the Region that contains your task definition.\n3.In the navigation pane, choose Task definitions.\n4. On the Task definitions page, choose the task, and then choose Create new revision.\n5. On the Create new task definition revision page, make changes. For example, to change the existing container definitions (such as the container image, memory limits, or port mappings), select the container, and then make the changes.\n6. Verify the information, and then choose Create.\n\nTo create and IAM role for your task and assign it to ECS Cluster perform the following:\n1. Open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, choose Roles, Create role.\n3. For Select trusted entity section, choose AWS service.\n4. For Use case, using the drop down menu, select Elastic Container Service and then the Elastic Container Service Task use case and then choose Next.\n5. For Add permissions, search for and select the policy to use for your tasks (in this example AmazonECSTaskS3BucketPolicy), and then choose Next.\n6. On Step 3: Name, review, and create, do the following:\na. For Role name, enter a name for your role. For this example, type AmazonECSTaskS3BucketRole to name the role.\nb. (Optional) For Description. specify a description for this IAM role.\nc. Review the trusted entity and permissions policy for the role.\nd. For Add tags (Optional), enter any metadata tags you want to associate with the IAM role, and then choose Create role.\n\n**From Command Line**\nYou can use the following command in order to add task-role to your task definition:\n```\naws ecs register-task-definition --family PUT_VALUE --task-role-arn PUT_VALUE\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonECS/latest/userguide/update-task-definition-console-v2.html\n2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/register-task-definition.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "/ZFDYurESG+2PiFGTwLT2w",
        "ruleId": "D9.AWS.IAM.48",
        "category": ""
    },
    {
        "name": "Remove Unused Security Groups",
        "description": "A security group should always have attached protected assets. Removing Unused Security Groups is the expected outcome of the firewall and router rule sets review.",
        "severity": "Low",
        "logic": "SecurityGroup where name != 'default' should not have networkAssetsStats contain-all [ count = 0 ] and networkInterfaces isEmpty()",
        "remediation": "\n**From Portal**\n1. Note down the unused Security Groups detected by the CloudGuard Report.\n2. Go to EC2 console and navigate to security groups.\n3. Select all the security groups and click on 'Actions'.\n4. Click on 'Delete security groups'.\n\nNote: Security groups that are attached to instances or containing any network assets are used and should not be deleted.\n\n**From Command Line**\nRun the following command to delete an EC2 security group created within EC2-Classic.\n```\naws ec2 delete-security-group --region REGION_NAME --group-name SECURITY_GROUP_NAME\n```\n\nRun the following command to delete an EC2 security group created within EC2-VPC.\n```\naws ec2 delete-security-group --region REGION_NAME --group-id SECURITY_GROUP_ID\n```\nNote: The above example deletes the security group with the ID. You can not reference a security group for EC2-VPC by name.\n\n**References**\n1. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n2. https://docs.aws.amazon.com/cli/latest/userguide/cli-services-ec2-sg.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete-security-group.html ",
        "complianceTag": "Network Security",
        "logicHash": "LIhVhPxTYePDyWuQweJk9Q",
        "ruleId": "D9.AWS.NET.15",
        "category": ""
    },
    {
        "name": "S3 bucket should have server access logging enabled",
        "description": "Turn on logging on all of your buckets so that you can make sure that all changes are logged and trackable.",
        "severity": "Low",
        "logic": "S3Bucket should have logging.enabled=true",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console at https://console.aws.amazon.com/.\n2. Open the Amazon S3 console.\n3. Navigate to the Bucket name list.\n4. To enable server access logging for a bucket, select the name of the bucket.\n5. Click Properties.\n6. Click Server access logging. For the target, select the name of the bucket that you want to receive the log record objects.\n7. Click Enable Logging.\nNote: The target bucket must be in the same Region as the source bucket and must not have a default retention period configuration.\n\n**From TF**\n```\nresource \"aws_s3_bucket\" \"example_bucket\" {\nbucket = \"example-bucket\"\nlogging {\ntarget_bucket = \"s3_bucket_id\"\ntarget_prefix = \"log/\"\n}\nother required fields here\n}\n```\n\n**From Command Line**\n1. Run the following to check Bucket logging status.\n```\naws s3api get-bucket-logging --bucket S3_BUCKET\n```\n2. Run the following command to enable logging.\n```\naws s3api put-bucket-logging --bucket S3_BUCKET --bucket-logging-status file://logging.json\n```\nNote: Logging.json is a JSON document in the current folder that contains the logging policy\n\n**References**\n1. http://docs.aws.amazon.com/AmazonS3/latest/user-guide/server-access-logging.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-logging\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/get-bucket-acl.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-bucket-acl.html ",
        "complianceTag": "Logging",
        "logicHash": "5K85vjuhZsiPGk6vBHMcDQ",
        "ruleId": "D9.AWS.LOG.12",
        "category": ""
    },
    {
        "name": "S3 bucket should have versioning enabled",
        "description": "Ensure that buckets have versioning enabled so that you can recover objects from accidental deletion or overwrite",
        "severity": "Low",
        "logic": "S3Bucket should have versioning.status='Enabled'",
        "remediation": "\n**From Portal**\n1. Sign in to the AWS Management Console and navigate to Amazon S3 console at https://console.aws.amazon.com/s3/.\n2. Click on the name of the S3 bucket that you want to reconfigure.\n3. Select the Properties tab from the console menu to access the bucket properties.\n4. In the Bucket Versioning section, choose Edit to modify the object versioning configuration.\n5. On the Edit Bucket Versioning page, select Enable under Bucket Versioning to enable the feature. Choose Save changes to apply the configuration changes.\n\nNote: After enabling object versioning, you might need to update your lifecycle rules to manage previous versions of objects.\n\n**From TF**\n```\nresource \"aws_s3_bucket_versioning\" \"versioning_example\" {\nbucket = aws_s3_bucket.example.id\nversioning_configuration {\nstatus = \"Enabled\"\n}\n}\n```\n\n**From Command Line**\nRun put-bucket-versioning command to enable S3 object versioning for the selected bucket.\n```\naws s3api put-bucket-versioning --bucket cc-prod-web-data --versioning-configuration Status=Enabled\n```\n\n**References**\n1. https://docs.aws.amazon.com/AmazonS3/latest/userguide/manage-versioning-examples.html\n2. https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_versioning\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-bucket-versioning.html\n4. https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html ",
        "complianceTag": "Network Security",
        "logicHash": "CEEF1H4rD1d5mD8BEZIApw",
        "ruleId": "D9.AWS.NET.19",
        "category": ""
    },
    {
        "name": "SSL/TLS certificates expire in one month",
        "description": "Ensure that SSL/TLS certificates stored in AWS IAM are renewed one month before expiry.",
        "severity": "Low",
        "logic": "IamServerCertificate should not have expiration before(30, 'days')",
        "remediation": "\n**From Portal**\n1. Login to the AWS Management Console.\n2. Navigate to EC2 dashboard\n3. Go to Load Balancing and click Load Balancers.\n4. Select the Elastic Load Balancer for which certificate is expiring in one month.\n5. Select the Listeners tab and click the Change link in the SSL Certificate column.\n6. In the Select Certificate dialog box, perform the following actions:\na. If you have already deployed a certificate with AWS Certificate Manager (ACM), select Choose an existing certificate from AWS Certificate Manager (ACM) and choose the new SSL certificate from the Certificate dropdown list.\nb. If you have already uploaded an SSL certificate to AWS IAM, select Choose an existing certificate from AWS Identity and Access Management (IAM) and choose the new SSL certificate from the Certificate dropdown list.\nc. If you have not yet uploaded an SSL/TLS certificate to AWS IAM, select Upload a new SSL certificate to AWS IAM to deploy the new SSL certificate by entering the required data provided by the SSL certificate provider.\n7. Click Save to apply the new SSL certificate and replace the one that is about to expire.\n\nNote: You can perform the same steps for all load balancer that needs SSL/TLS certificates renewal.\n\n**From Command Line**\nRun below Command to replace the SSL certificates that are about to expire with new certificates uploaded to IAM.\n```\naws iam upload-server-certificate --server-certificate-name EXAMPLE_CERTIFICATE --certificate-body file://Certificate.pem --certificate-chain file://CertificateChain.pem --private-key file://PrivateKey.pem\n```\nRun below command to replace the ELB existing SSL certificate with the newly one uploaded to AWS IAM through upload command in previous step.\n```\naws elb set-load-balancer-listener-ssl-certificate --load-balancer-name EXAMPLE_NAME --load-balancer-port 443 --ssl-certificate-id EXAMPLE_CERTIFICATE_ID\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_server-certs.html\n2. https://aws.amazon.com/certificate-manager/ ",
        "complianceTag": "Encryption and Key Management",
        "logicHash": "LhXyLFHVWKTXu0uaK6kogA",
        "ruleId": "D9.AWS.CRY.09",
        "category": ""
    },
    {
        "name": "Security Groups must be defined under a Virtual Private Cloud",
        "description": "All security groups must be associated with a VPC, EC2 Classic not allowed. VPCs provides the controls to facilitate a formal process for approving and testing all network connections and changes to the firewall and router configurations.",
        "severity": "Low",
        "logic": "SecurityGroup where not name='default' should have vpc",
        "remediation": "\n**From Portal:**\nIf you want your instances in your VPC to have the same security group rules as your EC2-Classic instances, you can use the Amazon EC2 console to copy your existing EC2-Classic security group rules to a new VPC security group. You can copy any security group from EC2-Classic to your VPC that meets the requirements. Default security groups cannot be deleted and will be removed on your behalf when EC2-Classic is retired. You can only copy security group rules to a new security group in the same AWS account in the same Region. If you are using a different Region or a different AWS account, you must create a new security group and manually add the rules yourself. For more information, see Amazon EC2 security groups for Linux instances.\n\nPrerequisites: Before you begin copying your security groups, you should check for rules in which your EC2-Classic security groups reference another security group in EC2-Classic. You should remove these rules as they can't be copied into a VPC. For more information, see Delete rules from a security group.\n\nUse following steps to copy your security group rules to a new security group\n1. Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n2. In the navigation pane, choose Security Groups.\n3. Select the security group that's associated with your EC2-Classic instance, then choose Actions, and select Copy to new security group.\n4. In the Copy to new security group dialog box, specify a name and description for your new security group. Select your VPC from the VPC list.\n5. Under Inbound rules, the fields are populated with the rules from your EC2-Classic security group. You can modify the rules as required. Under Outbound rules, a rule that allows all outbound traffic has automatically been created for you. For more information about modifying security group rules, see Amazon EC2 security groups for Linux instances.\nImportant: You must remove any rules that reference a security group in EC2-Classic, because you can't reference an EC2-Classic security group from a VPC security group. You can add similar rules after you copy the security group to your VPC.\n6. Choose Create security group.\n\n**From Command Line:**\n1. Run following command to describe the configuration of the default security group.\n```\naws ec2 describe-security-groups --region us-east-1 --filters Name=group-name,Values='default'\n```\n2. Run following command to create a new custom security group under VPC, this will replace the default security group.\n```\naws ec2 create-security-group --region region_name --group-name security_group_name --description example_description --vpc-id vpc_id\n```\n3. Run following command using newly created security group ID as the identifier parameter, to transfer the inbound information from the default security group to the new security group.\n```\naws ec2 authorize-security-group-ingress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --cidr cidr_value\n```\n4. Run following command using newly created security group ID as the identifier parameter, to transfer the outbound information from the default security group to the new security group.\n```\naws ec2 authorize-security-group-egress --region region_name --group-id security_group_id --protocol protocol_name --port port_name --cidr cidr_value\n```\n5. Run following command using the Amazon EC2 ID that you want to reconfigure, to replace the default security group with the custom one. Make sure to add any other compliant security groups, associated with the EC2 instance under the --groups parameter.\n```\naws ec2 modify-instance-attribute --region region_name --instance-id ID_value --groups default_security_group_id custom_security_group_id\n```\n\nReferences:\n1. http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-migrate.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-instances.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-security-groups.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-security-group.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/authorize-security-group-ingress.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/authorize-security-group-egress.html\n7. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify-instance-attribute.html ",
        "complianceTag": "Network Security",
        "logicHash": "6WFfUdXueaDW1GNgwNsXfw",
        "ruleId": "D9.AWS.NET.13",
        "category": ""
    },
    {
        "name": "Unused IAM role more than 90 days",
        "description": "Unused IAM role more than 90 days, or IAM role was not in use at all (if lastUsedDate in null).",
        "severity": "Low",
        "logic": "IamRole should not have roleLastUsed.lastUsedDate before(-90,'days')",
        "remediation": "\n**From Portal**\nUse following steps to identify unused IAM roles from AWS console:\n1. Sign in to the AWS Management Console.\n2. Navigate to the IAM dashboard at https://console.aws.amazon.com/iam/.\n3. In the left navigation panel, select **Roles**.\n4. Look for the Last activity column.\nNote: This column displays the number of days that have passed since each role made an AWS service request. AWS records last-used information for the trailing 400 days. This is referred to as the tracking period.\n5. Sort the column by clicking on it to identify the roles your team has not used recently.\n6. Any role that has Last activity of more than 90 days can be considered unused.\n7. Click on the name of the role to view more information. The role Summary page also includes the Last activity, which displays the last used date for the role.\nNote that there are multiple pages, so you may have to click on the top arrows to view the information for all roles.\n8. Any role with Last Activity as Blank (-) means no activity has been recorded for the past 400 days.\n\nUse following steps to delete the unused roles from AWS console:\nNote: Ensure that the rule is necessary and follows the least privilege principle, otherwise consider deleting the role.\n\n1. Sign in to the AWS Management Console.\n2. Navigate to the IAM dashboard at https://console.aws.amazon.com/iam/.\n3. In the left navigation panel, select **Roles**.\n4. Filter the role that you want to delete. You can use the Search bar and type the role initial few letters to filter to the role easily.\n5. Check the box next to the role name you intend to delete.\n6. At the top right corner, click the Delete button to delete the role.\n7. Review the last accessed information in the confirmation dialog prompt. This will help check the active status of the selected roles, i.e., the last time an AWS Service used them.\na. If you want to proceed, enter the role's name in the text input field and choose Delete.\nb. If you are sure, you can proceed with the deletion even if the last accessed information is still loading.\n\n**From Command Line**\nNote: When you use the AWS CLI to delete a role, you must first delete the policies associated with the role. Also, if you want to delete the associated instance profile that contains the role, you must delete it separately.\n\n1. Remove the role from all instance profiles that the role is in.\n\na. Use the following command to list all instance profiles that the role is associated with.\n```\naws iam list-instance-profiles-for-role --role-name example_role_name\n```\nb. Use the following command for each instance profile to remove the role from an instance profile.\n```\naws iam remove-role-from-instance-profile --instance-profile-name profile_name --role-name example_role_name\n```\n2. To Delete all inline policies that are associated with the role, perform the following:\na. Use the following command to list all policies that are in the role:\n```\naws iam list-role-policies --role-name example_role_name\n```\nb. Use the following command for each policy to delete each policy from the role.\n```\naws iam delete-role-policy --role-name example_role_name --policy-name ec2-list-policy\n```\n3. Run delete-role command to delete the IAM role:\n```\naws iam delete-role --role-name example_role_name\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_manage_delete.html\n2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-instance-profiles-for-role.html\n3. https://awscli.amazonaws.com/v2/documentation/api/2.1.30/reference/iam/remove-role-from-instance-profile.html\n4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-role-policies.html\n5. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-role-policy.html\n6. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-role.html ",
        "complianceTag": "Identity and Access Management",
        "logicHash": "VzbMo0SVu+yL9/zZmOj8Gw",
        "ruleId": "D9.AWS.IAM.63",
        "category": ""
    },
    {
        "name": "Use managed policies instead of inline IAM Policies ",
        "description": "Inline policies are policies that are embedded directly into a single user, group, or role.\nIt is recommend to use managed policies instead of inline policies. Managed policies provide reusability, central change management, versioning and more capabilities.",
        "severity": "Low",
        "logic": "IamUser should not have inlinePolicies",
        "remediation": "\n**From Portal**\nUsing the GUI, perform the following to detach the policy that has full administrative privileges:\n1. Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.\n2. In the navigation pane, click Users.\n3. Select the User and click on Permissions.\n4. Remove any policies attached directly to the user (these are inline policies), and replace them with equivalent managed policies (in the Policies page) that are assigned to users, groups or roles.\n\n**From TF**\n```\nresource \"aws_iam_policy\" \"my-policy\" {\nname = \"test-policy\"\n\npolicy = <<EOF\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n+     \"Action\": [\"some:action\"],\n\"Resource\": \"*\"\n}\n]\n}\nEOF\n}\n```\n\n**From Command Line**\nTo delete inline policy for any specific user, run :\n```\naws iam delete-user-policy --user-name USERNAME --policy-name POLICY_NAME\n\n```\n\n**References**\n1. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html\n2. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage.html\n3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/list-policies.html",
        "complianceTag": "Identity and Access Management",
        "logicHash": "EeY3uIY5iwAWr/2JogpxEg",
        "ruleId": "D9.AWS.IAM.44",
        "category": ""
    }
]